{
  "hash": "f8412ddf45a65e220fb10fdff2227e01",
  "result": {
    "markdown": "---\ntitle: \"In-class Exercise 2\"\ndate: '25 November 2023'\ndate-modified: 'last-modified'\nformat: html\nexecute: \n  eval: true # run the code live\n  echo: true # all code will appear\n  warning: false # hide all warnings\neditor: visual\n---\n\n\n## Getting Started\n\n### Installing and Loading R Packages\n\nLoading R packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, sfdep, tmap, tidyverse, knitr)\n```\n:::\n\n\n### The Data\n\nFor this In-class Exercise, the Hunan data sets will be used. They are:\n\n1.  hunan: a geographical data set in ESRI shapefile format\n2.  Hunan_2012: an attribute data set in csv format\n\n### Importing geospatial data\n\n*st_read()* can be used to read the shape file data set into an R sf dataframe\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan <- st_read(dsn = 'data/geospatial',\n                 layer = 'Hunan')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nReading layer `Hunan' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n:::\n:::\n\n\n### Importing attribute table\n\n*read_csv()* can be used to read the attribute file into an R data frame\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_2012 <- read_csv('data/aspatial/Hunan_2012.csv')\n```\n:::\n\n\n### Combining the two data sets\n\n*left_join()* can be used to combine the two data sets\n\n::: callout-note\nIn order to retain the geospatial properties, the left data frame must be **sf data.frame**, in this case it is hunan\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_GDPPC <- left_join(hunan, hunan_2012,\n                            by = 'County')%>%\n  select(1:4, 7, 15) #Retaining the city's name, ID, county name, county type, GDPPC, and geometry\n```\n:::\n\n\n## Deriving Contiguity Weights: Queen's Model\n\nThe sfdep method entails the creation of a tibble data frame which contains the original data as well as the neighbors list and weights for each polygon , as opposed to creating the contiguity and weight separately in spdep.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry), # Default is Queen\n         wt = st_weights(nb,\n                         style='W'),\n         .before = 1)\n```\n:::\n\n\n## Computing Global Moran's I (old spdep method)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranI <- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\nmoranI\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$I\n[1] 0.30075\n\n$K\n[1] 7.640659\n```\n:::\n:::\n\n\n## Computing Local Moran's I (with sfdep method)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa <- wm_q %>%\n  mutate(local_moran = local_moran(GDPPC, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_moran)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}