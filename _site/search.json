[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "Welcome to ISSS624 Geospatial Analytics Applications!\nIn this webpage, I am going to share with you my learning journey of geospatial analytics."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/data/geospatial/MPSZ-2019.html",
    "href": "In-Class_Ex/In-Class_Ex1/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#overview",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Getting Started",
    "text": "Getting Started\nThe code chunk below installs and loads sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\n\nImporting polygon features data\nReading the Master Planning 2014 Subzone shapefile into a dataframe\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nReading the CyclingPath shapefile into a dataframe\n\ncyclingpath &lt;- st_read(dsn = \"data/geospatial\",layer = 'CyclingPathGazette')\n\nReading layer `CyclingPathGazette' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nRead the Pre-School Locations kml file into a dataframe using a complete path\n\npreschool &lt;- st_read('data/geospatial/PreSchoolsLocation.kml')\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#checking-the-content-of-a-simple-feature-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#checking-the-content-of-a-simple-feature-dataframe",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Checking the Content of a Simple Feature DataFrame",
    "text": "Checking the Content of a Simple Feature DataFrame\n\nWorking with st_geometry()\nUsing st_geometry() to retrieve basic information of the dataframe\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\n\nWorking with glimpse()\nUse glimpse() to get the data types of each column and some of their values\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\nWorking with head()\nhead() lets us inspect the top n rows of the dataframe\n\nhead(mpsz, n= 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#plotting-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Plotting Geospatial Data",
    "text": "Plotting Geospatial Data\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum. This can be seen using the plot() function.\n\nplot(mpsz)\n\n\n\n\nWe can choose to plot only the geometry (outline) by using st_geometry()\n\nplot(st_geometry(mpsz))\n\n\n\n\nWe can also choose the specific attribute of the dataframe we would like to plot by addressing it in the R dataframe\n\nplot(mpsz['PLN_AREA_N'])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#working-with-projection",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Working with Projection",
    "text": "Working with Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nThe process of projecting one dataframe from one coordinate system to another is called projection transformation.\n\nAssigning EPSG code to a simple feature data frame\nIdentifying the coordinate system of a dataframe using st_crs()\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nIn order to assign the correct EPSG code, use st_set_crs()\n\nmpsz3414 &lt;- st_set_crs(mpsz,3414)\n\nDouble check the new ESPG using st_crs()\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nTransforming the projection of preschool from WGS84 to SVY21\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nCheck the coordinate system for the preschool dataframe\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nst_set_crs() is not appropriate here because we need to reproject the dataframe from one coordinate system to another coordinate system mathematically.\nThis can be performed using st_transform()\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\nDouble-check the coordinate system for preschool3414\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing and Converting Aspatial Data",
    "text": "Importing and Converting Aspatial Data\n\nImporting the Aspatial Data\nWe can read the listings csv into an R tibble dataframe using read_csv() of readr\n\nlistings &lt;- read_csv('data/aspatial/listings.csv')\n\nWe can use list(), instead of glimpse() in order to see the columns, data types, and some rows of the new dataframe\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,483 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Vill… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… &lt;b&gt;The spa…\n 3  71903 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n10 369141 https://www.airbnb.co…   2.02e13 2023-09-23   city … Plac… A room in …\n# ℹ 3,473 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\n\n\nCreating a simple feature dataframe from an aspatial dataframe\nst_as_sf() can be used to convert the listing dataframe into a simple feature dataframe. Note that:\n\ncoords argument requires the column name of the x-coordinates first (longitude) then the column name of the y-coordinates (latitude)\ncrs argument requires the specific coordinates system. As we suspect the coordinate system of listings to be WGS84, this would be crs = 4326 . Singapore’s EPSG code is 3414 as we have used before.\nWe use %&gt;% in dplyr to nest st_transform() to reproject the new simple feature dataframe into SVY21 (EPSG: 3414) coordinates system.\n\n\nlistings_sf &lt;- st_as_sf(listings,\n                        coords = c('longitude','latitude'),\n                        crs=4326)%&gt;%\n  st_transform(crs=3414)\n\nglimpse() can be used to view the new simple feature dataframe, its data types, and some row values. Notice that a new column called geometry has been added and longitude and latitude have been dropped.\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.023092e+13, 2.023092e+1…\n$ last_scraped                                 &lt;date&gt; 2023-09-23, 2023-09-23, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"previ…\n$ name                                         &lt;chr&gt; \"Villa in Singapore · ★4.…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within a few hours\", \"wi…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52…\n$ host_total_listings_count                    &lt;dbl&gt; 15, 15, 15, 65, 65, 15, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; NA, NA, NA, NA, NA, 3, NA…\n$ beds                                         &lt;dbl&gt; 3, 1, 2, 1, 1, 5, 1, 1, 1…\n$ amenities                                    &lt;chr&gt; \"[\\\"Private backyard \\\\u2…\n$ price                                        &lt;chr&gt; \"$150.00\", \"$80.00\", \"$80…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 28, 28, 28, 1, 30, 28, 30…\n$ availability_60                              &lt;dbl&gt; 58, 58, 58, 1, 60, 58, 60…\n$ availability_90                              &lt;dbl&gt; 88, 88, 88, 1, 90, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 89, 89, 275, 274, 89,…\n$ calendar_last_scraped                        &lt;date&gt; 2023-09-23, 2023-09-23, …\n$ number_of_reviews                            &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 1, 1, 1…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 6, 51…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\nThe sf package offers a wide range of geoprocessing (GIS) functions.\nIn this section, you will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\nBuffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution\nWe can use st_buffer() to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist =5,\n                            nQuadSegs = 30)\n\nWe can then calculate the area of each of the buffers using st_area()\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, we can sum up all the areas of the buffers to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n\n\nPoint-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nWe can: first, identify pre-schools located inside each Planning Subzone by using st_intersects(), second, length() can be used to calculate number of pre-schools that falls inside each planning subzone.\n\nmpsz3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nsummary() can be used to check the summary statistics of the newly created PreSch Count column in mpsz3414\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\ntop_n() can be used to list the top n planning subzone with the highest number of pre-school\n\ntop_n(mpsz3414,1,`PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nWe can also calculate the density of preschool by planning subzone:\nFirst, st_area() can be used to derive the area of each planning subzone.\n\nmpsz3414$AREA &lt;- mpsz3414%&gt;%\n  st_area()\n\nNext, mutate() can be used to compute the density by using the previously created ‘PreSch Count’ and ‘AREA’ columns\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = (`PreSch Count`/AREA)*1000000)\n\nWe can extract the planning subzone with the highest preschool density using top_n()\n\ntop_n(mpsz3414,1,`PreSch Density`)\n\nSimple feature collection with 1 feature and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29501.64 ymin: 28623.75 xmax: 29976.93 ymax: 29362.03\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO SUBZONE_N SUBZONE_C CA_IND    PLN_AREA_N PLN_AREA_C\n1       27          8     CECIL    DTSZ08      Y DOWNTOWN CORE         DT\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D  X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 65AA82AF6F4D925D 2014-12-05 29730.2 29011.33\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   2116.095   196619.9 MULTIPOLYGON (((29808.18 28...            7\n            AREA   PreSch Density\n1 196619.9 [m^2] 35.60169 [1/m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#overview",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Getting Started",
    "text": "Getting Started\nThe code chunk below installs and loads sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\n\nImporting polygon features data\nReading the Master Planning 2014 Subzone shapefile into a dataframe\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nReading the CyclingPath shapefile into a dataframe\n\ncyclingpath &lt;- st_read(dsn = \"data/geospatial\",layer = 'CyclingPathGazette')\n\nReading layer `CyclingPathGazette' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nRead the Pre-School Locations kml file into a dataframe using a complete path\n\npreschool &lt;- st_read('data/geospatial/PreSchoolsLocation.kml')\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#checking-the-content-of-a-simple-feature-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#checking-the-content-of-a-simple-feature-dataframe",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Checking the Content of a Simple Feature DataFrame",
    "text": "Checking the Content of a Simple Feature DataFrame\n\nWorking with st_geometry()\nUsing st_geometry() to retrieve basic information of the dataframe\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\nWorking with glimpse()\nUse glimpse() to get the data types of each column and some of their values\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\nWorking with head()\nhead() lets us inspect the top n rows of the dataframe\n\nhead(mpsz, n= 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#plotting-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Plotting Geospatial Data",
    "text": "Plotting Geospatial Data\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum. This can be seen using the plot() function.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nWe can choose to plot only the geometry (outline) by using st_geometry()\n\nplot(st_geometry(mpsz))\n\n\n\n\nWe can also choose the specific attribute of the dataframe we would like to plot by addressing it in the R dataframe\n\nplot(mpsz['PLN_AREA_N'])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#working-with-projection",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Working with Projection",
    "text": "Working with Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nThe process of projecting one dataframe from one coordinate system to another is called projection transformation.\n\nAssigning EPSG code to a simple feature data frame\nIdentifying the coordinate system of a dataframe using st_crs()\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nIn order to assign the correct EPSG code, use st_set_crs()\n\nmpsz3414 &lt;- st_set_crs(mpsz,3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nDouble check the new ESPG using st_crs()\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nTransforming the projection of preschool from WGS84 to SVY21\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nCheck the coordinate system for the preschool dataframe\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT Z (103.8072 1.299333 0)\n\n\nPOINT Z (103.826 1.312839 0)\n\n\nPOINT Z (103.8409 1.348843 0)\n\n\nPOINT Z (103.8048 1.435024 0)\n\n\nPOINT Z (103.839 1.33315 0)\n\n\nst_set_crs() is not appropriate here because we need to reproject the dataframe from one coordinate system to another coordinate system mathematically.\nThis can be performed using st_transform()\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\nDouble-check the coordinate system for preschool3414\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing and Converting Aspatial Data",
    "text": "Importing and Converting Aspatial Data\n\nImporting the Aspatial Data\nWe can read the listings csv into an R tibble dataframe using read_csv() of readr\n\nlistings &lt;- read_csv('data/aspatial/listings.csv')\n\nRows: 3483 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (37): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (7): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe can use list(), instead of glimpse() in order to see the columns, data types, and some rows of the new dataframe\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,483 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Vill… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… &lt;b&gt;The spa…\n 3  71903 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n10 369141 https://www.airbnb.co…   2.02e13 2023-09-23   city … Plac… A room in …\n# ℹ 3,473 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\n\n\nCreating a simple feature dataframe from an aspatial dataframe\nst_as_sf() can be used to convert the listing dataframe into a simple feature dataframe. Note that:\n\ncoords argument requires the column name of the x-coordinates first (longitude) then the column name of the y-coordinates (latitude)\ncrs argument requires the specific coordinates system. As we suspect the coordinate system of listings to be WGS84, this would be crs = 4326 . Singapore’s EPSG code is 3414 as we have used before.\nWe use %&gt;% in dplyr to nest st_transform() to reproject the new simple feature dataframe into SVY21 (EPSG: 3414) coordinates system.\n\n\nlistings_sf &lt;- st_as_sf(listings,\n                        coords = c('longitude','latitude'),\n                        crs=4326)%&gt;%\n  st_transform(crs=3414)\n\nglimpse() can be used to view the new simple feature dataframe, its data types, and some row values. Notice that a new column called geometry has been added and longitude and latitude have been dropped.\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.023092e+13, 2.023092e+1…\n$ last_scraped                                 &lt;date&gt; 2023-09-23, 2023-09-23, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"previ…\n$ name                                         &lt;chr&gt; \"Villa in Singapore · ★4.…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within a few hours\", \"wi…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52…\n$ host_total_listings_count                    &lt;dbl&gt; 15, 15, 15, 65, 65, 15, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; NA, NA, NA, NA, NA, 3, NA…\n$ beds                                         &lt;dbl&gt; 3, 1, 2, 1, 1, 5, 1, 1, 1…\n$ amenities                                    &lt;chr&gt; \"[\\\"Private backyard \\\\u2…\n$ price                                        &lt;chr&gt; \"$150.00\", \"$80.00\", \"$80…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 28, 28, 28, 1, 30, 28, 30…\n$ availability_60                              &lt;dbl&gt; 58, 58, 58, 1, 60, 58, 60…\n$ availability_90                              &lt;dbl&gt; 88, 88, 88, 1, 90, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 89, 89, 275, 274, 89,…\n$ calendar_last_scraped                        &lt;date&gt; 2023-09-23, 2023-09-23, …\n$ number_of_reviews                            &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 1, 1, 1…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 6, 51…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\nThe sf package offers a wide range of geoprocessing (GIS) functions.\nIn this section, you will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\nBuffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution\nWe can use st_buffer() to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist =5,\n                            nQuadSegs = 30)\n\nWe can then calculate the area of each of the buffers using st_area()\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, we can sum up all the areas of the buffers to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n\n\nPoint-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nWe can: first, identify pre-schools located inside each Planning Subzone by using st_intersects(), second, length() can be used to calculate number of pre-schools that falls inside each planning subzone.\n\nmpsz3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nsummary() can be used to check the summary statistics of the newly created PreSch Count column in mpsz3414\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\ntop_n() can be used to list the top n planning subzone with the highest number of pre-school\n\ntop_n(mpsz3414,1,`PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nWe can also calculate the density of preschool by planning subzone:\nFirst, st_area() can be used to derive the area of each planning subzone.\n\nmpsz3414$AREA &lt;- mpsz3414%&gt;%\n  st_area()\n\nNext, mutate() can be used to compute the density by using the previously created ‘PreSch Count’ and ‘AREA’ columns\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = (`PreSch Count`/AREA)*1000000)\n\nWe can extract the planning subzone with the highest preschool density using top_n()\n\ntop_n(mpsz3414,1,`PreSch Density`)\n\nSimple feature collection with 1 feature and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29501.64 ymin: 28623.75 xmax: 29976.93 ymax: 29362.03\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO SUBZONE_N SUBZONE_C CA_IND    PLN_AREA_N PLN_AREA_C\n1       27          8     CECIL    DTSZ08      Y DOWNTOWN CORE         DT\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D  X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 65AA82AF6F4D925D 2014-12-05 29730.2 29011.33\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   2116.095   196619.9 MULTIPOLYGON (((29808.18 28...            7\n            AREA   PreSch Density\n1 196619.9 [m^2] 35.60169 [1/m^2]"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\nThis was made by Phan Hoang Long for ISSS624."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThis can be done using the tmap package. We can load this and other required packages (sf, tidyverse) using the code below.\n\npacman::p_load(sf, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#overview",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThis can be done using the tmap package. We can load this and other required packages (sf, tidyverse) using the code below.\n\npacman::p_load(sf, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#importing-data-into-r",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Importing Data into R",
    "text": "Importing Data into R\n\nThe Data\nTwo datasets will be used:\n\nMaster Plan 2014 Subzone Boundary (Web) in ESRI shapefile format. It consists of geographical boundary of Singapore at the planning subzone level and is babsed on the URA Master Plan 2014.\nSingapore Residents by Planning Area/Subzone, Age Grouu, Sex, and Type of Dwelling, June 2011-2020 csv format. This is aspatial data. Its PA and SZ fields can be used to geocode to the Master Plan 2014 Subzone Boundary (Web) shapefile.\n\n\n\nImporting Geospatial Data into R\nst_read() can be used to read the Master Plan 2014 shapefile into an R dataframe.\n\nmpsz &lt;- st_read(dsn = 'data/geospatial',\n                layer = 'MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nglimpse() and head() can be used to look at the data types and first few rows of data\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\nhead(mpsz, 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\nImporting Attribute Data into R\nFor the resident population data, read_csv() will be used as it is stored as a csv\n\npopdata &lt;- read_csv('data/aspatial/respopagesexfa2011to2020.csv')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#data-preparation",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Data Preparation",
    "text": "Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\nThis table would have the rows be each unique PA and SZ and with the following new columns:\n\nYOUNG: number of people from age group 0-4 to age group 20-24\nECONOMY ACTIVE: number of people from age group 25-29 to age group 60-64\nAGED: number of people age group 65 +\nTOTAL: number of people in all age groups\nDEPENDENCY: the ratio between YOUNG + AGED against ECONOMY ACTIVE\n\n\nData Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider(): To pivot the dataframe from long to wide format with rows becoming new columns\nmutate(), filter(), and group_by(): Creating new columns, filtering, and group columns based on value of some columns\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;% #Getting only 2020 data\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;% #Summarizing by population based on the group_by\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP)%&gt;% #pivot wider based on names in AG and values from POP\n  mutate(YOUNG = rowSums(.[3:6])+rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+rowSums(.[15]))%&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)\n\n\n\nJoining the attribute data and geospatial data\nCurrently, the values of the PA and SZ fields are a mix of lower and uppercase characters while the values in SUBZONE_N and PLN_AREA_N are all uppercase.\nWe need to convert the values in PA and SZ fields to uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), #Apply the toupper function to multiple columns\n            .funs = list(toupper)) %&gt;% \n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nleft_join() can then be used to join the geographical data and attribute table based on SZ being the same as SUBZONE_N. left_join() is used with the simple feature dataframe (mpsz) as the left data table to ensure the output will be a simple features dataframe; it will also keep all observations in mpsz.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c('SUBZONE_N' = 'SZ'))\n\nNow, we can use write_rds to create a new rds (R Data Serialization) file with the new dataframe\n\nwrite_rds(mpsz_pop2020, 'data/rds/mpszpop2020.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Choropleth Mapping Geospatial Data using tmap",
    "text": "Choropleth Mapping Geospatial Data using tmap\n\nPlotting a choropleth map quickly by using qtm()\nDefault visualization using qtm(). Note that tmap_mode() with “plot” is used to produce a static map. For interactive mode, “view” should be used.\n\ntmap_mode('plot')\nqtm(mpsz_pop2020,\n    fill = 'DEPENDENCY') #the DEPENDENCY column will be used for the color variation\n\n\n\n\n\n\nCreating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          style='quantile',\n          palette = 'Blues',\n          title = 'Dependency ration')+\n  tm_layout(main.title = 'Distribution of Dependency Ratio by planning subzone',\n            main.title.position = 'center',\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type='8star',size=2)+\n  tm_scale_bar()+\n  tm_grid(alpha = 0.2)+\n  tm_credits('Sourrce: Planning Sub-zone boundary from Urban Redevelopment Authority \\n and Population data from Department of Statistics (DOS)',\n             position = c('left','bottom'))\n\n\n\n\nThe following sections will explain each step of the process executed in the code chunk above\n\n\nDrawing a base map\nThe basic building block of tmap is tm_shape() which is used to define the input data and tm_polygons() which is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons()\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\ntm_polygons() can be modified with the target variable in order to draw the choropleth map showing the geographical distribution of the selected variable.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons('DEPENDENCY')\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\nDrawing a choropleth map using tm_fill() and tm_border()\ntm_polygons() is a wrapper of tm_fill() and tm_border():\n\ntm_fill() shades the polygons by using the default colour scheme\ntm_borders() adds the borders of the shapefile onto the choropleth map\n\nIf you use tm_fill() alone, there will be no border between the subzones. The planning subzones are shared according to the respective dependency values.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY')\n\n\n\n\ntm_borders() can be used to add the boundary of the planning subzones. tm_borders() has three arguments:\n\nalpha: transparency of the line\ncol: border colour\nlwd: line width\nlty: line type\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY')+\n  tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\nData classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\nPlotting choropleth maps with built-in classification methods\njenks data classification method\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 5, #number of classes\n          style = 'jenks')+\n  tm_borders(alpha = 0.5)\n\n\n\n\nequal data classification method\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 5,\n          style = 'equal')+\n  tm_borders(alpha = 0.5)\n\n\n\n\nquantile data classification method\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 5,\n          style = 'quantile')+\n  tm_borders(alpha = 0.5)\n\n\n\n\nThe distribution of quantile data classification method are more evenly distributed then equal data classification method.\nUsing the quantile style with different numbers of classes\n2 classes\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 2,\n          style = 'quantile')+\n  tm_borders(alpha = 0.5)\n\n\n\n\n6 classes\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 6,\n          style = 'quantile')+\n  tm_borders(alpha = 0.5)\n\n\n\n\n10 classes\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 10,\n          style = 'quantile')+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nPlotting choropleth map with custom break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nsummary() can be used to get some descriptive statistics on the variable ‘DEPENDENCY’ before setting break points.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6540  0.7063  0.7712  0.7657 19.0000      92 \n\n\nWith reference to the results above and the need to include a minimum and maximum (0 and 100), we can set our breaks with the vector c(0, 0.5, 0.6, 0.7, 0.8, 1.00)\nNow we can plot the choropleth map with custom breaks\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          breaks = c(0, 0.5, 0.6, 0.7, 0.8, 1.00))+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nColour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package\n\nUsing ColourBrewer palette\nTo change the colour, we assigned the preferred colour to the palette argument of tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 6,\n          style = 'quantile',\n          palette = 'Blues')+\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can also reverse the color scheme (darker for lower values) by adding a ‘-’ prefix to the palette argument\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 6,\n          style = 'quantile',\n          palette = '-Blues')+\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#map-layouts",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Map Layouts",
    "text": "Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\nMap Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          style = 'jenks',\n          palette = 'Blues',\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1)+\n  tm_layout(main.title = 'Distribution of Dependency Ratio by planning subzone \\n (Jenks Classification)',\n            main.title.position = 'center',\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c('right','bottom'),\n            frame = FALSE)+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMap Style\ntmap allows a wide variety of layout settings to be changes. They can be called by using tmap_style()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          style = 'quantile',\n          palette = '-Greens')+\n  tm_borders(alpha = 0.5)+\n  tmap_style('classic')\n\n\n\n\n\n\nCartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\ntm_compass() can be used to add a compass.\ntm_scale_bar() can be used to add a scale bar.\ntm_grid() can be used to add grid lines.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          style = 'quantile',\n          palette = 'Blues',\n          title = 'No. of persons')+\n  tm_layout(main.title = 'Distribution of Dependency Ratio by planning subzone \\n (Jenks Classification)',\n            main.title.position = 'center',\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = '8star', size = 2)+\n  tm_scale_bar(width = 0.15)+\n  tm_grid(lwd = 0.1, alpha = 0.2)+\n  tm_credits('Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA) \\n and Population data from Department of Statistic (DOS)',\n             position = c('left','bottom'))\n\n\n\n\nTo reset to the default style, use tmap_style(‘white’)\n\ntmap_style('white')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Drawing Small Multiple Choropleth Maps",
    "text": "Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the aesthetic arguments\nby defining a group-by variable in tm_facets()\nby creating multiple standalone maps with tmap_arrange()\n\n\nBy assigning multiple values to at least one of the aesthetic arguments\nThe ncols argument in tm_fill() can be used to make multiple choropleth maps\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c('YOUNG','AGED'),\n          style = 'equal',\n          palette = 'Blues')+\n  tm_layout(legend.position = c('right','bottom'))+\n  tm_borders(alpha = 0.5)+\n  tmap_style('white')\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(c('DEPENDENCY','AGED'),\n              style = c('equal','quantile'),\n              palette = list('Blues','Greens'))+\n  tm_layout(legend.position = c('right','bottom'))\n\n\n\n\n\n\nBy defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          style = 'quantile',\n          palette = 'Blues',\n          thres.poly = 0)+\n  tm_facets(by = 'REGION_N',\n            free.coords = TRUE,\n            drop.shapes = TRUE)+\n  tm_layout(legend.show = FALSE,\n            title.position = c('center','center'),\n            title.size = 20)+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nBy creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+\n  tm_polygons('YOUNG',\n              style = 'quantile',\n              palette = 'Blues')\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+\n  tm_polygons('AGED',\n              style = 'quantile',\n              palette = 'Blues')\n\ntmap_arrange(youngmap, agedmap, asp = 1, ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Mapping Spatial Object Meeting a Selection Criterion",
    "text": "Mapping Spatial Object Meeting a Selection Criterion\nSelection function can be used to map spatial objects meeting the selection criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N=='CENTRAL REGION',])+\n  tm_fill('DEPENDENCY',\n          style = 'quantile',\n          palette = 'Blues',\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1)+\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45,\n            legend.width = 5.0,\n            legend.position = c('right','bottom'),\n            frame = FALSE)+\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise:\n\nHunan County Boundary Layer: Geospatial data set in ESRI shapefile format\nHunan_2012.csv: Selected local development indicators in 2012\n\n\n\nWe will use the p_load() function of the pacman package to load the required packages: spdep (for spatial weights), sf, tmap, and tidyverse.\n\npacman::p_load(spdep, tmap, sf, knitr, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#the-study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#the-study-area-and-data",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise:\n\nHunan County Boundary Layer: Geospatial data set in ESRI shapefile format\nHunan_2012.csv: Selected local development indicators in 2012\n\n\n\nWe will use the p_load() function of the pacman package to load the required packages: spdep (for spatial weights), sf, tmap, and tidyverse.\n\npacman::p_load(spdep, tmap, sf, knitr, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#getting-the-data-into-the-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#getting-the-data-into-the-r-environment",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Getting the Data into the R Environment",
    "text": "Getting the Data into the R Environment\n\nImport Shapefile into R Environment\nst_read() can be used to import the Hunan shapefile into a sf dataframe\n\nhunan &lt;- st_read(dsn = 'data/geospatial',\n                 layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImport Attribute Data (aspatial) into R Environment\nread_csv() can be used to import the Hunan_2012.csv into R as a data frame\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\nPerforming Relational Join\nSince both data frames have 88 rows and share the ‘County’ column, we can use left_join() to update the hunan sf data frame with with attribute fields of hunan2012 data frame.\n\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nThe left_join() argument automatically seeks out the shared field for joining. In this case, it is ‘by = join_by(County)’."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#visualizing-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#visualizing-regional-development-indicator",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Visualizing Regional Development Indicator",
    "text": "Visualizing Regional Development Indicator\nwe can prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of the tmap package.\n\nbasemap &lt;- tm_shape(hunan)+\n  tm_polygons() +\n  tm_text('NAME_3', size = 0.3) #A basemap is created showing the boundaries and names of counties in Hunan\n\ngdppc &lt;- qtm(hunan, 'GDPPC') # A choropleth map showing the distribution of GDPPC in Hunan\n\ntmap_arrange(basemap, gdppc, asp = 1, ncol = 2) # Arranging basemap and gdppc along two columns"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#computing-contiguity-spatial-weights",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nWe can use poly2nb() of spep to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries.\nIn poly2nb(), you can pass TRUE or FALSE to the queen argument in order to indicate whether to use the queen method. The default is TRUE.\n\nComputing (QUEEN) contiguity based neighbours\n\nwm_q &lt;- poly2nb(hunan, queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours (area 85). There are two area units with only 1 neighbour (30 and 65).\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. To see the neighbors for the first polygon in the object, you can specify it similar to a list of list\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan spdf class\nWe can retrieve the county name of Polygon ID = 1 by specifying it its position in the hunan data fram\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nSimilarly, you can extract the name of its neighbors using their Polygon ID in wm_q\n\nhunan$County[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can also retreive the GDPPC of these five counties\n\nnb1 &lt;- wm_q[[1]]\nnb1_gdppc &lt;- hunan$GDPPC[nb1]\nnb1_gdppc\n\n[1] 20981 34592 24473 21311 22879\n\n\nAdditionally, you can display the complete neighbor list using str() However, this output will cut across several pages.\n\n\nCreating (ROOK) Contiguity Based Neighbours\nWe can use Rook contiguity instead of Queen contiguity by passing FALSE to the queen argument of poly2nb\n\nwm_r &lt;- poly2nb(hunan, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nSimilar to Queen, the number of area units in Hunan remains unchanged at 88. However, the most connected area unit has only 10 neighbours (area 85). The two area units with only one neighbour remain the same (area 30 and 65).\n\n\nVisualizing Contiguity Weights\nA connectivity graph takes a point and displays a line to each neighboring point.\nWe are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typical method for this will be polygon centroids.\nWe can use the sf package to get Latitude and Longitude of polygon centroids before moving onto the graphs.\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object. We need the coordinates in a separate data frame. To do this we will use a mapping function.\nThe mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of hunan. Our function will be st_centroid. We will be using map_dbl() variation of map from thhe purrr package.\nTo get our longitude values, we map the st_centroid function over the geometry column of hunan and access the longitude value through double bracket notation [[]] and 1 ([[1]]]). This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe can do the same for latitude, only with [[2]] instead.\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have longitude and latitude, we can use cbind to put them together into the same object (coords) as two separate columns\n\ncoords_hunan &lt;- cbind(longitude, latitude)\n\nWe can check the first few observation of this new object using head()\n\nhead(coords_hunan)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting Queen Contiguity Based Neighbours Map\nThe contiguity map will draw a line between the centroid of each polygon and the centroids of its neighbors based on the Queen Contiguity.\n\nplot(hunan$geometry, border = 'lightgrey')\nplot(wm_q,coords_hunan, pch = 19, cex = 0.6, add = TRUE, col = 'red')\n\n\n\n\nIf we use plot(wm_q, coords_hunan) by itself, it will only provide a contiguity map with no border for each county.\n\n\nPlotting Rook Contiguity Based Neighbours Map\nWe can easily make a Rook contiguity map instead of a Queen contiguity map by using wm_r instead of wm_q\n\nplot(hunan$geometry, border = 'lightgrey')\nplot(wm_r, coords_hunan, pch = 19, cex = 0.6, add = TRUE, col = 'red')\n\n\n\n\n\n\nPlotting both Queen and Rook Contiguity Based Neighbours Maps\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = 'lightgrey')\nplot(wm_q, coords_hunan, pch = 19, cex = 0.6, add = TRUE, col = 'red', main = 'Queen Contiguity')\nplot(hunan$geometry, border = 'lightgrey')\nplot(wm_r, coords_hunan, pch = 19, cex = 0.6, add = TRUE, col = 'red', main = 'Rook Contiguity')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#computing-distance-based-neighbours",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Computing Distance Based Neighbours",
    "text": "Computing Distance Based Neighbours\nDistance-based weight matrices can be derived using dnearneigh() of spdep.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument.\nIf unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat = TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\nDetermine the Cut-off Distance\nFirst, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of sdpep\nConvert the k nearest neighbour object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb()\nReturn the length of neighbour relationship edges by using nbdist() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords_hunan))\nk1dists &lt;- unlist(nbdists(k1, coords_hunan, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\nComputing Fixed Distance Weight Watrix\ndnearneigh() can be used to compute the distance weight matrix. It will create an object containing the neighbors of a each id based on their distance in km with a lower bound d1=0 and upper bound d2=62\n\nwm_d62 &lt;- dnearneigh(coords_hunan, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nstr() can be used to display the content of wm_d62\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords_hunan, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n\nPlotting Fixed Distance Weight Matrix\nWe can plot the distance weight matrix using the code chunk below\n\nplot(hunan$geometry, border = 'lightgrey')\nplot(wm_d62, coords_hunan, add = TRUE) #add centroids and links between neighbors\nplot(k1, coords_hunan, add = TRUE, col = 'red', length = 0.08) #add red coloration to the nearest neighbor based on distance\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot two separate plots next to each other, one with centroid for each region and the links to all its neighbors, and one with centroid for each region and the link to its 1st nearest neighbor.\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = 'lightgrey')\nplot(k1, coords_hunan, add = TRUE, col = 'red', length = 0.08, main = '1st Nearest Neighbor')\nplot(hunan$geometry, border = 'lightgrey')\nplot(wm_d62, coords_hunan, add = TRUE, pch = 19, cex = 0.6, main = 'Distance Link')\n\n\n\n\n\n\nComputing Adaptive Distance Weight Matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have fewwer neighbours. Having many neighbours smooths the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly by using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry\n\nknn6 &lt;- knn2nb(knearneigh(coords_hunan, k = 6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly we can display the content of the matrix by using str()\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords_hunan, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\nPlotting Distance Based Neighbours\nWe can plot the weight matrix using the code below\n\nplot(hunan$geometry, border = 'lightgrey')\nplot(knn6, coords_hunan, pch = 19, cex = 0.6, add = TRUE, col = 'red')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#weight-based-on-idw",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#weight-based-on-idw",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Weight Based on IDW",
    "text": "Weight Based on IDW\nWe can derive a spatial weight matrix based on the Inversed Distance method\nnbdists() can be used to compute the distances between areas\n\ndist &lt;- nbdists(wm_q, coords_hunan, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/x)\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\nRow-standardised Weights Matrix\nNext, we assign weights to each neighboring polygon.\nEach neighboring polygon will be assigned equal weight (style = “W”). This is accomplished by assigning the fraction of 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values, it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\nFor this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style='W', zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy = TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset. However, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\nWe can use the same method to derive a row standardised distance weight matrix.\n\nrswm_ids &lt;- nb2listw(wm_q, glist = ids, style = 'B', zero.policy = TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\nTo see the weight of the first polygon’s neighbours\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\nWe can see the summary of the weights by using summary()\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#application-of-spatial-weight-matrix",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Application of Spatial Weight Matrix",
    "text": "Application of Spatial Weight Matrix\nIn this section we will create four different spatial lagged variables:\n\nspatial lag with row-standardized weights\nspatial lag as a sum of neighbouring values\nspatial window average\nspatial window sum\n\n\nSpatial Lag with Row-standardized Weights\nWe will compute the average neighbor GDPPC value for each polygon\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecalled in the previous section, we retrieved the GDPPC of these five counties\n\nnb1 &lt;- wm_q[[1]]\nnb1_gdppc &lt;- hunan$GDPPC[nb1]\nnb1_gdppc\n\n[1] 20981 34592 24473 21311 22879\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights?\nFor better comparison, we can try to print both series of values\n\nprint(GDPPC.lag[wm_q[[1]]])\n\n[1] 22724.80 24143.25 27737.50 25093.00 22259.09\n\nprint(nb1_gdppc)\n\n[1] 20981 34592 24473 21311 22879\n\n\nPossible Answer: Most neighbors were adjusted slightly based on their weights, particularly neighbor id 3. This accounts geographical distance into the GDPPC value of each neighbor, accounting for the influence on the value of GDPPC by the values of GDPPC of its neighbours.\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c('NAME_3', 'lag GDPPC')\nhunan &lt;- left_join(hunan,lag.res)\n\nWe can see the new spatial lag GDPPC using head()\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we can plot the GDPPC and spatial lag GDPPC for comparison\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\nSpatial Lag as a Sum of Neighboring Values\nWe can calculate spatial lag a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist= in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbor structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q,\n                       glist = b_weights,\n                       style = 'B')\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c('NAME_3', 'lag_sum GDPPC')\n\nWe can take a glimpse of the newly created data frame\n\nlag.res\n\n          NAME_3 lag_sum GDPPC\n1        Anxiang        124236\n2        Hanshou        113624\n3         Jinshi         96573\n4             Li        110950\n5          Linli        109081\n6         Shimen        106244\n7        Liuyang        174988\n8      Ningxiang        235079\n9      Wangcheng        273907\n10         Anren        256221\n11       Guidong         98013\n12         Jiahe        104050\n13         Linwu        102846\n14       Rucheng         92017\n15       Yizhang        133831\n16      Yongxing        158446\n17        Zixing        141883\n18     Changning        119508\n19      Hengdong        150757\n20       Hengnan        153324\n21      Hengshan        113593\n22       Leiyang        129594\n23        Qidong        142149\n24        Chenxi        100119\n25     Zhongfang         82884\n26       Huitong         74668\n27      Jingzhou         43184\n28        Mayang         99244\n29       Tongdao         46549\n30      Xinhuang         20518\n31          Xupu        140576\n32      Yuanling        121601\n33      Zhijiang         92069\n34 Lengshuijiang         43258\n35    Shuangfeng        144567\n36        Xinhua        132119\n37       Chengbu         51694\n38        Dongan         59024\n39       Dongkou         69349\n40       Longhui         73780\n41      Shaodong         94651\n42       Suining        100680\n43        Wugang         69398\n44       Xinning         52798\n45       Xinshao        140472\n46      Shaoshan        118623\n47    Xiangxiang        180933\n48       Baojing         82798\n49     Fenghuang         83090\n50       Guzhang         97356\n51       Huayuan         59482\n52        Jishou         77334\n53      Longshan         38777\n54          Luxi        111463\n55      Yongshun         74715\n56         Anhua        174391\n57           Nan        150558\n58     Yuanjiang        122144\n59      Jianghua         68012\n60       Lanshan         84575\n61      Ningyuan        143045\n62     Shuangpai         51394\n63       Xintian         98279\n64       Huarong         47671\n65      Linxiang         26360\n66         Miluo        236917\n67     Pingjiang        220631\n68      Xiangyin        185290\n69          Cili         64640\n70       Chaling         70046\n71        Liling        126971\n72       Yanling        144693\n73           You        129404\n74       Zhuzhou        284074\n75       Sangzhi        112268\n76       Yueyang        203611\n77        Qiyang        145238\n78      Taojiang        251536\n79      Shaoyang        108078\n80      Lianyuan        238300\n81     Hongjiang        108870\n82      Hengyang        108085\n83       Guiyang        262835\n84      Changsha        248182\n85       Taoyuan        244850\n86      Xiangtan        404456\n87           Dao         67608\n88     Jiangyong         33860\n\n\nQuestion: Can you understand the meaning of Spatial Lag as a Sum of Neighboring Values?\nAnswer: Instead of using the GDPPC value of the polygon, this method sums the GDPPC values of all of its neighbors\nWe can append the lag_sum GDPPC field into the hunan sf data frame\n\nhunan &lt;- left_join(hunan, lag.res)\n\nNext, we can plot the GDPPC and spatial lag as sum of neighbors GDPPC for comparison\n\ngdppc &lt;- qtm(hunan, 'GDPPC')\nlag_sum_gdppc &lt;- qtm(hunan, 'lag_sum GDPPC')\ntmap_arrange(gdppc, lag_sum_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\nSpatial Window Average\nThe spatial window average uses row-standardized weights and includes the diagonal element, or the self-weight. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nWe can take a good look at the neighbour list of area [1]\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNow, [1] has six neighbours instead of five, including itself.\nNow we can obtain the weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nLastly, we can create the lag variable from our weight structure and GDPPC variable\n\nlag_w_avg_gdppc &lt;- lag.listw(wm_qs, hunan$GDPPC)\n\nlag_w_avg_gdppc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw into a data frame similar to what we have done previously\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c('NAME_3', 'lag_window_avg GDPPC')\n\nNow, we can append this data frame onto the original hunan sf data frame\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial Window Average, kable() is used\n\nhunan %&gt;%\n  select('County', 'lag GDPPC', 'lag_window_avg GDPPC') %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nFinally, we can create two plots in order to compare how lag GDPPC and lag_window_avg GDPPC are plotted\n\nw_avg_gdppc &lt;- qtm(hunan, 'lag_window_avg GDPPC')\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\nSpatial Window Sum\nThe spatial window sum is the counterpart of the window average, but without using row-standardized weights.\nFirst, we create the neighbor list including self\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we can assign binary weights to the neighbour structure that includes the diagonal element similar to what was done in Spatial Lag as a Sum of Neighboring Values.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x+1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nSimilar to Spatial Window Average, [1] now has six neighbours\nNow we can use nb2listw() to assign weight values, which is now binary\n\nb_weights2 &lt;- nb2listw(wm_qs,\n                       glist = b_weights,\n                       style = 'B')\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert this object into a data frame\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c('NAME_3', 'w_sum GDPPC')\n\nNext, we will join it with the original hunan data frame\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select('County', 'lag_sum GDPPC', 'w_sum GDPPC') %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, we can draw plots to compare the two methods: Spatial Lag as a Sum of Neighboring Values and Spatial Window Sum\n\nw_sum_gdppc &lt;- qtm(hunan, 'w_sum GDPPC')\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp = 1, ncol = 2)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "To prepare a choropleth map showing the distribution of passenger trips at planning sub-zone by integrating Passenger Volume by Origin Destination Bus Stops and bus stop data sets downloaded from LTA DataMall and Planning Sub-zone boundary of URA Master Plan 2019 from data.gov.sg."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#the-task",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#the-task",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "To prepare a choropleth map showing the distribution of passenger trips at planning sub-zone by integrating Passenger Volume by Origin Destination Bus Stops and bus stop data sets downloaded from LTA DataMall and Planning Sub-zone boundary of URA Master Plan 2019 from data.gov.sg."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#getting-started",
    "title": "In-Class Exercise 1",
    "section": "Getting Started",
    "text": "Getting Started\nLoading the necessary packages in R:\n\ntmap: for thematic mapping\nsf: for geospatial data handling\ntidyverse: for non-spatial data handling\n\n\npacman::p_load(tmap, tidyverse, sf, knitr)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#importing-the-od-data",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#importing-the-od-data",
    "title": "In-Class Exercise 1",
    "section": "Importing the OD Data",
    "text": "Importing the OD Data\nFirstly we will import the Passenger Volume by Origin Destination Bus Stops data downloaed from LTA DataMall by using read_csv() of readr package\n\n# eval:false\nodbus &lt;- read_csv('data/aspatial/origin_destination_bus_202308.csv')\n\nWe can check the odbus tibble dataframe to explore the data types\n\nglimpse(odbus)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nWe can convert ORIGIN_PT_CODE and DESTINATION_PT_CODE into Factor data, a data type unique to R, in order to speed up sorting\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\nWe can confirm that the data types of ORIGIN_PT_CODE and DESTINATION_PT_CODE using glimpse()\n\nglimpse(odbus)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 44069, 20281, 2…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 17229, 20141, 2…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#extracting-the-study-data",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#extracting-the-study-data",
    "title": "In-Class Exercise 1",
    "section": "Extracting the study data",
    "text": "Extracting the study data\nIf we want to pick out the commuter data between 7 and 9 o clock on weekdays\n\norigin_7_9 &lt;- odbus %&gt;%   filter(DAY_TYPE == 'WEEKDAY') %&gt;%   filter(TIME_PER_HOUR &gt;=7 & TIME_PER_HOUR &lt;=9) %&gt;%   group_by(ORIGIN_PT_CODE)%&gt;%   summarise(TRIPS = sum(TOTAL_TRIPS))\n\nWe can check the data table using the code below\n\nkable(head(origin_7_9))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n1617\n\n\n01013\n813\n\n\n01019\n1620\n\n\n01029\n2383\n\n\n01039\n2727\n\n\n01059\n1415\n\n\n\n\n\nWe will save the output in rds format for future use\n\nwrite_rds(origin_7_9, 'data/rds/origin_7_9.rds')\n\nWe can read the origin7_9.rds into R using the code below\n\norigin_7_9 &lt;- read_rds('data/rds/origin_7_9.rds')"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#working-with-geospatial-data",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#working-with-geospatial-data",
    "title": "In-Class Exercise 1",
    "section": "Working with Geospatial Data",
    "text": "Working with Geospatial Data\nTwo geospatial data will be used in this study:\n\nBusStop: Location of bus stops in the last quarter of 2022\nMPSZ-2019: Master Plan Boundary (No Sea) of Singapore in 2019\n\n\nImporting geospatial data\nWe can import the BusStop shape file into an R simple feature dataframe using st_read()\n\nbusstop &lt;- st_read(dsn = 'data/geospatial',\n                   layer = 'BusStop')\n\nReading layer `BusStop' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nWe can check the structure and data types of the new busstop dataframe using glimpse()\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\nAs the busstop data frame has a CRS of SVY21, we want to transform it into a CRS of SVY21 / Singapore TM (EPSG 3414) using st_transform()\n\nbusstop &lt;- st_transform(busstop, crs = 3414)\n\nWe can next import the Master Plan Sub-zone Boundary 2019 shape file into a simple feature dataframe using st_read()\n\nmpsz &lt;- st_read(dsn = 'data/geospatial',\n                layer = 'MPSZ-2019')\n\nReading layer `MPSZ-2019' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nWe can see that the CRS for the mpsz dataframe is WGS 84 (or EPSG 4326), we want it to be SVY21 (or EPSG 3414). We can do this by using st_transform()\n\nmpsz &lt;- st_transform(mpsz, 3414)\n\nWe can double check the CRS of mpsz using st_geometry(). We can see that the Projected CRS is now SVY21\n\nst_geometry(mpsz)\n\nGeometry set for 332 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#geospatial-data-wrangling",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#geospatial-data-wrangling",
    "title": "In-Class Exercise 1",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\n\nCombining busstop and mpsz\nThis code below populates the planning subzone code (SUBZONE_C) of mpsz data frame into the busstop data frame. st_intersection() is used to perform point and polygon overlap and the output will be in point simple feature object.\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\nWe will save the new data frame into rds format\n\nwrite_rds(busstop_mpsz, 'data/rds/busstop_mpsz.csv')\n\nNext, we are going to append the planning subzone code from busstop_mpsz data frame onto origin_7_9 data frame\n\norigin_data &lt;- left_join(origin_7_9, busstop_mpsz,\n                         by = c('ORIGIN_PT_CODE' = 'BUS_STOP_N')) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C)\n\nIt is good practice to check for duplicate records\n\nduplicate &lt;- origin_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nIf duplicated records are found, the code chunk below will be used to retain only the unique records\n\norigin_data &lt;- unique(origin_data)\n\nWe can re-reun the code chunk to check for duplicate records in the new data frame. We will now see that the duplicate dataframe contains 0 observation.\n\nduplicate &lt;- origin_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nNow, we can append the bus stop code and number of trips starting from that code onto the original mpsz data frame (which contains the geometry information for mapping)\n\nmpsz_origtrip &lt;- left_join(mpsz, origin_data,\n                         by = c('SUBZONE_C' = 'ORIGIN_SZ'))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#choropleth-visualization",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#choropleth-visualization",
    "title": "In-Class Exercise 1",
    "section": "Choropleth Visualization",
    "text": "Choropleth Visualization\nTo create a choropleth visualization, we can using the tmap package\n\ntm_shape(mpsz_origtrip)+\n  tm_fill('TRIPS',\n          n = 6,\n          style = 'quantile',\n          palette = 'Blues')+\n  tm_layout(main.title = 'Passenger Trips Generated at Planning Sub-zone Level',\n            main.title.position = 'center',\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = '8star', size = 2)+\n  tm_scale_bar()+\n  tm_grid(alpha = 0.2)+\n  tm_credits('Source: Planning Sub-zone Boundary from Urban Redevelopment Authority (URA) \\n and Population Data from Department of Statistics (DOS)',\n             position = c('left','bottom'))\n\n\n\n\nWe can use a map using custom breaks for comparison. Before that, we can use the summary function to determine appropriate breakpoints\n\nsummary(mpsz_origtrip$TRIPS)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n     1.0    386.5   1773.0   4191.5   5002.0 295128.0       21 \n\n\nThen, we can draw the map using the tmap package\n\ntm_shape(mpsz_origtrip)+\n  tm_fill('TRIPS',\n          breaks = c(0, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000),\n          palette = 'Blues')+\n  tm_layout(main.title = 'Passenger Trips Generated at Planning Sub-zone Level',\n            main.title.position = 'center',\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = '8star', size = 2)+\n  tm_scale_bar()+\n  tm_grid(alpha = 0.2)+\n  tm_credits('Source: Planning Sub-zone Boundary from Urban Redevelopment Authority (URA) \\n and Population Data from Department of Statistics (DOS)',\n             position = c('left','bottom'))\n\n\n\n\nIt can be seen that due to the large variations in number of trips between different planning sub-zones, the custom breaks are not as insightful as the ‘quantile’ style built into tmap."
  }
]