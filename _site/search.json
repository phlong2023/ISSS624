[
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#getting-started",
    "href": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#getting-started",
    "title": "Take-Home_Ex2",
    "section": "Getting Started",
    "text": "Getting Started\nFirst, the necessary R packages will be loaded using the p_load() function of the pacman package. p_load() will also install any package which is not already installed. The following packages will be loaded:\n\nsf: For handling of geospatial data.\nsfdep: For determining the spatial dependence of spatial features. The three main categories of functionality relates to the determination of geometry neighbors, weights, and LISA.\ntidyverse: For manipulation of non-spatial data. This package contains ggplot2 for plotting, dplyr and tidyr for dataframe manipulation, and readr for reading comma-separated values (CSV).\ntmap: For thematic mapping, especially the mapping of simple features data frame.\nspdep: For drawing Moran scatterplot.\n\n\npacman::p_load(tmap, sf, sp, DT, performance, reshape2, ggpubr, units, tidyverse, sfdep, stplanr)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#defining-the-desired-time-frame",
    "href": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#defining-the-desired-time-frame",
    "title": "Take-Home_Ex2",
    "section": "Defining the Desired Time Frame",
    "text": "Defining the Desired Time Frame\nThere are four time windows of transit behaviour which can be considered:\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nThis study will focus on the Weekend/holiday Morning Peak 11am - 2pm. This would allow the study to focus on the transit flow of Singapore residents during a period of rest and relaxation, leading to recommendations to improve the attractiveness of dining, leisure, retail, and entertainment destinations in Singapore."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#importing-required-data",
    "href": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#importing-required-data",
    "title": "Take-Home_Ex2",
    "section": "Importing Required Data",
    "text": "Importing Required Data\nFor the purpose of this study, two types of data will be used: geospatial data which consists of spatial features and their coordinates information, and aspatial data which consists of attributes which can be ascribed to the geospatial data. Specifically, the following datasets will be used for each type:\n\nGeospatial Data:\n\nBusStop.shp: This shape file contains the locations of the bus stops in Singapore as at July 2023. This file can be retrieved from the Land Transport Authority (LTA) Data Mall (link). They are stored as points.\nRapidTransitSystemStation.shp: This shape file contains the locations of all Mass Rapid Transit (MRT) and Light Rail Transit (LRT) stations in Singapore in polygon shapes.\nTrain_Station_Exit_Layer.shp: This shape file contains the exit points of all MRT and LRT stations in Singapore. They are stored as points.\nentertn.shp: This shape file contains the locations of entertainment venues in Singapore such as cinemas and theatres. They are stored as points.\nF&B.shp: This shape file contains the locations of Food & Beverage venues in Singapore such as restaurants and cafes. They are stored as points.\nFinServ.shp: This shape file contains the locations of Financial Services in Singapore such ATMs, money changers, and banks. They are stored as points.\nLiesure&Recreation.shp: This shape file contains the locations of Leisure and Recreation venues in Singapore such as sport venues, museums, and galleries. They are stored as points.\nRetails.shp: This shape file contains the locations of Retail venues in Singapore, including all shops which might not fall under other categories. They are stored as points.\n\nAspatial Data:\n\norigin_destination_bus_202309.csv: This CSV file contains the detail of bus trips from an originating bus stop to a destination bus stop, identified by their unique codes, each hour of the day during September 2023. The data is further broken down into weekend or weekday, but not by the specific day of the week. This data can be retrieved by using the LTA Data Mall’s API (link).\nhdb.csv: This CSV file contains the details of different HDB blocks in Singapore, including the number of dwelling units and their types. More importantly, it also consists of the longitudes and latitudes of the HDB blocks, which would allow us to create a sf data frame and treat the information as a spatial object.\n\n\nThe first steps taken will be to import these files into the R environment in a manipulable format.\n\nImporting Geospatial Data\nGeospatial data can be imported using the st_read() function of the sf package. This will import the file into the R environment as a sf (simple features) data frame. st_transform() can be added to transform the Coordinate Reference System (CRS) to EPSG: 3414, which is the CRS of Singapore.\n\n\n\n\n\n\nNote\n\n\n\nIn st_read():\n\ndsn: the directory where the shape file is stored\nlayer: the name of the shape file\n\n\n\n\nMaster Planning Sub-Zone 2019\n\n\n\n\n\n\nImportant\n\n\n\nEven though the study’s analysis layer is based on hexagon cells, by importing the Master Planning Sub-Zone 2019 file, other point layers such as Retail and Leisure can be contextualized onto the map of Singapore. This will allows for the visualization of their locations in different planning sub-zones of Singapore.\n\n\n\nmpsz &lt;- st_read(dsn = 'data/geospatial',\n                layer = 'MPSZ-2019') %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nglimpse(mpsz)\n\nRows: 332\nColumns: 7\n$ SUBZONE_N  &lt;chr&gt; \"MARINA EAST\", \"INSTITUTION HILL\", \"ROBERTSON QUAY\", \"JURON…\n$ SUBZONE_C  &lt;chr&gt; \"MESZ01\", \"RVSZ05\", \"SRSZ01\", \"WISZ01\", \"MUSZ02\", \"MPSZ05\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA EAST\", \"RIVER VALLEY\", \"SINGAPORE RIVER\", \"WESTERN …\n$ PLN_AREA_C &lt;chr&gt; \"ME\", \"RV\", \"SR\", \"WI\", \"MU\", \"MP\", \"WI\", \"WI\", \"SI\", \"SI\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"WEST…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"WR\", \"CR\", \"CR\", \"WR\", \"WR\", \"CR\", \"CR\",…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((33222.98 29..., MULTIPOLYGON (…\n\n\nThe data type for each column can be seen as well as some of their values. For sf data frames, there is a geometry column (MULTIPOLYGON type) which contains the location information for each polygon.\nAdditionally, mpsz can be visualized in order to spot any anomaly. This can be done using the qtm() function in the tmap package for quick plotting.\n\ntm_shape(mpsz)+\n  tm_polygons(col = 'white')\n\n\n\n\n\n\nBus Stop\nThe steps used to import and examine the mpsz data frame can be repeated for the busstop data frame.\n\nbusstop &lt;- st_read(dsn = 'data/geospatial',\n                   layer = 'BusStop') %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\nAdditionally, busstop can be visualized in order to spot any anomaly. This can be done using the tm_shape() function in the tmap package for quick plotting.\n\n\n\n\n\n\nNote\n\n\n\nA separate tm_shape() argument can be used to add the mpsz object as a layer on which the bus stops can be visualized. This will allow for the contextualization of bus stop locations on Singapore map.\n\n\n\ntm_shape(mpsz)+\n  tm_polygons(col = 'white')+\n  tm_shape(busstop)+\n  tm_dots(col = 'red')\n\n\n\n\nThe visualization shows us that there are four bus stops in Malaysia. Let’s remove them so that only bus stops in Singapore will be considered. This is because these special bus stops might exhibit different behaviors due to their different context from the rest of the bus stops in Singapore.\nfilter() can be used in conjunction with a dplyr step to remove these bus stops.\n\nbusstop &lt;- busstop %&gt;%   filter(!BUS_STOP_N %in% c('46609','47701', '46211', '46219', '46239'))\n\ntm_shape() can be used again to check that the bus stops have been removed.\n\ntm_shape(mpsz)+\n  tm_polygons(col = 'white')+\n  tm_shape(busstop)+\n  tm_dots(col = 'red')\n\n\n\n\n\n\nEntertainment\nA similar procedures can be done to glimpse and map the information in the other sf data frames.\n\nEntertainment &lt;- st_read(dsn = 'data/geospatial',\n            layer = 'entertn')\n\nReading layer `entertn' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 114 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 10809.34 ymin: 26528.63 xmax: 41600.62 ymax: 46375.77\nProjected CRS: SVY21 / Singapore TM\n\nglimpse(Entertainment)\n\nRows: 114\nColumns: 4\n$ POI_NAME   &lt;chr&gt; \"TP AUDITORIUM\", \"NP CONVENTION CENTRE\", \"SP AUDITORIUM\", \"…\n$ POI_ST_NUM &lt;chr&gt; NA, NA, NA, \"1\", \"350\", NA, \"201\", NA, \"83\", \"328\", NA, \"5\"…\n$ POI_ST_NAM &lt;chr&gt; NA, NA, NA, \"FULLERTON SQ\", \"BALESTIER RD\", \"TRENGGANU ST\",…\n$ geometry   &lt;POINT [m]&gt; POINT (39115.71 36392.13), POINT (21533.12 34921.34),…\n\n\nAs can be seen, venues such as galleries, theatres, and cinemas are included in the Entertainment data frame. This sf data frame has already been projected to ‘SVY21 / Singapore TM’ and does not need further transformation.\n\ntm_shape(mpsz)+\n  tm_polygons(col = 'white')+\n  tm_shape(Entertainment)+\n  tm_dots(col = 'red')\n\n\n\n\n\n\nFood and Beverage (F&B)\n\nFoodBev &lt;- st_read(dsn = 'data/geospatial',\n            layer = 'F&B')\n\nReading layer `F&B' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1919 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 6010.495 ymin: 25343.27 xmax: 45462.43 ymax: 48796.21\nProjected CRS: SVY21 / Singapore TM\n\nglimpse(FoodBev)\n\nRows: 1,919\nColumns: 4\n$ POI_NAME   &lt;chr&gt; \"KHEL\", \"I PUB\", \"LARK LOUNGE & NITE-CLUB\", \"CHAKRAVARTHY\",…\n$ POI_ST_NUM &lt;chr&gt; \"141\", \"14\", \"195\", \"195\", \"48\", \"36\", \"10\", \"697\", \"11\", \"…\n$ POI_ST_NAM &lt;chr&gt; \"KITCHENER RD\", \"CHUN TIN RD\", \"LAVENDER ST\", \"LAVENDER ST\"…\n$ geometry   &lt;POINT [m]&gt; POINT (30654.44 32466.51), POINT (21515.34 36007.18),…\n\n\nAs can be seen, venues such as pubs, restaurants, and cafes are included in the FoodBev data frame. This sf data frame has already been projected to ‘SVY21 / Singapore TM’ and does not need further transformation.\n\ntm_shape(mpsz)+\n  tm_polygons(col = 'white')+\n  tm_shape(FoodBev)+\n  tm_dots(col = 'red')\n\n\n\n\n\n\nFinancial Services\n\nFinServ &lt;- st_read(dsn = 'data/geospatial',\n            layer = 'FinServ')\n\nReading layer `FinServ' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3320 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4881.527 ymin: 25171.88 xmax: 46526.16 ymax: 49338.02\nProjected CRS: SVY21 / Singapore TM\n\nglimpse(FinServ)\n\nRows: 3,320\nColumns: 4\n$ POI_NAME   &lt;chr&gt; \"UOB\", \"POSB\", \"UOB\", \"OCBC\", \"OCBC\", \"MAYBANK\", \"ADPOST MO…\n$ POI_ST_NUM &lt;chr&gt; \"201\", \"375\", \"375\", \"375\", NA, \"707\", \"163\", NA, \"11\", NA,…\n$ POI_ST_NAM &lt;chr&gt; \"YISHUN AVE 2\", \"COMMONWEALTH AVE\", \"COMMONWEALTH AVE\", \"CO…\n$ geometry   &lt;POINT [m]&gt; POINT (27966.77 44304.65), POINT (24163.96 31606.25),…\n\n\nAs can be seen, venues such as bank branches, moneychangers, and ATMs are included in the FinServ data frame. This sf data frame has already been projected to ‘SVY21 / Singapore TM’ and does not need further transformation.\n\ntm_shape(mpsz)+\n  tm_polygons(col = 'white')+\n  tm_shape(FinServ)+\n  tm_dots(col = 'red')\n\n\n\n\n\n\nLeisure\n\nLeisure &lt;- st_read(dsn = 'data/geospatial',\n            layer = 'Liesure&Recreation')\n\nReading layer `Liesure&Recreation' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1217 features and 30 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 6010.495 ymin: 25134.28 xmax: 48439.77 ymax: 50078.88\nProjected CRS: SVY21 / Singapore TM\n\nglimpse(Leisure)\n\nRows: 1,217\nColumns: 31\n$ LINK_ID    &lt;dbl&gt; 914885888, 1046871091, 845355245, 940657500, 940657500, 941…\n$ POI_ID     &lt;dbl&gt; 1192316147, 1132324271, 1132324254, 1110521716, 1110521715,…\n$ SEQ_NUM    &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ FAC_TYPE   &lt;int&gt; 8410, 7997, 7997, 7997, 7997, 8410, 7997, 7997, 7997, 7997,…\n$ POI_NAME   &lt;chr&gt; \"NIE ART GALLERY\", \"ASPIRE CONCEPT\", \"SOCCERPUNTER\", \"ANAND…\n$ POI_LANGCD &lt;chr&gt; \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"EN…\n$ POI_NMTYPE &lt;chr&gt; \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"B\", \"J\", \"B\", \"B\", \"B\", \"B\",…\n$ POI_ST_NUM &lt;chr&gt; NA, \"883\", \"14\", \"1\", \"1\", \"39\", NA, NA, \"108\", \"11\", \"11\",…\n$ ST_NUM_FUL &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"169A\", NA, NA,…\n$ ST_NFUL_LC &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, \"ENG\", NA, NA, …\n$ ST_NAME    &lt;chr&gt; \"NANYANG CRES\", \"NORTH BRIDGE RD\", \"ROBINSON RD\", \"MARINE P…\n$ ST_LANGCD  &lt;chr&gt; \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", \"ENG\", NA, NA, \"ENG\", \"E…\n$ POI_ST_SD  &lt;chr&gt; \"R\", \"L\", \"L\", \"R\", \"R\", \"L\", \"R\", \"R\", \"L\", \"L\", \"L\", \"R\",…\n$ ACC_TYPE   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ PH_NUMBER  &lt;chr&gt; NA, \"66347769\", NA, NA, \"63446164\", \"63327591\", \"67659324\",…\n$ CHAIN_ID   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ NAT_IMPORT &lt;chr&gt; \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ PRIVATE    &lt;chr&gt; \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ IN_VICIN   &lt;chr&gt; \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\", \"N\",…\n$ NUM_PARENT &lt;int&gt; 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0, 0, 0, 0,…\n$ NUM_CHILD  &lt;int&gt; 0, 0, 0, 0, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,…\n$ PERCFRREF  &lt;int&gt; NA, NA, NA, 43, 43, 51, 40, 40, NA, NA, 40, 99, 59, 15, NA,…\n$ VANCITY_ID &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ ACT_ADDR   &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"1 CHOA CHU KANG STREET 53         …\n$ ACT_LANGCD &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"ENG\", \"ENG\", NA, NA, NA, NA, NA, N…\n$ ACT_ST_NAM &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"CHOA CHU KANG STREET 53\", \"CHOA CH…\n$ ACT_ST_NUM &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"1\", \"1\", NA, NA, NA, NA, NA, NA, N…\n$ ACT_ADMIN  &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"SINGAPORE\", \"SINGAPORE\", NA, NA, N…\n$ ACT_POSTAL &lt;chr&gt; NA, NA, NA, NA, NA, NA, \"689236\", \"689236\", NA, NA, NA, NA,…\n$ ENTR_TYPE  &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ geometry   &lt;POINT [m]&gt; POINT (10664.66 36585.97), POINT (31490.24 32040.81),…\n\n\nAs can be seen, venues such as museums, sport activities, and parks are included in the Leisure data frame. This sf data frame has already been projected to ‘SVY21 / Singapore TM’ and does not need further transformation. However, this data frame contains too many variables which might not be used. In order to standardize it to other data frames, the select() function can be used.\n\n\n\n\n\n\nNote\n\n\n\nThe Leisure data frame contains a variable named “ST_NAME” which is the street name of the venue. This can be renamed to “POI_ST_NAM” to standardize it to other data frames. “POI_ST_NAM” refers to the street name of the point polygon, which might differ slightly to “ST_NAME”, but not meaningfully so.\nrename() can be used to perform this operation.\n\n\n\nLeisure &lt;- Leisure %&gt;%\n  select(POI_NAME, POI_ST_NUM, ST_NAME, geometry) %&gt;%\n  rename(POI_ST_NAM = ST_NAME)\n\nglimpse(Leisure)\n\nRows: 1,217\nColumns: 4\n$ POI_NAME   &lt;chr&gt; \"NIE ART GALLERY\", \"ASPIRE CONCEPT\", \"SOCCERPUNTER\", \"ANAND…\n$ POI_ST_NUM &lt;chr&gt; NA, \"883\", \"14\", \"1\", \"1\", \"39\", NA, NA, \"108\", \"11\", \"11\",…\n$ POI_ST_NAM &lt;chr&gt; \"NANYANG CRES\", \"NORTH BRIDGE RD\", \"ROBINSON RD\", \"MARINE P…\n$ geometry   &lt;POINT [m]&gt; POINT (10664.66 36585.97), POINT (31490.24 32040.81),…\n\n\n\ntm_shape(mpsz)+\n  tm_polygons(col = 'white')+\n  tm_shape(Leisure)+\n  tm_dots(col = 'red')\n\n\n\n\n\n\nRetails\n\nRetails &lt;- st_read(dsn = 'data/geospatial',\n            layer = 'Retails')\n\nReading layer `Retails' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 37635 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4737.982 ymin: 25171.88 xmax: 48265.04 ymax: 50135.28\nProjected CRS: SVY21 / Singapore TM\n\nglimpse(Retails)\n\nRows: 37,635\nColumns: 4\n$ POI_NAME   &lt;chr&gt; \"TIAN KEE & CO\", \"PEOPLE TRADITIONAL CHINESE MEDICAL\", \"RIV…\n$ POI_ST_NUM &lt;chr&gt; \"12\", \"12\", NA, NA, \"588\", \"243\", \"208\", \"267\", \"231\", \"158…\n$ POI_ST_NAM &lt;chr&gt; \"DAKOTA CRES\", \"DAKOTA CRES\", NA, NA, \"SERANGOON RD\", \"ALEX…\n$ geometry   &lt;POINT [m]&gt; POINT (33713.83 32023.15), POINT (33713.83 32023.15),…\n\n\nAs can be seen, venues such as bank pharmacy, gift shops, and other general and specialized stores are included in the Retails data frame. This sf data frame has already been projected to ‘SVY21 / Singapore TM’ and does not need further transformation.\n\ntm_shape(mpsz)+\n  tm_polygons(col = 'white')+\n  tm_shape(Retails)+\n  tm_dots(col = 'red')\n\n\n\n\n\n\nTrain Station and Station Exits\n\ntrainstation &lt;- st_read(dsn = 'data/geospatial',\n                        layer = 'RapidTransitSystemStation')\n\nReading layer `RapidTransitSystemStation' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 220 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 6068.209 ymin: 27478.44 xmax: 45377.5 ymax: 47913.58\nProjected CRS: SVY21\n\n# trainstation &lt;- trainstation %&gt;%\n#   filter(st_is_valid(.))\n\nglimpse(trainstation)\n\nRows: 220\nColumns: 5\n$ TYP_CD     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ STN_NAM    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ TYP_CD_DES &lt;chr&gt; \"MRT\", \"MRT\", \"MRT\", \"MRT\", \"MRT\", \"LRT\", \"MRT\", \"MRT\", \"LR…\n$ STN_NAM_DE &lt;chr&gt; \"ESPLANADE MRT STATION\", \"PAYA LEBAR MRT STATION\", \"DHOBY G…\n$ geometry   &lt;POLYGON [m]&gt; POLYGON ((30566.07 30621.21..., POLYGON ((34495.6 3…\n\n\nAs can be seen, trainstation data frame contains the that type of stations, their names, and their geometry in polygon shape. However, there is a warning message that there are non-closed ring, which indicates that some polygons are not whole in that their start point and their end point are not the same. This can be addressed by fixing the non-closed polygon using st_make_valid() or by filtering them out of the data frame using st_is_valid() and filter(). For this study, These polygons will be removed as contextual information on why they are non-closed is missing.\nAdditionally, the projected CRS is SVY21, and requires transformation to SVY21/Singapore TM using st_transform().\n\ntrainstation &lt;- trainstation %&gt;%\n  filter(st_is_valid(.)) %&gt;%\n  st_transform(crs = 3414)\n\nglimpse(trainstation)\n\nRows: 217\nColumns: 5\n$ TYP_CD     &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ STN_NAM    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,…\n$ TYP_CD_DES &lt;chr&gt; \"MRT\", \"MRT\", \"MRT\", \"MRT\", \"MRT\", \"LRT\", \"MRT\", \"MRT\", \"LR…\n$ STN_NAM_DE &lt;chr&gt; \"ESPLANADE MRT STATION\", \"PAYA LEBAR MRT STATION\", \"DHOBY G…\n$ geometry   &lt;POLYGON [m]&gt; POLYGON ((30566.07 30621.21..., POLYGON ((34495.6 3…\n\nst_crs(trainstation)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nAfter the transformation, 3 features have been removed and the projected CRS is now SVY21/Singapore TM.\nBefore visualizing the trainstation, the train exit points can be imported so that they can be visualized together due to their inherently connected nature.\n\ntrainexit &lt;- st_read(dsn = 'data/geospatial',\n                     layer = 'Train_Station_Exit_Layer')\n\nReading layer `Train_Station_Exit_Layer' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 565 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 6134.086 ymin: 27499.7 xmax: 45356.36 ymax: 47865.92\nProjected CRS: SVY21\n\nglimpse(trainexit)\n\nRows: 565\nColumns: 3\n$ stn_name  &lt;chr&gt; \"MACPHERSON MRT STATION\", \"MACPHERSON MRT STATION\", \"MACPHER…\n$ exit_code &lt;chr&gt; \"Exit A\", \"Exit B\", \"Exit C\", \"Exit B\", \"Exit A\", \"Exit A\", …\n$ geometry  &lt;POINT [m]&gt; POINT (34285.07 34322.99), POINT (34382.15 34231.9), P…\n\n\nThe train exit data frame consists of each MRT and LRT stations and the point geometry of all of their exits. However, its projected CRS is SVY21, which should be transformed into SVY21/Singapore TM using st_transform().\n\ntrainexit &lt;- trainexit %&gt;%\n  st_transform(crs = 3414)\n\nst_crs(trainexit)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNow, both trainstation and trainexit can be visualized together using the tmap package.\n\n\n\n\n\n\nNote\n\n\n\nDue to the smaller size of the train station polygons, it will be difficult to see them on a static map. tmap_mode(‘view’) can be used to create an interactive map which would allow for zoom.\nSome helpful functions can be used to create a better interactive map:\n\ntmap_options(check.and.fix = TRUE): Even though our data frames do not contain any broken polygons, this argument can still be added in order to close any non-closed polygons.\ntm_view(set.zoom.limits = c(11,14)): This option is added to limit the zoom level of the map, preventing user from zooming in too close or zooming out too far. 11 indicates the minimum zoom level while 14 indicates the maximum zoom level.\ntmap_mode(‘plot’): This function is added to return the tmap_mode to plotting mode for later code chunks. This will ensure that the next code chunk is the lighter, static plot rather than an interactive plot by default.\n\n\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode('view')\n\ntm_shape(mpsz)+\n  tm_polygons(alpha = 0.5)+\n  tm_shape(trainstation)+\n  tm_fill(col = 'blue',\n          id = 'STN_NAM_DE')+\n  tm_shape(trainexit)+\n  tm_dots(col = 'red',\n          id = 'exit_code')+\n  tm_view(set.zoom.limits = c(11,16))\n\n\n\n\n\ntmap_mode('plot')\n\nThere are two immediate issues which emerge by looking at the visualization:\n\nThe trainstation data frame contains the locations of train depots such as the Mandai Depot and the Ulu Pandan Depot, which are not accessible to commuters.\nThe trainstation data frame contains the locations of train stations which are not in operation such as the Bukit Brown MRT Station and the Mount Pleasant MRT Station, and, therefore, are not accessible to commuters and have no exit.\n\nIt is possible to resolve both of these issues by only retaining the train stations which are listed in the trainexit data frame using the %in% argument and filter().\n\ntrainstation &lt;- trainstation %&gt;%\n  filter(trainstation$STN_NAM_DE %in% trainexit$stn_name)\n\nEighteen stations have been removed from the trainstation dataset, the visualization can be recreated to confirm whether only commuter-accessible train station remains.\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode('view')\n\ntm_shape(mpsz)+\n  tm_polygons(alpha = 0.5)+\n  tm_shape(trainstation)+\n  tm_fill(col = 'blue',\n          id = 'STN_NAM_DE')+\n  tm_shape(trainexit)+\n  tm_dots(col = 'red',\n          id = 'exit_code')+\n  tm_view(set.zoom.limits = c(11,16))\n\n\n\n\n\n\n\n\n\nImporting Aspatial Data\n\nPassenger\nThe read_csv() function of readr can be used to import the origin_destination_bus_202309 CSV file into the R environment as a data frame.\n\npassenger &lt;- read_csv('data/aspatial/origin_destination_bus_202309.csv')\n\nFrom the message provided by R, it can be seen that the passenger has 5,714,196 rows and 7 columns.\nhead() can be used instead of glimpse() to view the top five rows of the passenger data frame. This will also allow us to see the data type of each of the column.\n\nhead(passenger)\n\n# A tibble: 6 × 7\n  YEAR_MONTH DAY_TYPE   TIME_PER_HOUR PT_TYPE ORIGIN_PT_CODE DESTINATION_PT_CODE\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;              \n1 2023-09    WEEKENDS/…            17 BUS     24499          22221              \n2 2023-09    WEEKENDS/…            10 BUS     65239          65159              \n3 2023-09    WEEKDAY               10 BUS     65239          65159              \n4 2023-09    WEEKDAY                7 BUS     23519          23311              \n5 2023-09    WEEKENDS/…             7 BUS     23519          23311              \n6 2023-09    WEEKENDS/…            11 BUS     52509          42041              \n# ℹ 1 more variable: TOTAL_TRIPS &lt;dbl&gt;\n\n\nNote that the ORIGIN_PT_CODE and DESTINATION_PT_CODE are in the character (“chr”) data type. However, we would like it to be in the factor (“fctr”) data type for easier categorization and sorting. This can be done by using the as.factor() function.\n\npassenger$ORIGIN_PT_CODE &lt;- as.factor(passenger$ORIGIN_PT_CODE)\npassenger$DESTINATION_PT_CODE &lt;- as.factor(passenger$DESTINATION_PT_CODE)\n\nWe can use head() to check the data type of the passenger data frame.\n\nhead(passenger)\n\n# A tibble: 6 × 7\n  YEAR_MONTH DAY_TYPE   TIME_PER_HOUR PT_TYPE ORIGIN_PT_CODE DESTINATION_PT_CODE\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;   &lt;fct&gt;          &lt;fct&gt;              \n1 2023-09    WEEKENDS/…            17 BUS     24499          22221              \n2 2023-09    WEEKENDS/…            10 BUS     65239          65159              \n3 2023-09    WEEKDAY               10 BUS     65239          65159              \n4 2023-09    WEEKDAY                7 BUS     23519          23311              \n5 2023-09    WEEKENDS/…             7 BUS     23519          23311              \n6 2023-09    WEEKENDS/…            11 BUS     52509          42041              \n# ℹ 1 more variable: TOTAL_TRIPS &lt;dbl&gt;\n\n\n\n\nHousing Development Board (HDB)\nSimilarly, the hdb.csv data can be imported using similar methods\n\nhdb &lt;- read_csv('data/aspatial/hdb.csv')\n\nhead(hdb)\n\n# A tibble: 6 × 37\n   ...1 blk_no street        max_floor_lvl year_completed residential commercial\n  &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;                 &lt;dbl&gt;          &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;     \n1     0 1      BEACH RD                 16           1970 Y           Y         \n2     1 1      BEDOK STH AV…            14           1975 Y           N         \n3     2 1      CANTONMENT RD             2           2010 N           Y         \n4     3 1      CHAI CHEE RD             15           1982 Y           N         \n5     4 1      CHANGI VILLA…             4           1975 Y           Y         \n6     5 1      DELTA AVE                25           1982 Y           N         \n# ℹ 30 more variables: market_hawker &lt;chr&gt;, miscellaneous &lt;chr&gt;,\n#   multistorey_carpark &lt;chr&gt;, precinct_pavilion &lt;chr&gt;,\n#   bldg_contract_town &lt;chr&gt;, total_dwelling_units &lt;dbl&gt;, `1room_sold` &lt;dbl&gt;,\n#   `2room_sold` &lt;dbl&gt;, `3room_sold` &lt;dbl&gt;, `4room_sold` &lt;dbl&gt;,\n#   `5room_sold` &lt;dbl&gt;, exec_sold &lt;dbl&gt;, multigen_sold &lt;dbl&gt;,\n#   studio_apartment_sold &lt;dbl&gt;, `1room_rental` &lt;dbl&gt;, `2room_rental` &lt;dbl&gt;,\n#   `3room_rental` &lt;dbl&gt;, other_room_rental &lt;dbl&gt;, lat &lt;dbl&gt;, lng &lt;dbl&gt;, …\n\n\nAs can be seen, the block number, street name, year completed, and many other types of information are included in the hdb data frame for each hdb block.\nUnlike passenger, however, the hdb csv file has a column which indicates the longitude and latitude of the each HDB block. This means that it can be visualized using tm_shape().\n\nhdb_sf &lt;- hdb %&gt;%\n  st_as_sf(coords = c('lng','lat'),\n           crs = 4326) %&gt;%\n  st_transform(3414)\n\ntm_shape(mpsz)+\n  tm_polygons(col = 'white')+\n  tm_shape(hdb_sf)+\n  tm_dots(col = 'red')"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#data-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#data-preparation",
    "title": "Take-Home_Ex2",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nWrangling Aspatial Data\n\nFiltering the passenger Data Set for Desired Time Frames\nFor the purpose of this study, the passenger data set needs to be filtered to only contain trips falling within one of the desired time frame: Weekend/Holiday Morning Peak 11am - 2pm (11:00 - 14:00).\nThis can be accomplished using the filter() function and the dplyr pipe (%&gt;%).\n\npassenger&lt;- passenger %&gt;%   filter(DAY_TYPE == 'WEEKENDS/HOLIDAY') %&gt;%   filter(TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14)  \n\nAdditionally, the passenger data set should also be filtered for those bus stops which have been filtered out of the busstop data frame due to them being in Malaysia.\n\n\n\n\n\n\nWarning\n\n\n\nThis step is a limitation of this study as there would be major transit flow between Singapore and Johor Bahru during the weekend and holiday. However, as there is no information on the attractiveness of Malaysia (number of retail locations, F&B, etc.), it is not appropriate to include them in this analysis.\n\n\n\npassenger &lt;- passenger %&gt;%\n  filter(!(ORIGIN_PT_CODE %in% c('46609','47701', '46211', '46219', '46239'))) %&gt;%\n  filter(!(DESTINATION_PT_CODE %in% c('46609','47701', '46211', '46219', '46239')))\n\n\n\nTallying Number of Trips by Origin and Destination Bus Stops\nAfter the different trips have been categorized into their separate data frames, the total number trips for each origin bus stop can be tallied into a single statistic for the study period. This can be accomplished using the summarize() function.\n\n\n\n\n\n\nNote\n\n\n\nThe group_by() function is used to instruct R to conduct operations based on the groups created by group_by(). In this case, the summary operations will be done based on the origin bus stop codes.\n\n\n\npassenger_tallied &lt;- passenger %&gt;%\n  group_by(ORIGIN_PT_CODE, DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\npassenger_tallied\n\n# A tibble: 227,837 × 3\n# Groups:   ORIGIN_PT_CODE [5,012]\n   ORIGIN_PT_CODE DESTINATION_PT_CODE TRIPS\n   &lt;fct&gt;          &lt;fct&gt;               &lt;dbl&gt;\n 1 01012          01112                 250\n 2 01012          01113                 175\n 3 01012          01121                 128\n 4 01012          01211                 140\n 5 01012          01311                 266\n 6 01012          01411                   2\n 7 01012          01421                   2\n 8 01012          01549                  10\n 9 01012          01559                   1\n10 01012          07371                  19\n# ℹ 227,827 more rows\n\n\nIt is possible to visualize the distribution of trips by using creating a histogram using the geom_histogram() of the ggplot2 package.\n\nggplot(passenger_tallied, aes(x=TRIPS))+\n  geom_histogram()+\n  theme_classic()\n\n\n\n\nLet’s confirm the distribution by checking the descriptive statistics of the number of trips based on the origin and destination bus stop. This can be done using the summary() function.\n\nsummary(passenger_tallied$TRIPS)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n    1.00     2.00     7.00    37.08    22.00 17107.00 \n\n\nIt can be seen that the distribution of trip is heavily skewed with large outliers. Many flows (origin-destination pair) have very few trips, while some outlier flows have a very large number of trips. This is an indication that there might be spatial autocorrelation, that the number of trips depend on the location of the bus stops. However, there might also be spatial interaction, with certain propulsive and attractiveness factors influencing the number of trips between the origin and destination.\n\n\n\nWrangling Geospatial Data\nIn order to adequately visualize the busstop sf data frame, we need to define a mapping layer. An example of a mapping layer would be to use the Master Plan 2019 Planning Sub-zone created by the Urban Redevelopment Authority (URA). However, for the purpose of this study, a hexagon layer will be used to ensure standardization of the size of each polygon and the evenly spaced gaps between a polygon and its neighbors.\nThe steps in this section will detail the creation of the hexagon layer using the busstop data frame and visualize the layer on a map of Singapore.\n\nCreating a Hexagon Layer in R\nThe steps taken in this section is based on the guide provided by Kenneth Wong of Urban Data Palette (link).\nFirstly, a hexagon or honeycomb grid can be created based on the busstop data frame using the st_make_grid() function.\n\n\n\n\n\n\nNote\n\n\n\nThere are some notable arguments in the st_make_grid() function:\n\ncellsize = c(750,750): This argument indicates the size of each hexagon, calculated as the distance between opposite edges. If the cell size is large, each hexagon can encompasses multiple bus stops, whereas if a smaller cell size can help us differentiate between individual bus stop. However, a smaller cell size with many hexagons will take more time to create. For this study, hexagons of 375m (this distance is the perpendicular distance between the centre of the hexagon and its edges) will be created with the parameter of 750.\nwhat = ‘polygons’: We would like to create polygons on a grid.\nsquare = FALSE: The default argument is TRUE, which would create a square grid. FALSE is specified in order to create a hexagon grid.\n\n\n\n\narea_honeycomb_grid = st_make_grid(busstop, cellsize = c(750,750), what = 'polygons', square = FALSE)\n\narea_honeycomb_grid\n\nGeometry set for 2299 features \nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3220.122 ymin: 26049.09 xmax: 48970.12 ymax: 50947.32\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nThe area_honeycomb_grid contains 136906 features of the same Projected CRS as the busstop data frame. If the plot() function is used, the hexagon grid will be displayed. It will show a large hexagon grid overlaid over the map of Singapore.\n\ntmap_mode('plot')\ntm_shape(mpsz)+\n  tm_polygons()+\n  tm_shape(area_honeycomb_grid)+\n  tm_polygons()\n\n\n\n\nThe area_honey_comb needs to be converted to a sf data frame for further manipulation using st_sf(). Additionally, we can assign a unique id to each of the hexagon cell in area_honey_comb using mutate().\n\nhoneycomb_grid_sf = st_sf(area_honeycomb_grid) %&gt;%\n  # add grid ID\n  mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))\n\nFollowing this, we can use lengths() and st_intersect() to determine the allocation of bus stop in each cell. The goal is to create a new column, consisting of the number of bus stop in each of the cell. The filter() function can then be added to remove all cells with no bus stop and create the final sf data frame.\n\n# Counting the number of bus stop in each cell\nhoneycomb_grid_sf$n_busstop = lengths(st_intersects(honeycomb_grid_sf,busstop))\n\n# Removing all cells without bus stop\nhoneycomb_count = filter(honeycomb_grid_sf, n_busstop &gt; 0)\n\nWe can see that there are 1050 hexagon cells in honeycomb_count, indicating that there are 1050 cells with at least 1 bus stops.\nAt this point, the hexagon grid of bus stop can be drawn onto a map of Singapore using the functions of the tmap package. Additionally, the n_busstop column can be passed to the tm_fill() function to shade the cell based on the number of bus stops in it.\n\n\n\n\n\n\nNote\n\n\n\n\ntm_basemap: Choosing the basemap layer on which the hexagon grid will be drawn. OpenStreetMap is chosen due to its high fidelity while not being overly crowded. Additionally, OpenStreetMap displays icon for bus stops in Singapore, allowing user to visually check any cell.\n\nIf an incorrect CRS was specified in the earlier steps, the basemap will be of an incorrect location or alignment.\n\n\n\n\n\ntmap_mode('plot')\n\nbushexmap &lt;-   tm_shape(mpsz)+\n  tm_polygons(col = 'white')+\n  tm_shape(honeycomb_count)+\n  tm_fill(\n    col = \"n_busstop\",\n    palette = \"Blues\",\n    style = \"cont\",\n    title = \"Number of bus stop\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of bus stop: \" = \"n_busstop\"\n    ),\n    popup.format = list(\n      n_busstop = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_layout(main.title = 'Distribution of Bus Stops', main.title.position = 'center')\n\nbushexmap\n\n\n\n\nFrom the illustration, we can see that each cell might contain up to 14 bus stops. A bar chat can be drawn with the ggplot2 package to visualize the distribution of number of bus stop in each cell.\n\nggplot(honeycomb_count, aes(x=n_busstop))+   geom_bar()+   theme_classic()+   geom_text(aes(label = after_stat(count)), stat = \"count\", vjust = -0.5, colour = \"black\")\n\n\n\n\nAs can be seen, the majority of cells contain 1-9 bus stops with only 178 cells containing 10 or more bus stops. This shows that the cells adequately capture solitary bus stop, as well as pairs of bus stops (bus stops which are opposite each other, served by the same bus services).\n\n\n\nCombining Aspatial and Geospatial Data\nIn order to conduct geospatial analysis, a data frame which contains the hexagon cells as well as the number of bus trips for each cells must be created. This must be done in multiple steps\n\nCombining the Origin - Destination Bus Stop Data Frame with Bus Stop Geometry Data Frame\nThis can be done using the inner_join() function, which will keep all the rows that is in both data frame. By using this argument, it is possible to retain only bus stops which are present in both data frames, eliminating any bus stops which might be present in one but not the other. By\n\n\n\n\n\n\nNote\n\n\n\nThere are important arguments which can be used to create a cleaner combined data frame.\n\nby = join_by(ORIGIN_PT_CODE == BUS_STOP_N)): Indicate the column by which the two data frames can be matched and joined. In this case, the origin bus stop code will be used.\nby = join_by(DESTINATION_PT_CODE == BUS_STOP_N)): Indicate the column by which the two data frames can be matched and joined. In this case, the destination bus stop code will be used.\nselect(1,2,3,6): Indicate the index number of the columns to be kept in the final data frame. Only the bus stop number (column 1), destination bus stop (column 2), total number of trips (column 3), and geometry (column 6) will be kept.\nreplace(is.na(.),0): Replace all value of NA with 0. This is to ensure that bus stop with no trips in a given time frame is accurately tallied at 0.\n\n\n\n\norig &lt;- inner_join(passenger_tallied, busstop,\n                       by = join_by(ORIGIN_PT_CODE == BUS_STOP_N)) %&gt;%\n  select(1,2,3,6)%&gt;%\n  st_as_sf()\n\ndestin &lt;- inner_join(passenger_tallied, busstop,\n                   by = join_by(DESTINATION_PT_CODE == BUS_STOP_N)) %&gt;%\n  select(1,2,3,6) %&gt;%\n  st_as_sf()\n\nNow, there are two separate data frames, one with the point geometry of the origin bus stop, and one with the point geometry of the destination bus stop. However, since the analysis layer consists of different polygons with unique grid_id. It is necessary to aggregate the number of trips to their origin and destination hexagon cells.\nThis can be performed in multiple steps.\n\n\nIdentifying the Origin and Destination Hexagon Cells’ Grid ID\nIn order to aggregate the origin and destination bus stops into their hexagon cells, st_join() can be used respectively for each data frame.\n\n\n\n\n\n\nNote\n\n\n\nThe by argument in st_join() can be passed the function st_within to specify that we would like to join the two data frames where the geometry in the latter is within the geometry of the former. In this case, it would mean that two rows will be joined where the bus stop lies within a particular polygon.\nst_drop_geometry() is being used to drop the spatial feature of each data frame, this would allow for the combination of the two data frames later using a regular join function.\n\n\n\norig_hex &lt;- st_join(honeycomb_count, orig, by = st_within)%&gt;%\n  select(1,3,4,5,6) %&gt;%\n  filter(grid_id != 50) %&gt;%\n  rename(ORIG_ID = grid_id,\n         ORIG_GEOM = area_honeycomb_grid) %&gt;%\n  st_drop_geometry()%&gt;%\n  na.omit()\n\ndestin_hex &lt;- st_join(honeycomb_count, destin, by = st_within)%&gt;%\n  select(1,3,4,5,6) %&gt;%\n  filter(grid_id != 50) %&gt;%\n  rename(DESTIN_ID = grid_id,\n         DESTIN_GEOM = area_honeycomb_grid) %&gt;%\n  st_drop_geometry() %&gt;%\n  na.omit()\n\nNow that there are two data frames, each almost identical to the other with the exception of a column containing the grid id of the origin and destination bus stop respectively. Let’s take a look using head().\n\nhead(orig_hex)\n\n    ORIG_ID ORIGIN_PT_CODE DESTINATION_PT_CODE TRIPS\n2        40          25751               24719    32\n2.1      40          25751               25429     1\n2.2      40          25751               25709     2\n2.3      40          25751               25771     3\n3        42          26369               24009    21\n3.1      42          26369               24049     1\n\nhead(destin_hex)\n\n    DESTIN_ID ORIGIN_PT_CODE DESTINATION_PT_CODE TRIPS\n2          40          25421               25751     3\n2.1        40          25681               25751     1\n2.2        40          25691               25751    13\n2.3        40          25701               25751     7\n2.4        40          25711               25751     1\n3          42          24009               26369    73\n\n\n\n\nCreating a Origin - Destination Hexagon Cells’ Grid ID Data Frame\nThe next step is to create a combined data frame which has both the origin and destination hexagon cell grid id and tally the total number of trips for each pair. This can be done using inner_join() and summarise().\n\ncombined_hex &lt;- inner_join(orig_hex, destin_hex, by = join_by (ORIGIN_PT_CODE == ORIGIN_PT_CODE,DESTINATION_PT_CODE == DESTINATION_PT_CODE)) %&gt;%\n  select(ORIG_ID, DESTIN_ID, TRIPS.x) %&gt;%\n  group_by(ORIG_ID, DESTIN_ID) %&gt;%\n  summarise(TOTAL_TRIP = sum(TRIPS.x))\n\nhead(combined_hex)\n\n# A tibble: 6 × 3\n# Groups:   ORIG_ID [2]\n  ORIG_ID DESTIN_ID TOTAL_TRIP\n    &lt;int&gt;     &lt;int&gt;      &lt;dbl&gt;\n1      40        80          2\n2      40       116          3\n3      40       122          1\n4      40       159         32\n5      42        61          1\n6      42        99          1\n\n\nNext, it is possible to check for duplicate record and proceed to remove them.\n\nduplicate &lt;- combined_hex %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\ncombined_hex &lt;- unique(combined_hex)\n\nhead(combined_hex)\n\n# A tibble: 6 × 3\n# Groups:   ORIG_ID [2]\n  ORIG_ID DESTIN_ID TOTAL_TRIP\n    &lt;int&gt;     &lt;int&gt;      &lt;dbl&gt;\n1      40        80          2\n2      40       116          3\n3      40       122          1\n4      40       159         32\n5      42        61          1\n6      42        99          1\n\n\nBefore moving on, it is important to check if there are any intra-zonal trips in the data frame. This is because these trips will not be included in the spatial interaction model and should be filtered out.\n\ncombined_hex %&gt;%\n  filter(ORIG_ID == DESTIN_ID)\n\n# A tibble: 582 × 3\n# Groups:   ORIG_ID [582]\n   ORIG_ID DESTIN_ID TOTAL_TRIP\n     &lt;int&gt;     &lt;int&gt;      &lt;dbl&gt;\n 1      80        80          1\n 2     101       101          4\n 3     136       136          1\n 4     140       140          9\n 5     159       159         13\n 6     160       160         21\n 7     196       196          7\n 8     197       197         12\n 9     215       215          1\n10     234       234          1\n# ℹ 572 more rows\n\n\nAs can be seen, there are 582 intra-zonal trip pair. filter() can be used to remove them.\n\ncombined_hex &lt;- combined_hex %&gt;%\n  filter(!(ORIG_ID == DESTIN_ID))\n\n\n\nCreating a Origin-Destination Matrix\nAside from having the total number of trips between each origin and destination hexagon, an origin-destination matrix (O-D Matrix) is also required. This matrix will display the geographical distance between the centroid of each hexagon cell in the grid. To create a OD-Matrix will require multiple steps.\nFirst, the hexagon cells object (honeycomb_count should be stored as a SpatialPolygonDataFrame object.\n\nhoneycomb_count_filtered &lt;- honeycomb_count %&gt;%   \n  select(1,2)  \n\nhoneycomb_count_filtered &lt;- as(honeycomb_count_filtered, 'Spatial')\n\nNext, the distance between each hexagon cell can be calculated using the spDists() function of the sp package.\n\ndists &lt;- sp::spDists(honeycomb_count_filtered, longlat = FALSE)\n\ndists[1:5,1:5]\n\n         [,1]     [,2]     [,3]     [,4]     [,5]\n[1,]    0.000  750.000 3269.174 1500.000 2704.163\n[2,]  750.000    0.000 2598.076  750.000 1984.313\n[3,] 3269.174 2598.076    0.000 1984.313  750.000\n[4,] 1500.000  750.000 1984.313    0.000 1299.038\n[5,] 2704.163 1984.313  750.000 1299.038    0.000\n\n\nAs can be seen, the dists matrix consists of the distance between each hexagon cell. For example, the hexagon cell in position 2 is 750 distance unit away from the hexagon cell in position 1. However, this would not be conducive to analysis and it would be preferable to store the column and row ids as the grid ID of the hexagon cells.\n\ngrid_id &lt;- honeycomb_count$grid_id  \ncolnames(dists) &lt;- paste0(grid_id) \nrownames(dists) &lt;- paste0(grid_id)  \ndists[1:5,1:5]\n\n         21       40       42       60       61\n21    0.000  750.000 3269.174 1500.000 2704.163\n40  750.000    0.000 2598.076  750.000 1984.313\n42 3269.174 2598.076    0.000 1984.313  750.000\n60 1500.000  750.000 1984.313    0.000 1299.038\n61 2704.163 1984.313  750.000 1299.038    0.000\n\n\nIt is possible to see now the distance between each hexagon cell using their cell id. As the matrix is a in the wide format, melt() of the reshaper package can be used to transform it into the long format for easier analysis.\n\ndistPair &lt;- melt(dists) %&gt;%   \n  rename(dists = value)  \n\ndistPair &lt;- distPair %&gt;%   \n  rename(ORIG_ID = Var1, DESTIN_ID = Var2)\n\nhead(distPair)\n\n  ORIG_ID DESTIN_ID    dists\n1      21        21    0.000\n2      40        21  750.000\n3      42        21 3269.174\n4      60        21 1500.000\n5      61        21 2704.163\n6      62        21 3968.627\n\n\nLastly, what to do with intra-zonal travel must be decided. For example, as can be seen above, the travel distance between grid_id 21 and 21 is 0. As the model will not be calibrated to handle intra-zonal trips, they will be excluded from the final data frame. For now, it is possible to filter them out of the origin-destination matrix using filter().\n\ndistPair &lt;- distPair %&gt;%\n  filter(!(dists == 0))\n\nhead(distPair)\n\n  ORIG_ID DESTIN_ID    dists\n1      40        21  750.000\n2      42        21 3269.174\n3      60        21 1500.000\n4      61        21 2704.163\n5      62        21 3968.627\n6      78        21 1299.038\n\n\n\n\n\nPreparing Final Data Frame for Spatial Interaction Modelling\n\nTabulating Features\nIn order to define the propulsive and attractive factors of the origin and destination cells, it is important to tabulate the number of different features/venues in the different cells in the aggregate level. For example, the aggregate number of Retail locations in a cell must be tabulated. The tabulation will be appended to the honeycomb_count data frame in order to have the count for each grid id, before joining it to other data frame later on. This can be accomplished using st_intersects() and lengths().\n\nflow_data &lt;- honeycomb_count %&gt;%\n  rename(geometry = area_honeycomb_grid)\n\nflow_data$Entertainment &lt;- lengths(st_intersects(flow_data, Entertainment))\n\nflow_data$FoodBev &lt;- lengths(st_intersects(flow_data, FoodBev))\n\nflow_data$Retails &lt;- lengths(st_intersects(flow_data, Retails))\n\nflow_data$FinServ &lt;- lengths(st_intersects(flow_data, FinServ))\n\nflow_data$Leisure &lt;- lengths(st_intersects(flow_data, Leisure))\n\nBefore the number of train stations is tabulated, it is important to consider how a train station is determined to be within a zone. Due to the polygon nature of train stations, they might stretch beyond two hexagon cells. This can be visualized using tmap.\n\ntmap_mode('view')\ntm_shape(honeycomb_count)+\n  tm_fill(alpha = 0.3)+\n  tm_borders(alpha = 0.5)+\n  tm_shape(trainstation)+\n  tm_fill(col = 'blue',\n          id = 'STN_NAM_DE')+\n  tm_shape(trainexit)+\n  tm_dots(col = 'red',\n          id = 'exit_code')+\n  tm_view(set.zoom.limits = c(11,16))+\n  tm_layout(title = 'Train Station Location and Hexagon Cells', title.position = c('right','top'))\n\n\n\n\n\n\nThough many examples can be found, one is highlighted in the image below. The One-North MRT station stretches from hexagon cell with grid id 974 to hexagon cell with grid id 992.\n\n\n\nOne-North MRT Station Between Two Hexagons\n\n\nIt would be more appropriate to consider that both of these cells contain One-North MRT station as practically speaking, residents in both area would have access to it and would use it. The location of exits, albeit important, would not be a good indicator as residents in cells which do not contain a station exit but do contain a train station can walk to the exit located at a negligible distance away, as no train station is sufficiently large to make this an unfeasible option.\nThe tabulation can be accomplished using st_intersects() and st_lengths().\n\n\n\n\n\n\nWarning\n\n\n\nA major limitation of this study is the failure to consider train stations which might not be within any hexagon cell but are within a certain proximity of of a cell. For example, in the image below, residents of cell 992 could practically consider walking to Kent Ridge MRT station right below instead of using One-North MRT. By this definition, cell 992 would actually have 2 train stations.\nHowever, due to technical limitations, this study would not include this approach.\n\n\n\nflow_data$trainstation &lt;- lengths(st_intersects(flow_data, trainstation))\n\nglimpse(flow_data)\n\nRows: 831\nColumns: 9\n$ grid_id       &lt;int&gt; 21, 40, 42, 60, 61, 62, 78, 79, 80, 81, 82, 99, 100, 101…\n$ n_busstop     &lt;int&gt; 1, 1, 2, 1, 4, 1, 1, 1, 4, 2, 1, 3, 2, 5, 2, 1, 1, 5, 3,…\n$ geometry      &lt;POLYGON [m]&gt; POLYGON ((3970.122 27348.13..., POLYGON ((4345.1…\n$ Entertainment &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ FoodBev       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Retails       &lt;int&gt; 0, 0, 0, 0, 5, 0, 0, 0, 5, 1, 3, 1, 1, 4, 0, 0, 0, 0, 0,…\n$ FinServ       &lt;int&gt; 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ Leisure       &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n$ trainstation  &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\n\nVisualizing Features Distribution\nLet’s visualize the distribution of the different features in each cell.\n\n\n\n\n\n\nNote\n\n\n\nThe style argument of tm_fill is passed with “jenks” in order for tmap to “divides the features into classes whose boundaries are where there are relatively big differences in the data values” (Reference), which allow for better visualization of skewed values with little variation.\n\n\n\ntmap_mode('plot')\n\nent &lt;- tm_shape(mpsz)+\n  tm_polygons(col='white')+\n  tm_shape(flow_data)+\n  tm_fill(col = 'Entertainment',\n          style = 'jenks',\n          palette = 'Reds',\n          alpha = 0.7)+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = 'Entertainment Distribution', main.title.position = 'center', main.title.size = 1.5)\n\nent\n\n\n\nleis &lt;- tm_shape(mpsz)+\n  tm_polygons(col='white')+\n  tm_shape(flow_data)+\n  tm_fill(col = 'Leisure',\n          style = 'jenks',\n          palette = 'Reds',\n          alpha = 0.7)+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = 'Leisure Distribution', main.title.position = 'center', main.title.size = 1.5)\n\nleis\n\n\n\nfin &lt;- tm_shape(mpsz)+\n  tm_polygons(col='white')+\n  tm_shape(flow_data)+\n  tm_fill(col = 'FinServ',\n          style = 'jenks',\n          palette = 'Reds',\n          alpha = 0.7)+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = 'Financial Service Distribution', main.title.position = 'center', main.title.size = 1.5)\n\nfin\n\n\n\nret &lt;- tm_shape(mpsz)+\n  tm_polygons(col='white')+\n  tm_shape(flow_data)+\n  tm_fill(col = 'Retails',\n          style = 'jenks',\n          palette = 'Reds',\n          alpha = 0.7)+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = 'Retails Distribution', main.title.position = 'center', main.title.size = 1.5)\n\nret\n\n\n\nfb &lt;- tm_shape(mpsz)+\n  tm_polygons(col='white')+\n  tm_shape(flow_data)+\n  tm_fill(col = 'FoodBev',\n          style = 'jenks',\n          palette = 'Reds',\n          alpha = 0.7)+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = 'F&B Distribution', main.title.position = 'center', main.title.size = 1.5)\n\nfb\n\n\n\ntrain &lt;- tm_shape(mpsz)+\n  tm_polygons(col='white')+\n  tm_shape(flow_data)+\n  tm_fill(col = 'trainstation',\n          style = 'jenks',\n          palette = 'Reds',\n          alpha = 0.7)+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = 'Train Station Distribution', main.title.position = 'center', main.title.size = 1.5)\n\ntrain\n\n\n\n\nEven though there are wide variation in the values of the different type of venues, one common feature among the graphs is that the highest concentration tend to be around the Downtown area, also known as the Downtown Core, of Singapore. Potentially, this might be a major attractive feature for the downtown flow of visitors."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#creating-and-visualizing-flowline",
    "href": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#creating-and-visualizing-flowline",
    "title": "Take-Home_Ex2",
    "section": "Creating and Visualizing Flowline",
    "text": "Creating and Visualizing Flowline\nBefore a spatial interaction model is created, let’s create a visualization of the flow lines between the hexagon cells. The width of the flow lines will depend on the number of trips between the hexagon cells. The geometry of the flow line can be created using the od2line() function of the stplanr package.\n\n\n\n\n\n\nNote\n\n\n\nThere are important arguments in od2line:\n\nflow: A data frame represeenting the origin-destination data. The first column should be the same as the first column of the data in the zones dataframe.\nzones: The origin and destination of the travels should be passed here.\nzone_code: Name of the variable in zones containing the ids of the zones.\n\n\n\n\nflowLine &lt;- od2line(flow = combined_hex, \n        zones = honeycomb_count,\n        zone_code = 'grid_id')\n\nhead(flowLine)\n\nSimple feature collection with 6 features and 3 fields\nGeometry type: LINESTRING\nDimension:     XY\nBounding box:  xmin: 4345.122 ymin: 28430.66 xmax: 6595.122 ymax: 36224.89\nProjected CRS: SVY21 / Singapore TM\n  ORIG_ID DESTIN_ID TOTAL_TRIP                       geometry\n1      40        80          2 LINESTRING (4345.122 28430....\n2      40       116          3 LINESTRING (4345.122 28430....\n3      40       122          1 LINESTRING (4345.122 28430....\n4      40       159         32 LINESTRING (4345.122 28430....\n5      42        61          1 LINESTRING (4345.122 31028....\n6      42        99          1 LINESTRING (4345.122 31028....\n\n\nIn the flowLine object, there is a new column which contains the line string geometry connecting the origin and destination hexagon cells. Now, it can be visualized using the tmap package.\n\n\n\n\n\n\nWarning\n\n\n\nDue to the large number of lines (more than 60,000 entries in flowLine), it is not advisable to visualize all the lines as it will result in large processing time and an incomprehensible graphic. Therefore, only lines representing a large number of trips should be visualized. We can choose to visualize lines representing 1000 trips or more.\n\n\n\ntmap_mode('plot')\n\ntm_shape(mpsz)+\n  tm_polygons(col = 'white')+\n  tm_shape(honeycomb_count)+\n  tm_fill(alpha = 0.5)+\n  tm_borders(col='black')+\n  flowLine %&gt;%\n  filter(TOTAL_TRIP &gt;= 750) %&gt;%\n  tm_shape()+\n  tm_lines(lwd = 'TOTAL_TRIP',\n           col = 'red',\n           style = 'quantile',\n           palette = 'Reds',\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)+\n  tm_layout(main.title = 'Weekdend/Holiday Morning Peak Flowline', main.title.position = 'center', scale = 0.7)\n\n\n\n\nThough there are numerous flow lines on the map, it is possible to identify that there are major clusters on the map where many lines converge and where thicker lines can be found. These usually are the major bus interchanges where many bus stops and starts, and which are located near population centres and shopping malls. There are numerous thinner red lines in the downtown area of Singapore, showing shorter trips on lower intensity lines.\nBy creating a Spatial Interaction Model, it would be possible to determine what are the push and pull factors between the different origin and destination cells."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#spatial-interaction-model",
    "href": "Take-Home_Ex/Take-Home_Ex2/Take-Home_Ex2.html#spatial-interaction-model",
    "title": "Take-Home_Ex2",
    "section": "Spatial Interaction Model",
    "text": "Spatial Interaction Model"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/MPSZ-2019.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/FinServ.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/FinServ.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/entertn.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/entertn.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html",
    "title": "Take-Home_Ex1",
    "section": "",
    "text": "The bus system is one of Singapore’s two pillars of public transport aside from the MRT. The bus system ensures convenient and affordable short-, medium-, and long-distance travel for riders. Thanks to the widespread availability of bus stops as compared to MRT stations, it has a high level of accessibility. However, this also leaves the system prone to under- or over-investment in terms of the number of bus routes, leading some stops and routes to be under-served or over-served.\nThe objective of this study is to examine the distribution of bus trips in Singapore by analyzing the number of trips by originating bus stops. It will consist of two levels of analysis:\n\nGeoVisualisation and Analysis: Visualizing the number of trips by originating bus stops and provide descriptive statistics of the distribution of trips by bus stops.\nLocal Indicators of Spatial Association Analysis (LISA): This analysis involves the calculation of Local Moran’s I to determine local spatial autocorrelation between a bus stop and its neighbors. Additionally, visualizations such as a LISA cluster map will be created for easier comparison.\n\n\n\n\nFirst, the necessary R packages will be loaded using the p_load() function of the pacman package. p_load() will also install any package which is not already installed. The following packages will be loaded:\n\nsf: For handling of geospatial data.\nsfdep: For determining the spatial dependence of spatial features. The three main categories of functionality relates to the determination of geometry neighbors, weights, and LISA.\ntidyverse: For manipulation of non-spatial data. This package contains ggplot2 for plotting, dplyr and tidyr for dataframe manipulation, and readr for reading comma-separated values (CSV).\ntmap: For thematic mapping, especially the mapping of simple features data frame.\nspdep: For drawing Moran scatterplot.\n\n\npacman::p_load(sf,sfdep,tidyverse,tmap, spdep)\n\n\n\n\nFor the purpose of this study, two types of data will be used: geospatial data which consists of spatial features and their coordinates information, and aspatial data which consists of attributes which can be ascribed to the geospatial data. Specifically, the following datasets will be used for each type:\n\nGeospatial Data:\n\nBusStop.shp: This shape file contains the location of the bus stops in Singapore as at July 2023. This file can be retrieved from the Land Transport Authority (LTA) Data Mall (link).\n\nAspatial Data:\n\norigin_destination_bus_202309.csv: This CSV file contains the detail of bus trips from an originating bus stop to a destination bus stop, identified by their unique codes, each hour of the day during September 2023. The data is further broken down into weekend or weekday, but not by the specific day of the week. This data can be retrieved by using the LTA Data Mall’s API (link).\n\n\nThe first steps taken will be to import these files into the R environment in a manipulable format.\n\n\nGeospatial data can be imported using the st_read() function of the sf package. This will import the file into the R environment as a sf (simple features) data frame. st_transform() is added to transform the Coordinate Reference System (CRS) to EPSG: 3414, which is the CRS of Singapore.\n\n\n\n\n\n\nNote\n\n\n\nIn st_read():\n\ndsn: the directory where the shape file is stored\nlayer: the name of the shape file\n\n\n\n\nbusstop &lt;- st_read(dsn = 'data/geospatial',\n                   layer = 'BusStop') %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nFrom the message provided by R, it can be seen that the busstop sf data frame has 5161 rows, 3 columns, and has a CRS of SVY 21.\nTo get a better grasp of the busstop data frame, glimpse() function can be used.\n\n\n\n\n\n\nNote\n\n\n\nThe data type for each column can be seen as well as some of their values. For sf data frames, there is a geometry column (POINT type) which contains the location information for each polygon.\n\n\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\nAdditionally, busstop can be visualized in order to spot any anomaly. This can be done using the qtm() function in the tmap package for quick plotting.\n\nqtm(busstop)\n\n\n\n\nThe visualization shows us that there are four bus stops in Malaysia. Let’s remove them so that only bus stops in Singapore will be considered. This is because these special bus stops might exhibit different behaviors due to their different context from the rest of the bus stops in Singapore.\nfilter() can be used in conjunction with a dplyr step to remove these bus stops.\n\nbusstop &lt;- busstop %&gt;%\n  filter(!BUS_STOP_N %in% c('46609','47701', '46211', '46219', '46239'))\n\n\n\n\n\n\n\nNote\n\n\n\nqtm() can be used again to check that the bus stops have been removed.\n\n\n\n\n\nThe read_csv() function of readr can be used to import the origin_destination_bus_202309 CSV file into the R environment as a data frame.\n\npassenger &lt;- read_csv('data/aspatial/origin_destination_bus_202309.csv')\n\nFrom the message provided by R, it can be seen that the passenger has 5,714,196 rows and 7 columns.\nhead() can be used instead of glimpse() to view the top five rows of the passenger data frame. This will also allow us to see the data type of each of the column.\n\nhead(passenger)\n\n# A tibble: 6 × 7\n  YEAR_MONTH DAY_TYPE   TIME_PER_HOUR PT_TYPE ORIGIN_PT_CODE DESTINATION_PT_CODE\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;              \n1 2023-09    WEEKENDS/…            17 BUS     24499          22221              \n2 2023-09    WEEKENDS/…            10 BUS     65239          65159              \n3 2023-09    WEEKDAY               10 BUS     65239          65159              \n4 2023-09    WEEKDAY                7 BUS     23519          23311              \n5 2023-09    WEEKENDS/…             7 BUS     23519          23311              \n6 2023-09    WEEKENDS/…            11 BUS     52509          42041              \n# ℹ 1 more variable: TOTAL_TRIPS &lt;dbl&gt;\n\n\nNote that the ORIGIN_PT_CODE and DESTINATION_PT_CODE are in the character (“chr”) data type. However, we would like it to be in the factor (“fctr”) data type for easier categorization and sorting. This can be done by using the as.factor() function.\n\npassenger$ORIGIN_PT_CODE &lt;- as.factor(passenger$ORIGIN_PT_CODE)\npassenger$DESTINATION_PT_CODE &lt;- as.factor(passenger$DESTINATION_PT_CODE)\n\nWe can use head() to check the data type of the passenger data frame.\n\nhead(passenger)\n\n# A tibble: 6 × 7\n  YEAR_MONTH DAY_TYPE   TIME_PER_HOUR PT_TYPE ORIGIN_PT_CODE DESTINATION_PT_CODE\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;   &lt;fct&gt;          &lt;fct&gt;              \n1 2023-09    WEEKENDS/…            17 BUS     24499          22221              \n2 2023-09    WEEKENDS/…            10 BUS     65239          65159              \n3 2023-09    WEEKDAY               10 BUS     65239          65159              \n4 2023-09    WEEKDAY                7 BUS     23519          23311              \n5 2023-09    WEEKENDS/…             7 BUS     23519          23311              \n6 2023-09    WEEKENDS/…            11 BUS     52509          42041              \n# ℹ 1 more variable: TOTAL_TRIPS &lt;dbl&gt;\n\n\n\n\n\n\nIn order to perform our analysis, certain manipulations must be made in order to prepare the data. Specifically, the passenger data set will be filtered and summarzied. Subsequently, it will be combined with the busstop data set based on the bus stop code variable present in both data frames.\n\n\n\n\nFor the purpose of this study, the passenger data set needs to be filtered to only contain trips falling within one of the following time frames:\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nThis can be accomplished using the filter() function and the dplyr steps. We can create four separate data frames to store the four different time frames\n\n# Weekday morning peak 6am - 9am\npassenger_wd_69 &lt;- passenger %&gt;%\n  filter(DAY_TYPE == 'WEEKDAY') %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9)\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\npassenger_wd_1720 &lt;- passenger %&gt;%\n  filter(DAY_TYPE == 'WEEKDAY') %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20)\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\npassenger_weh_1114 &lt;- passenger %&gt;%\n  filter(DAY_TYPE == 'WEEKENDS/HOLIDAY') %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14)\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\npassenger_weh_1619 &lt;- passenger %&gt;%\n  filter(DAY_TYPE == 'WEEKENDS/HOLIDAY') %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19)\n\nAfter the different trips have been categorized into their separate data frames, the total number trips for each origin bus stop can be tallied into a single statistic for the study period. This can be accomplished using the summarize() function. The example below shows this operation using passenger_wd_69.\n\n\n\n\n\n\nNote\n\n\n\nThe group_by() function is used to instruct R to conduct operations based on the groups created by group_by(). In this case, the summary operations will be done based on the origin bus stop codes.\n\n\n\n# Tallying the trips by origin bus stop for Weekday morning peak 6am - 9am\npassenger_wd_69_tallied &lt;- passenger_wd_69 %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\npassenger_wd_69_tallied\n\n# A tibble: 5,020 × 2\n   ORIGIN_PT_CODE TRIPS\n   &lt;fct&gt;          &lt;dbl&gt;\n 1 01012           1640\n 2 01013            764\n 3 01019           1322\n 4 01029           2373\n 5 01039           2562\n 6 01059           1582\n 7 01109            144\n 8 01112           7993\n 9 01113           6734\n10 01119           3736\n# ℹ 5,010 more rows\n\n\nAs can be seen, the newly created data frame consists only of the total trip numbers for each origin bus stop. This can be repeated for the other time frames.\n\n# Tallying the trips by origin bus stop for Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\npassenger_wd_1720_tallied &lt;- passenger_wd_1720 %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n# Tallying the trips by origin bus stop for Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\npassenger_weh_1114_tallied &lt;- passenger_weh_1114 %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n# Tallying the trips by origin bus stop for Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\npassenger_weh_1619_tallied &lt;- passenger_weh_1619 %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\n\n\n\nIn order to adequately visualize the busstop sf data frame, we need to define a mapping layer. An example of a mapping layer would be to use the Master Plan 2019 Planning Sub-zone created by the Urban Redevelopment Authority (URA). However, for the purpose of this study, a hexagon layer will be used to ensure standardization of the size of each polygon and the evenly spaced gaps between a polygon and its neighbors.\nThe steps in this section will detail the creation of the hexagon layer using the busstop data frame and visualize the layer on a map of Singapore.\n\n\n\nThe steps taken in this section is based on the guide provided by Kenneth Wong of Urban Data Palette (link).\nFirstly, a hexagon or honeycomb grid can be created based on the busstop data frame using the st_make_grid() function.\n\n\n\n\n\n\nNote\n\n\n\nThere are some notable arguments in the st_make_grid() function:\n\ncellsize = c(500,500): This argument indicates the size of each hexagon, calculated as the distance between opposite edges. If the cell size is large, each hexagon can encompasses multiple bus stops, whereas if a smaller cell size can help us differentiate between individual bus stop. However, a smaller cell size with many hexagons will take more time to create. For this study, hexagons of 250m (this distance is the perpendicular distance between the centre of the hexagon and its edges) will be created with the parameter of 500.\nwhat = ‘polygons’: We would like to create polygons on a grid.\nsquare = FALSE: The default argument is TRUE, which would create a square grid. FALSE is specified in order to create a hexagon grid.\n\n\n\n\narea_honeycomb_grid = st_make_grid(busstop, cellsize = c(500,500), what = 'polygons', square = FALSE)\n\narea_honeycomb_grid\n\nGeometry set for 5040 features \nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3470.122 ymin: 26193.43 xmax: 48720.12 ymax: 50586.47\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nThe area_honeycomb_grid contains 136906 features of the same Projected CRS as the busstop data frame. If the plot() function is used, the hexagon grid will be displayed. However, this grid contains no information and might be too small to discern the individual cell.\n\n#qtm(area_honeycomb_grid)\n\nThe area_honey_comb needs to be converted to a sf data frame for further manipulation using st_sf(). Additionally, we can assign a unique id to each of the hexagon cell in area_honey_comb using mutate().\n\nhoneycomb_grid_sf = st_sf(area_honeycomb_grid) %&gt;%\n  # add grid ID\n  mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))\n\nFollowing this, we can use lengths() and st_intersect() to determine the allocation of bus stop in each cell. The goal is to create a new column, consisting of the number of bus stop in each of the cell. The filter() function can then be added to remove all cells with no bus stop and create the final sf data frame.\n\n# Counting the number of bus stop in each cell\nhoneycomb_grid_sf$n_busstop = lengths(st_intersects(honeycomb_grid_sf,busstop))\n\n# Removing all cells without bus stop\nhoneycomb_count = filter(honeycomb_grid_sf, n_busstop &gt; 0)\n\nAt this point, the hexagon grid of bus stop can be drawn onto a map of Singapore using the functions of the tmap package. Additionally, the n_busstop column can be passed to the tm_fill() function to shade the cell based on the number of bus stops in it.\n\n\n\n\n\n\nNote\n\n\n\n\ntm_basemap: Choosing the basemap layer on which the hexagon grid will be drawn. OpenStreetMap is chosen due to its high fidelity while not being overly crowded. Additionally, OpenStreetMap displays icon for bus stops in Singapore, allowing user to visually check any cell.\n\nIf an incorrect CRS was specified in the earlier steps, the basemap will be of an incorrect location or alignment.\n\n\n\n\n\ntmap_mode('plot')\n\nbushexmap &lt;- tm_shape(honeycomb_count)+\n  tm_fill(\n    col = \"n_busstop\",\n    palette = \"Blues\",\n    style = \"cont\",\n    title = \"Number of bus stop\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of bus stop: \" = \"n_busstop\"\n    ),\n    popup.format = list(\n      n_busstop = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(main.title = 'Distribution of Bus Stops', main.title.position = 'center')\n\nbushexmap\n\n\n\n\nFrom the illustration, we can see that each cell might contain up to ten bus stops. A bar chat can be drawn with the ggplot2 package to visualize the distribution of number of bus stop in each cell.\n\nggplot(honeycomb_count, aes(x=n_busstop))+\n  geom_bar()+\n  theme_classic()+\n  geom_text(aes(label = ..count..), stat = \"count\", vjust = -0.5, colour = \"black\")\n\n\n\n\nAs can be seen, the majority of cells contain 1-2 bus stop with only 214 cells containing more than 6 bus stops. This shows that the cells adequately capture solitary bus stop, as well as pairs of bus stops (bus stops which are opposite each other, served by the same bus services).\n\n\n\nIn order to conduct geospatial analysis, a data frame which contains the hexagon cells as well as the number of bus trips for each cells must be created. This can be done using the left_join argument.\n\n\n\n\n\n\nNote\n\n\n\nThere are important arguments which can be used to create a cleaner combined data frame.\n\nby = join_by(BUS_STOP_N == ORIGIN_PT_CODE)): Indicate the column by which the two data frames can be matched and joined. In this case, the bus stop code will be used.\nselect(1,4,5): Indicate the index number of the columns to be kept in the final data frame. Only the bus stop number (column 1), total number of trips (column 4), and geometry (column 5) will be kept.\nreplace(is.na(.),0): Replace all value of NA with 0. This is to ensure that bus stop with no trips in a given time frame is accurately tallied at 0.\n\n\n\n\n# Weekday morning peak 6am - 9am\npassenger_wd_69_combined &lt;- left_join(busstop, passenger_wd_69_tallied, by = join_by(BUS_STOP_N == ORIGIN_PT_CODE))%&gt;%\n  select(1,4,5)%&gt;%\n  replace(is.na(.),0)\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\npassenger_wd_1720_combined &lt;- left_join(busstop, passenger_wd_1720_tallied, by = join_by(BUS_STOP_N == ORIGIN_PT_CODE))%&gt;%\n  select(1,4,5)%&gt;%\n  replace(is.na(.),0)\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\npassenger_weh_1114_combined &lt;- left_join(busstop, passenger_weh_1114_tallied, by = join_by(BUS_STOP_N == ORIGIN_PT_CODE))%&gt;%\n  select(1,4,5)%&gt;%\n  replace(is.na(.),0)\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\npassenger_weh_1619_combined &lt;- left_join(busstop, passenger_weh_1619_tallied, by = join_by(BUS_STOP_N == ORIGIN_PT_CODE))%&gt;%\n  select(1,4,5)%&gt;%\n  replace(is.na(.),0)\n\nIt is important to note that the bus stops and their total trips have not been tallied into the hexagon cells. st_join() can be used to accomplish this for each time frame.\n\n\n\n\n\n\nNote\n\n\n\nThe by argument in st_join() can be passed the function st_within to specify that we would like to join the two data frames where the geometry in the latter is within the geometry of the former. In this case, it would mean that two rows will be joined where the bus stop lies within a particular polygon.\n\nThe group_by() and summarise() functions here are used similarly to before, they sums up the total number of trips for all the bus stops in the hexagon, based on its grid_id, and create a new column called TOTAL_TRIP.\n\n\n\n\n# Weekday morning peak 6am - 9am\nhex_passenger_wd_69 &lt;- st_join(honeycomb_count, passenger_wd_69_combined, by = st_within(sparse = FALSE), largest = TRUE) %&gt;%\n  group_by(grid_id)%&gt;%\n  summarise(TOTAL_TRIP = sum(TRIPS))\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nhex_passenger_wd_1720 &lt;- st_join(honeycomb_count, passenger_wd_1720_combined, by = st_within(sparse = FALSE), largest = TRUE) %&gt;%\n  group_by(grid_id)%&gt;%\n  summarise(TOTAL_TRIP = sum(TRIPS))\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nhex_passenger_weh_1114 &lt;- st_join(honeycomb_count, passenger_weh_1114_combined, by = st_within(sparse = FALSE), largest = TRUE) %&gt;%\n  group_by(grid_id)%&gt;%\n  summarise(TOTAL_TRIP = sum(TRIPS))\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nhex_passenger_weh_1619 &lt;- st_join(honeycomb_count, passenger_weh_1619_combined, by = st_within(sparse = FALSE), largest = TRUE) %&gt;%\n  group_by(grid_id)%&gt;%\n  summarise(TOTAL_TRIP = sum(TRIPS))\n\nIn sum, the analysis will revolve around the four following data frames which contain the spatial information of the hexagon as well as the total number of trips for each interested time frame:\n\nhex_passenger_wd_69: Weekday morning peak 6am - 9am\nhex_passenger_wd_1720: Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nhex_passenger_weh_1114: Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nhex_passenger_weh_1619: Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\n\n\n\n\n\nBefore we move on to Geovisualization and the analysis of LISA, it would be wise to remove objects which will no longer be used. This will help to free up memory for other tasks. rm() can be used to perform this task\n\nrm(list = c('area_honeycomb_grid', 'bushexmap', 'honeycomb_count', 'honeycomb_grid_sf',       'passenger_wd_1720', 'passenger_wd_1720_tallied', 'passenger_wd_1720_combined',    'passenger_wd_69', 'passenger_wd_69_tallied', 'passenger_wd_69_combined',      'passenger_weh_1114', 'passenger_weh_1114_tallied', 'passenger_weh_1114_combined',      'passenger_weh_1619', 'passenger_weh_1619_tallied', 'passenger_weh_1619_combined'))\n\n\n\n\n\n\nThe beginning step of the analysis would be to visualize the distribution of bus trips on the hexagon layer. This can be accomplished with the mapping functions of the tmap package. However, unlike the geovisualization of bus stop per hexagon, the number of trips for each hexagon depending on the time frame varies widely. Let’s confirm this by drawing a histogram of the distribution of trips in each time frame.\n\nweekday_morning_hist &lt;- ggplot(hex_passenger_wd_69, aes(x=TOTAL_TRIP))+\n  geom_histogram()+\n  scale_x_continuous(labels = scales::comma)+\n  ggtitle('Weekday Morning')+\n  theme_classic()\n\nweekday_afternoon_hist &lt;- ggplot(hex_passenger_wd_1720, aes(x=TOTAL_TRIP))+\n  geom_histogram()+\n  scale_x_continuous(labels = scales::comma)+\n  ggtitle('Weekday Evening')+\n  theme_classic()\n  \nweekend_morning_hist &lt;- ggplot(hex_passenger_weh_1114, aes(x=TOTAL_TRIP))+\n  geom_histogram()+\n  scale_x_continuous(labels = scales::comma)+\n  ggtitle('Weekend Morning')+\n  theme_classic()\n  \nweekend_evening_hist &lt;- ggplot(hex_passenger_weh_1619, aes(x=TOTAL_TRIP))+\n  geom_histogram()+\n  scale_x_continuous(labels = scales::comma)+\n  ggtitle('Weekend Evening')+\n  theme_classic()\n  \n  \ngridExtra::grid.arrange(weekday_morning_hist, weekday_afternoon_hist, weekend_morning_hist, weekend_evening_hist, nrow = 2, ncol = 2)\n\n\n\n\nUpon a brief inspection, it is possible to see that the range of trips between the different time periods are very different from each other, with Weekday Evening trips going above 300,000 for some hexagons, while Weekend Noon only ranging around 80,000 for its hexagons. By plotting this on map, we will get to see the geospatial distribution of the number of trips for each time frame.\nBefore plotting, the summary() function can be used to compute the average number of trips for each time frame. By seeing the quantile statistics, the difference in trips between each time frame can be better illuminated.\n\n# Apply summary() to each data frame\nweekday_morning_summary &lt;- summary(hex_passenger_wd_69$TOTAL_TRIP)\nweekday_afternoon_summary &lt;- summary(hex_passenger_wd_1720$TOTAL_TRIP)\nweekend_morning_summary &lt;- summary(hex_passenger_weh_1114$TOTAL_TRIP)\nweekend_evening_summary &lt;- summary(hex_passenger_weh_1619$TOTAL_TRIP)\n\n# Combine the summary results into one data frame\nsummary_df &lt;- data.frame(unclass(weekday_morning_summary), unclass(weekday_afternoon_summary), unclass(weekend_morning_summary), unclass(weekend_evening_summary))\n\ncolnames(summary_df) &lt;- c('Weekday Morning', 'Weekday Afternoon', 'Weekend Morning', 'Weekend Evening')\n\nsummary_df\n\n        Weekday Morning Weekday Afternoon Weekend Morning Weekend Evening\nMin.              0.000             0.000           0.000           0.000\n1st Qu.         202.500           469.750         119.000         153.750\nMedian         1282.000          1526.000         560.500         564.000\nMean           3862.767          3874.821        1436.913        1469.692\n3rd Qu.        4405.250          3716.500        1652.250        1466.500\nMax.         136490.000        310285.000       81616.000      106402.000\n\n\nFrom the summary table, it is possible to see that the two Weekday data frames resemble each other more while the two Weekend data frames are more similar. In terms of the Mean number of across hexagon cells, Weekday Morning and Weekday Afternoon are relatively similar. However, the Max number of trips for Weekday Afternoon is larger than Weekday Morning’s by roughly 127.3%. Similarly, Weekend/Holiday Evening and Weekend/Holiday Morning have a similar Mean number of trips, but the Max number for Weekend/Holiday Evening is higher than that of Weekend/Holiday Morning by 30.4%. Overall, the number of trips in all quantile are roughly double during the Weekday than compared to the Weekends.\n\n\n\nBefore we map all four time frames, however, it is important to consider that the ‘style’ argument of tm_fill() can take on many values (pretty, quantile, equal, etc.). In order to pick an appropriate ‘style’, we can pick one time frame and plot it using three different styles to determine the best way to depict the distribution.\n\ntmap_mode('view')\n\n### Weekday morning peak 6am - 9am\n# Quantile style\nweekday_morning_quantile &lt;- tm_shape(hex_passenger_wd_69) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"quantile\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekday Morning Peak (Quantile)', title.position = c('right', 'top'), scale = 0.7)\n\n# Jenks style\nweekday_morning_jenks &lt;- tm_shape(hex_passenger_wd_69) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"jenks\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekday Morning Peak (Jenks)', title.position = c('right', 'top'), scale = 0.7)\n\n# Equal style\nweekday_morning_equal &lt;- tm_shape(hex_passenger_wd_69) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"equal\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekday Morning Peak (Equal)', title.position = c('right', 'top'), scale = 0.7)\n\ntmap_arrange(weekday_morning_quantile, weekday_morning_jenks, weekday_morning_equal, nrow = 3, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs can be seen, the ‘quantile’ and ‘jenks’ style can better display the difference in distribution of trips between the different hexagons, allowing for more differentiated shades. However, the ‘quantile’ function suffers from its final grouping, containing values from roughly 5,539 to 136,490; this resulted int the oversaturation of the high value hexagons. On the other hand, the ‘jenks’ method “divides the features into classes whose boundaries are where there are relatively big differences in the data values” (Reference). Therefore, it is possible to move forward using the ‘jenks’ style for visualization, but by adjusting the breaks to provide more stratification in the hexagon colors for better visualization..\n\nIt is good to remove the 3 plots created to plot the different styles since they will not be used and will only take up memory.\n\nrm(list=c('weekday_morning_equal','weekday_morning_quantile','weekday_morning_jenks'))\n\n\nThe functions of the tmap package will be used to create the maps.\n\ntmap_mode('view')\n\n# Weekday morning peak 6am - 9am\nweekday_morning &lt;- tm_shape(hex_passenger_wd_69) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"jenks\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekday Morning Peak', title.position = c('right', 'top'))\n\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nweekday_afternoon &lt;- tm_shape(hex_passenger_wd_1720) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"jenks\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekday Afternoon Peak', title.position = c('right', 'top'))\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweekend_noon &lt;- tm_shape(hex_passenger_weh_1114) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"jenks\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekend/holiday Morning Peak', title.position = c('right', 'top'))\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweekend_evening &lt;- tm_shape(hex_passenger_weh_1619) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"jenks\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekend/holiday Evening Peak', title.position = c('right', 'top'))\n\ntmap_arrange(weekday_morning, weekday_afternoon, weekend_noon, weekend_evening, nrow = 2, ncol = 2, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSearch for the bus stop near your place and compare the numbers between the four maps by zooming in! Do you think it’s accurate?\n\n\nFrom the rough visualization, it’s clear that not all bus stops experience a similar level of traffic throughout different timing of the days. Additionally, based on the quantiles created by tmap, it seems that the ranges of passenger traffic are radically different between the four time windows. For example, certain grids during Weekday Morning Peak, a hexagon could reach 328,545 passenger trips, whereas the highest number during Weekend/holiday Morning Peak only reaches 112,330. It appears that Weekend Evening Peak 17:00 - 20:00 is the period with the highest level of activity.\nAn important observation seems to be that there darker shaded hexagons tend to be clustered, indicating a positive spatial autocorrelation. However, there are clearly hexagons which are much darker than its surrounding tiles (such as the one near Tampines), indicating negative spatial autocorrelation. By conducting LISA analysis, it will be possible to determine the level of spatial autocorrelation for each hexagon, visualize them, as well as to depict the relationship between a hexagon and its neighbors through a LISA cluster map.\n\n\n\n\nBefore the LISA analysis can be conducted, it is important to define our neighborhood, or the neighbors of each polygon. This is based on the ideas that neighbors, or spatial objects which are related to other spatial objects based on sharing a common boundary or lying with a certain distance of one another, might affect each other.\nIn this case, we would like to identify the neighbors of each hexagon so that LISA analysis can determine if the number of trips in a hexagon in a time frame is correlated to the number of trips of the hexagons around it, either in the same direction or opposite direction.\nThe first step to determining the neighborhood is to choose a method by which neighbors are classified:\n\nContiguity-based Method: Based on the sharing of boundaries, either edges and/or points (Queen and Rook method).\nDistance-based Method: Based on the distances between the centroid (central point of each hexagon) of each polygon. This can either be set to a distance where each hexagon has at least one neighbor (Fixed Distance) or where each polygon has a certain number of neighbors (Adaptive Distance).\n\nIt is important to choose the appropriate method according to each situation. However, in this study, Contiguity-based methods can be preemptively ruled out due to the fact that some cells have no contiguous neighbors, as can be seen below.\n\n\n\nIsolated Cells\n\n\nIf the contiguity method is used, the LISA calculation for these cells would not be conducive for analysis as they technically have no neighbors. This can be confirmed by using the st_contiguity() function to create a Queen contiguity matrix for one time frame\n\nwm_q &lt;- st_contiguity(st_geometry(hex_passenger_wd_1720))\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 1520 \nNumber of nonzero links: 6874 \nPercentage nonzero weights: 0.2975242 \nAverage number of links: 4.522368 \n9 regions with no links:\n561 726 980 1047 1415 1505 1508 1512 1520\nLink number distribution:\n\n  0   1   2   3   4   5   6 \n  9  39 109 205 291 364 503 \n39 least connected regions:\n1 7 22 38 98 169 187 195 211 218 258 259 264 267 287 454 562 607 642 696 708 732 751 784 869 1021 1022 1046 1086 1214 1464 1471 1482 1500 1501 1503 1506 1510 1519 with 1 link\n503 most connected regions:\n10 13 16 17 24 25 31 35 42 43 48 53 55 60 63 67 73 77 80 81 84 85 87 88 91 92 97 102 107 111 117 121 127 133 140 141 143 148 149 150 154 155 156 157 163 164 165 173 174 175 183 184 185 191 192 193 194 200 201 202 205 206 207 208 216 229 239 243 244 246 257 266 271 278 279 283 284 291 292 298 300 301 302 304 309 310 312 313 316 321 324 325 327 337 338 339 340 343 352 355 363 368 390 391 400 402 403 407 414 418 423 425 431 436 437 438 440 443 450 451 452 461 466 467 468 469 473 477 480 481 485 489 493 494 496 502 503 507 513 514 517 518 523 529 534 539 543 548 549 550 552 556 558 564 568 573 574 576 577 581 590 591 594 598 599 604 605 609 615 619 624 626 633 636 637 638 648 649 650 654 655 657 658 659 669 670 671 677 680 681 682 687 688 690 691 700 701 704 705 706 713 716 717 724 727 728 729 740 741 755 757 758 760 771 774 775 776 777 782 783 787 788 789 792 793 794 795 799 800 806 807 810 811 812 813 819 820 823 824 825 830 831 832 841 843 844 846 847 848 850 851 852 853 854 860 863 865 866 867 871 872 876 877 878 880 881 882 884 885 887 888 891 893 896 899 902 905 906 910 914 919 921 926 927 928 930 931 935 937 943 944 945 946 947 948 954 958 959 962 963 968 969 971 972 973 977 984 985 986 987 988 990 996 997 998 999 1004 1011 1012 1013 1014 1024 1025 1026 1028 1029 1036 1037 1038 1042 1050 1051 1054 1056 1057 1062 1063 1064 1066 1067 1068 1069 1076 1078 1079 1080 1083 1089 1093 1100 1101 1102 1105 1106 1110 1111 1117 1120 1121 1122 1128 1133 1134 1135 1136 1141 1142 1144 1145 1146 1147 1148 1150 1156 1157 1158 1162 1163 1164 1166 1169 1170 1171 1172 1176 1177 1178 1179 1180 1184 1186 1190 1191 1192 1193 1194 1201 1202 1203 1204 1205 1206 1207 1210 1211 1217 1218 1219 1220 1221 1227 1233 1234 1235 1239 1244 1245 1251 1253 1254 1255 1261 1265 1266 1271 1272 1273 1277 1281 1283 1289 1299 1301 1302 1303 1304 1316 1318 1324 1325 1326 1327 1329 1330 1331 1334 1335 1336 1337 1343 1344 1345 1352 1353 1355 1356 1361 1365 1366 1368 1369 1371 1372 1377 1380 1381 1382 1384 1388 1391 1393 1395 1398 1406 1408 1412 1417 1418 1420 1424 1425 1426 1427 1428 1433 1434 1435 1436 1440 1441 1442 1446 1447 1449 1451 1453 1456 1457 1459 1460 1461 1462 1469 with 6 links\n\n\nAs can be seen from the weight matrix, 10 hexagon cells have 0 neighbor. Therefore, a Distance-based Method would be suitable for analysis. Both Fixed Distance and Adaptive Distance Weight Matrix can be created for comparison to find the most appropriate method.\n\n\n\n\nst_dist_band() of sfdep is incredibly powerful in that it can create a neighbor list based on distance between the centroid of polygons and a lower and upper bound distance to other centroid. The default arguments for st_dist_band() will define a lower and upper bound distance from the centroid of a polygon so that each hexagon will have at least one neighbor. This is the equivalent of the steps in spdep of the function knearneigh() of k=1.\nst_inverse_distance() of a sfdep can be combined with st_dist_band() in a dplyr step to create a new column in each data frame of the different time frames to create a neighbor list and a inverse distance weight list. Additionally, st_lag() can be used to create a spatially lagged value column for total trips based on the weight of neighbors.\n\n# Weekday morning peak 6am - 9am\nwd69_nb &lt;- hex_passenger_wd_69 %&gt;%\n  mutate(nb = st_dist_band(area_honeycomb_grid),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nwd1720_nb &lt;- hex_passenger_wd_1720 %&gt;%\n  mutate(nb = st_dist_band(area_honeycomb_grid),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweh1114_nb &lt;- hex_passenger_weh_1114 %&gt;%\n  mutate(nb = st_dist_band(area_honeycomb_grid),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweh1619_nb &lt;- hex_passenger_weh_1619 %&gt;%\n  mutate(nb = st_dist_band(area_honeycomb_grid),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n\n\n\nSince the hexagon tiles is stable across all time frame, it is possible to plot the neighbor relationship for only one time frame in order to visualize the neighbors list created. Let’s take Weekday morning peak 6am - 9am. By visualizing, the appropriateness of the Fixed Distance Method can be roughly determined.\n\nplot(wd69_nb$area_honeycomb_grid, border = 'lightgrey')\nplot(wd69_nb$nb, st_centroid(wd69_nb$area_honeycomb_grid), add=TRUE)\nplot(st_knn(wd69_nb$area_honeycomb_grid, k = 1), st_centroid(wd69_nb$area_honeycomb_grid), add=TRUE, col = 'red', length = 0.08)\n\n\n\n\nDue to the large number of hexagons, the visualization is too dense to delineate any helpful details. However, the summary() function might be of some help to study the neighbors list. Similar to be fore, we ony need to test one time frame.\n\nsummary(wd69_nb$nb)\n\nNeighbour list object:\nNumber of regions: 1520 \nNumber of nonzero links: 76822 \nPercentage nonzero weights: 3.325052 \nAverage number of links: 50.54079 \nLink number distribution:\n\n 1  2  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \n 2  1  5  1  5  5  1  4  3  3  4  4  3 12 10  8  7  7  9 11 14  7 10 12 13 15 \n31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 \n27 21 15 15 19 18 19 26 25 28 29 33 22 28 24 32 32 25 26 36 32 33 43 35 31 45 \n57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 \n31 35 35 36 48 35 36 47 39 47 38 37 27 32 30 16 25 13 13  3  2 \n2 least connected regions:\n1505 1520 with 1 link\n2 most connected regions:\n729 1076 with 77 links\n\n\nAs can be seen, there are many hexagons with less than 30 neighbors. However, the average number of links is still over 50. This is a draw back of the Fixed Distance method, hexagon cells in denser areas will have more neighbors while those in the periphery or isolated positions will have fewer neighbors. Yet, this lack of neighbor might affect the LISA calculation as the effect of spatial autocorrelation might be smoothed out for those cells with many neighbors\nBetween the Fixed Distance and Adaptive Distance Matrix, an Adaptive Distance Matrix would be more appropriate to the non-uniform nature of bus stop spatial distribution across the map. Using Adaptive Distance would allow for the specification of the number of neighbors, allowing for the standardisation of the LISA analysis process across hexagons.\n\n\n\n\nThe creation of the Adaptive Distance Weight list is largely similar to that of the Fixed Distance Weight list thanks to the sfdep package. The only major amendment is the usage of st_knn() instead of st_distance_band(). st_knn() allows for the forcing of a certain of neighbors for each hexagon cell. This can be accomplished by passing the k argument to st_knn().\n\n# Weekday morning peak 6am - 9am\nwd69_nb &lt;- hex_passenger_wd_69 %&gt;%\n  mutate(nb = st_knn(area_honeycomb_grid, k = 6),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\n\n\nwd1720_nb &lt;- hex_passenger_wd_1720 %&gt;%\n  mutate(nb = st_knn(area_honeycomb_grid, k = 6),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweh1114_nb &lt;- hex_passenger_weh_1114 %&gt;%\n  mutate(nb = st_knn(area_honeycomb_grid, k = 6),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweh1619_nb &lt;- hex_passenger_weh_1619 %&gt;%\n  mutate(nb = st_knn(area_honeycomb_grid, k = 6),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\nSimilar to before, the summary() function can be used to check the average number of neighbors for each cell.\n\nsummary(wd69_nb$nb)\n\nNeighbour list object:\nNumber of regions: 1520 \nNumber of nonzero links: 9120 \nPercentage nonzero weights: 0.3947368 \nAverage number of links: 6 \nNon-symmetric neighbours list\nLink number distribution:\n\n   6 \n1520 \n1520 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 with 6 links\n1520 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 with 6 links\n\n\nIt can be seen that all hexagon cells now have 6 neighbors. The LISA calculation can commence.\n\n\n\n\nThe statistical test used for LISA in this study will be the Local Moran’s I. The hypothesis for the Local Moran’s I will be as follow for each time frame:\n\nNull Hypothesis (H0): No Spatial Autocorrelation\nAlternative Hypothesis (H1): There is Spatial Autocorrelation, Positive or Negative\n\nThe result of the test can be determined using the z-score or p-value, we will be using the p-value.\n\n\nlocal_moran() of the sfdep package can be used to calculate Local Moran’s I Statistic and other related statistics. the unnest() function is used to unpack the Local Moran’s statistics into separate columns.\nNote some important arguments when using the local_moran() function.\n\n\n\n\n\n\nNote\n\n\n\n\nnsim: The number of simulations to run. The simulations will create random patterns on the map by reassigning the values and calculate the p-value as the proportions of values as extreme or more extreme than the actual observed values.\nalternative = ‘two.sided’: The default test for local_moran() is a two-sided tests, which is aligned with the H1. ‘greater’ or ‘less’ can be passed to alternative to conduct other types of tests.\n\n\n\n\n# Weekday morning peak 6am - 9am\nwd69_lisa &lt;- wd69_nb %&gt;%\n  mutate(local_moran = local_moran(TOTAL_TRIP, nb, wt, nsim = 199),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nwd1720_lisa &lt;- wd1720_nb %&gt;%\n  mutate(local_moran = local_moran(TOTAL_TRIP, nb, wt, nsim = 199),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweh1114_lisa &lt;- weh1114_nb %&gt;%\n  mutate(local_moran = local_moran(TOTAL_TRIP, nb, wt, nsim = 199),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweh1619_lisa &lt;- weh1619_nb %&gt;%\n  mutate(local_moran = local_moran(TOTAL_TRIP, nb, wt, nsim = 199),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n# Examining the first 5 rows of the new data frame\nhead(weh1619_lisa)\n\nSimple feature collection with 6 features and 17 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31533.92\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 18\n      ii       eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.0525 -0.00412  0.00490 0.808 0.419     0.05        0.025    -3.00    11.4 \n2 0.0695  0.00212  0.00707 0.802 0.423     0.09        0.045    -4.41    30.1 \n3 0.0893  0.00308  0.0109  0.827 0.408     0.03        0.015    -3.54    16.9 \n4 0.0585  0.000808 0.00673 0.703 0.482     0.04        0.02     -4.75    28.4 \n5 0.0719  0.00239  0.00634 0.873 0.382     0.02        0.01     -4.65    29.7 \n6 0.0975  0.0103   0.00633 1.10  0.273     0.03        0.015    -2.05     5.21\n# ℹ 9 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, lag_trip &lt;dbl&gt;, grid_id &lt;int&gt;, TOTAL_TRIP &lt;dbl&gt;,\n#   area_honeycomb_grid &lt;POLYGON [m]&gt;\n\n\nA host of statistics related to the Local Moran’s I have been added to the data frame including the I statistic (ii), the p-value (p_ii), and the mean cluster (mean). This will help us to create visualizations that will shed light onto the phenomenon of spatial autocorrelation in the different time frames.\n\n\n\n\n\nIn order to effectively visualize the Local Moran’s I statistics for each time frame, it is preferable to plot the Local Moran’s I values and p-values together. At this point, creating the visualization for each time frame separately instead of all together will allow for easier analysis.\n\n\n\n\n\n\nNote\n\n\n\nAs we would like to only display p-values which indicate statistical significance, we will use a filter and create a custom color palette to indicate that any p-value above 0.05 will not be displayed.\n\n\n\n\n\n\n\n\nNote\n\n\n\nSeveral functions are added to make the map interactive and aesthetically pleasing\n\ntmap_mode(‘view’): Creates an interactive map which allow zooming and interacting with cells on the map\npop.vars: Identifying the legend and value which pops up when a cell is selected. In this case, it is the number of bus stops.\npopup.format: Specifying the format of the variable to be displayed when selecting a cell.\n\n\n\nWeekday Morning Peak 6am - 9am\n\n\nShow the code\np_value_color = c('#bdd7e7','#6baed6', '#2171b5')\n\ntmap_mode('view')\n\n# Spatially Lagged Values\nwd69.lag &lt;- tm_shape(wd69_lisa)+\n  tm_fill('lag_trip',\n          style = \"jenks\", \n          title = \"Spatially Lagged Trips\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"Spatially Lagged Trips: \" = \"lag_trip\"),\n          popup.format = list(\n            lag_trip = list(format = \"f\", digits = 0)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Spatially Lagged Trips\", main.title.position = \"center\")\n\n# Local Moran's I Statistics\nwd69.localmi &lt;- wd69_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('ii',\n          style = \"pretty\", \n          title = \"Local Moran's I Statistics\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"I Statistic: \" = \"ii\"),\n          popup.format = list(\n            ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekday Morning Local Moran's I values\", main.title.position = \"center\")\n\n# Local Moran's I p-values\nwd69.pvalue &lt;- wd69_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('p_ii',\n          breaks = c(-Inf, 0.001, 0.01, 0.05),\n          palette = rev(p_value_color),\n          title = \"Local Moran's I p-values\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"p-value: \" = \"p_ii\"),\n          popup.format = list(\n            p_ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekday Morning Local Moran's I p-values\", main.title.position = \"center\")\n\ntmap_arrange(wd69.lag, wd69.localmi, wd69.pvalue, nrow = 3, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the illustrations, it can be determined that there is spatial clustering in the number of trips, especially in the pattern of hexagons with high number of spatially lagged trips surrounding one with a fewer spatially lagged trips; this pattern is notable around the Jurong and Choa Chu Kang areas in the West and Tampines Area in the East. One can also note this pattern in the Ang Mo Kio and Yishun area in the North and those hexagons around the Woodlands causeway. This is reinforced when one looks at the p-values plot. The surrounding polygons with high spatially lagged trips often have a p-value of less than 0.001, which indicates statistically significant spatial autocorrelation. Their Local Moran’s I Statistics are relatively close to zero, either in the positive or negative direction. They have a small, negative Local Moran’s I, suggesting that they are surrounded by neighbours which are dissimilar to them, likely due to their high spatially lagged values. A possible interpretation of this result is that these are major population centres, also known as the Heartlands, where people in the surrounding areas are congregating due to them hosting major bus interchanges in the morning to get to places of employment or education.\nWeekday Afternoon Peak 5pm - 8pm (17:00 - 20:00)\n\n\nShow the code\ntmap_mode('view')\n\n# Spatially Lagged Values\nwd1720.lag &lt;- tm_shape(wd1720_lisa)+\n  tm_fill('lag_trip',\n          style = \"jenks\", \n          title = \"Spatially Lagged Trips\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"Spatially Lagged Trips: \" = \"lag_trip\"),\n          popup.format = list(\n            lag_trip = list(format = \"f\", digits = 0)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Spatially Lagged Trips\", main.title.position = \"center\")\n\n# Local Moran's I Statistics\nwd1720.localmi &lt;- wd1720_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('ii',\n          style = \"pretty\", \n          title = \"Local Moran's I Statistics\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"I Statistic: \" = \"ii\"),\n          popup.format = list(\n            ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekday Afternoon Local Moran's I values\", main.title.position = \"center\")\n\n# Local Moran's I p-values\nwd1720.pvalue &lt;- wd1720_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('p_ii',\n          breaks = c(-Inf, 0.001, 0.01, 0.05),\n          palette = rev(p_value_color),\n          title = \"Local Moran's I p-values\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"p-value: \" = \"p_ii\"),\n          popup.format = list(\n            p_ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekday Afternoon Local Moran's I p-values\", main.title.position = \"center\")\n\ntmap_arrange(wd1720.lag, wd1720.localmi, wd1720.pvalue, nrow = 3, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Local Moran’s I result for the Weekday afternoon peak 5pm - 8pm is similar to that of the weekday morning peak. A similar pattern of hexagons with high number of spatially lagged trips and statistically significant p-value surrounding those with fewer spatially lagged trips and non-significant p-value reappear here. Interestingly, one of these clusters in Jurong in the West and the two in Ang Mo Kio and Yishun in the North seem to have dissipated in this time window. However, the cluster in Tampines, Choa Chu Kang, and the Woodlands causeway remain. This reinforces the previous observation that these areas consist of major interchanges where the flows of people would congregate before dispersing again. Possibly, this is due to the flow of people returning home after work. This is reinforced by the emergence of individual cells near the Marina Reservoir, also known as part of the Downtown Core, and the office buildings near Harbourfront in the South. They have statistically significant p-value and relatively high spatially lagged trips, possibly indicating flow of people leaving their workplaces.\nWeekend/holiday Morning Peak 11am - 2pm (11:00 - 14:00)\n\n\nShow the code\ntmap_mode('view')\n\n# Spatially Lagged Values\nweh1114.lag &lt;- tm_shape(weh1114_lisa)+\n  tm_fill('lag_trip',\n          style = \"jenks\", \n          title = \"Spatially Lagged Trips\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"Spatially Lagged Trips: \" = \"lag_trip\"),\n          popup.format = list(\n            lag_trip = list(format = \"f\", digits = 0)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Spatially Lagged Trips\", main.title.position = \"center\")\n\n# Local Moran's I Statistics\nweh1114.localmi &lt;- weh1114_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('ii',\n          style = \"pretty\", \n          title = \"Local Moran's I Statistics\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"I Statistic: \" = \"ii\"),\n          popup.format = list(\n            ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Local Moran's I values\", main.title.position = \"center\")\n\n# Local Moran's I p-values\nweh1114.pvalue &lt;- weh1114_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('p_ii',\n          breaks = c(-Inf, 0.001, 0.01, 0.05),\n          palette = rev(p_value_color),\n          title = \"Local Moran's I p-values\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"p-value: \" = \"p_ii\"),\n          popup.format = list(\n            p_ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Local Moran's I p-values\", main.title.position = \"center\")\n\ntmap_arrange(weh1114.lag, weh1114.localmi, weh1114.pvalue, nrow = 3, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn addition to the clusters in the Heartlands as seen previously, the Weekend/holiday Noon Peak 11am – 2pm (11:00 – 14:00) result shows a pattern of cells with statistically significant p-value emerge in the central of Singapore, in the areas of Tiong Bahru, Outram Park, and Orchard Road. These cells are surrounded by other cells with high spatially lagged trips but non-significant p-values. A possible interpretation for these cells is that these are popular areas for people to congregate on the weekends, increasing their number of trips, and due to their proximity, they exhibit statistically significant spatial autocorrelation. A more micro-level analysis might reveal why the bus stops within these areas are more prominent than others. For Orchard, road, the interpretation might be more straightforward, as perennially popular location for locals and tourists alike.\nWeekend/holiday Evening Peak 4pm - 7pm (16:00 - 19:00)\n\n\nShow the code\ntmap_mode('view')\n\n# Spatially Lagged Values\nweh1619.lag &lt;- tm_shape(weh1619_lisa)+\n  tm_fill('lag_trip',\n          style = \"jenks\", \n          title = \"Spatially Lagged Trips\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"Spatially Lagged Trips: \" = \"lag_trip\"),\n          popup.format = list(\n            lag_trip = list(format = \"f\", digits = 0)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Spatially Lagged Trips\", main.title.position = \"center\")\n\n# Local Moran's I Statistics\nweh1619.localmi &lt;- weh1619_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('ii',\n          style = \"pretty\", \n          title = \"Local Moran's I Statistics\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"I Statistic: \" = \"ii\"),\n          popup.format = list(\n            ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Local Moran's I values\", main.title.position = \"center\")\n\n# Local Moran's I p-values\nweh1619.pvalue &lt;- weh1619_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('p_ii',\n          breaks = c(-Inf, 0.001, 0.01, 0.05),\n          palette = rev(p_value_color),\n          title = \"Local Moran's I p-values\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"p-value: \" = \"p_ii\"),\n          popup.format = list(\n            p_ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Local Moran's I p-values\", main.title.position = \"center\")\n\ntmap_arrange(weh1619.lag, weh1619.localmi, weh1619.pvalue, nrow = 3, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, for the Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00) Local Moran’s I result, it is possible to find what seems to be the converge of other the patterns in the previous time windows. There are clusters of statistically significant cells with higher spatially lagged trips emerging in the Heartlands, Tiong Bahru, Orchard Road, and Harbourfront; the notable exception would be the lack of statistically significant cells in the Downtown Core. Aside from the pattern in major population centres, the pattern reinforces the previous observation that there is more activity at bus stops in popular areas for locals and tourists to visit and return during the evening peak period. A possible case for this would be the single cell on Sentosa island, a mostly purely leisure destination.\nOverall, the geospatial autocorrelation pattern that seems to emerge is the movement of people to and from work during the weekday and to leisure spots during the weekend and holiday. This pattern reveals itself through hexagons with higher level of spatially lagged trips, often bus interchanges in population centre, being surrounded by less similar neighbors. Or, hexagons with higher level of spatially lagged trips, often in leisure spots, being nearer to more similar neighbors and hexagons with higher spatially lagged trips but non-significant autocorrelation in the Downtown Core.\nThe observation made can further be examined by visualizing the structure of the relationship between the values of a hexagon and its similarity to its neighbors, or what is categorized in Local Moran’s I as low-low, low-high, high-low, high-high. This is can be done using the Moran Scatterplot andn LISA Cluster Map.\n\n\n\nThe Moran Scatterplot assign each of the hexagon cell of bus stops to one of four quadrants:\n\nHigh - High: Areas of high values surrounded by similar neighbors\nLow - Low: Areas of low values surrounded by similar neighbors\nHigh - Low: Areas of high values surrounded by dissimilar neighbors\nLow - High: Areas of low values surrounded by dissimilar neighbors\n\nThe Moran Scatterplot visualization allows users to roughly comprehend the spatial clustering in the data set. This can be done using the moran.plot() function of the spdep package.\n\n\n\n\n\n\nNote\n\n\n\nDue to the usage of sfdep package, certain functions must be combined with the lisa objects in order for moran.plot() to work correctly.\n\nscale(): The scale function works to center and scale the values. This involves subtracting the value by the mean then dividing it by the standard deviation.\nas.vector(): This function transforms the scaled values into a more easily plottable object.\nnb2listw(): This function transform the neighbor list into a listw object which can be accepted by moran.plot()\n\n\n\n\npar(mfrow = c(2,2))\n\n# Weekday morning peak 6am - 9am\nwd69_scatter &lt;- moran.plot(as.vector(scale(wd69_lisa$TOTAL_TRIP)), nb2listw(wd69_lisa$nb),\n           labels = as.character(wd69_lisa$grid_id),\n           xlab = 'z-Trip',\n           ylab = 'Spatially Lagged z-Trip',\n           main = 'Weekday Morning')\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nwd1720_scatter &lt;- moran.plot(as.vector(scale(wd1720_lisa$TOTAL_TRIP)), nb2listw(wd1720_lisa$nb),\n           labels = as.character(wd1720_lisa$grid_id),\n           xlab = 'z-Trip',\n           ylab = 'Spatially Lagged z-Trip',\n           main = 'Weekday Afternoon')\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweh1114_scatter &lt;- moran.plot(as.vector(scale(weh1114_lisa$TOTAL_TRIP)), nb2listw(weh1114_lisa$nb),\n           labels = as.character(weh1114_lisa$grid_id),\n           xlab = 'z-Trip',\n           ylab = 'Spatially Lagged z-Trip',\n           main = 'Weekend/holiday Noon')\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweh1619_scatter &lt;- moran.plot(as.vector(scale(weh1619_lisa$TOTAL_TRIP)), nb2listw(weh1619_lisa$nb),\n           labels = as.character(weh1619_lisa$grid_id),\n           xlab = 'z-Trip',\n           ylab = 'Spatially Lagged z-Trip',\n           main = 'Weekend/holiday Evening')\n\n\n\n\nThe draw back of the Moran Scatterplot is that we cannot visualize the spatial distribution of the hexagons, as well as the fact that it does not indicate significance of the Local Moran’s I. Additionally, due to density of certain segments, it is difficult to discern their position.\n\n\n\nThe LISA Cluster to which each hexagon belongs can be found in the mean, median, and psyal columns created by local_moran(). This can be used in combination with tmap to create our cluster map. The median will be used for the most accurate representation, accounting for outliers. Similar to before, we will only highlight polygons with a statistically significant value (p_value &lt; 0.05).\nThe four segments of the LISA Cluster Map are similar to those of the Moran Scatterplot:\n\nHigh - High: Areas of high values surrounded by similar neighbors\nLow - Low: Areas of low values surrounded by similar neighbors\nHigh - Low: Areas of high values surrounded by dissimilar neighbors\nLow - High: Areas of low values surrounded by dissimilar neighbors\n\n\ntmap_mode('view')\n\ncluster_palette = c('#0000FF', '#FFB6C1', '#7EC0EE', '#FF0000')\n\n# Weekday morning peak 6am - 9am\nwd69_cluster &lt;- wd69_lisa %&gt;%\n  filter(p_ii &lt;= 0.05) %&gt;%\n  tm_shape()+\n  tm_fill(col = 'mean',\n          title = 'Weekday Morning',\n          palette = cluster_palette)\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nwd1720_cluster &lt;- wd1720_lisa %&gt;%\n  filter(p_ii &lt;= 0.05) %&gt;%\n  tm_shape()+\n  tm_fill(col = 'mean',\n          title = 'Weekday Afternoon',\n          palette = cluster_palette)\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweh1114_cluster &lt;- weh1114_lisa %&gt;%\n  filter(p_ii &lt;= 0.05) %&gt;%\n  tm_shape()+\n  tm_fill(col = 'mean',\n          title = 'Weekend/holiday Morning',\n          palette = cluster_palette)\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweh1619_cluster &lt;- weh1619_lisa %&gt;%\n  filter(p_ii &lt;= 0.05) %&gt;%\n  tm_shape()+\n  tm_fill(col = 'mean',\n          title = 'Weekend/holiday Evening',\n          palette = cluster_palette)\n\ntmap_arrange(wd69_cluster, wd1720_cluster, weh1114_cluster, weh1619_cluster, ncol = 2, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDue to the display of only statistically significant hexagons, the pattern in the LISA Cluster Map is similar to that of the mapping of Local Moran’s I values and p-value. However, it is possible to observe a that there seems to be an interlacing of Low-High cells next to High-High cells. This means that there are cells with low values surrounded by neighbors with high values next cells with high values surrounded by neighbors with high values. Possibly, this might result from some bus stops in a cell which see very few passengers that are near more frequented bus stops in neighboring cells.\nWhat is more interesting that there are groups of statistically significant cells surrounding a non-significant cells. This is the case, for example, for Tampines Interchange whose cell is not statistically significant by itself. This pattern is similar to those in the previous visualizations as well. However, if the raw trip number is used, one will find that this cell often has the highest number of trips. It is possible that due to its and, potentially, other interchanges’ high trip values due to their special statuses, that they are spatial outliers. However, for their neighbors, their high number of trips help to define their level of spatial autocorrelation in the negative positive direction.\n\n\n\n\n\nThis study aimed to conduct exploratory data analysis and analysis of LISA on the number of trips by origin bus stop in Singapore for four time frames: Weekday Morning, Weekday Afternoon, Weekend/holiday Morning, Weekend/holiday Evening. The analysis was done based on a layer of hexagon cells, each consisting of a certain number of bus stops.\nData preparation was done on aspatial and geospatial data sets which were retrieved from LTA Data Mall. For aspatial data, this required separating the bus stop trips by origin bus stops in September 2023 into four different time frames. Subsequently, the number of trips were tallied by the origin bus stops. For geospatial data, hexagon layers were created based on the geometry of the bus stops’ location in Singapore. The hexagons have an edge-to-edge distance of 500 metre. Finally the aspatial and geospatial data sets were combined so that each hexagon would contain a certain number of bus stops and their total number of trips for each of the four time frame.\nExploratory Data Analysis in the form of descriptive analysis and geovisualization shows that each hexagon can contain a wide range of bus trips, due to its number of bus stops as well as the popularity of the bus stops. Additionally, the range of trips in each time frame are different, with higher values tending to be during the Weekday periods. It was also found that there seems to be visual clusters where hexagons with higher number of trips tend to be nearer to each other. This provided the rationale for LISA analysis.\nBefore LISA analysis was conducted, the neighborhood was defined using the Adaptive Distance Matrix, due to the inappropriateness of the Contiguity and Fixed Distance Matrix methods. The neighbor list, weight list using inverse distance matrix, and spatially lagged number of trips were then created for each hexagon for each time frame.\nA null and alternative hypotheses were defined before conducting the LISA analysis. The LISA analysis consisted of calculating the relevant Local Moran’s I statistics for each hexagon for each time frame and visualizing them. In addition, the Moran scatter plot and LISA cluster map were created using the quadrant structure. In order to maintain visual comprehensibility, only hexagons with a statistically significant p-value were visualized. From these analysis, it was found that there were a different pattern of bus stop usage from Weekday Morning to Weekday Afternoon and Weekend/Holiday Noon to Weekend/Holiday Evening as people go and return from work or leisure activities. There were clustering around areas with high number of bus trips, resulting in a number of High-High and Low-High, where less frequented bus stops were neighbors with highly frequented bus stops. Lastly, it was determined that major bus interchanges and stops, which have very high number of trips, could be spatial outliers which are not statistically significant due to their high values, but do affect the spatial relationships of their neighbors.\n\n\nFuture studies might consider studying the flow of bus trips in order to have better grasp of the demand during different time frames. This might better explain the effect of bus interchanges, where many bus services terminate and begin.\nAdditionally, the usage of bus stops can be considered in conjunction with the usage of MRT stations as they can work in tandem, especially where bus interchanges are concerned.\nFor future analysis, different types of bus services should be differentiated as feeder bus services are different from long-haul or express bus services, albeit being highly essential to the transportation needs in local communities. This could be done by adding an extra variable to classify the bus stop based on the majority of their bus services."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#objectives",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#objectives",
    "title": "Take-Home_Ex1",
    "section": "",
    "text": "The bus system is one of Singapore’s two pillars of public transport aside from the MRT. The bus system ensures convenient and affordable short-, medium-, and long-distance travel for riders. Thanks to the widespread availability of bus stops as compared to MRT stations, it has a high level of accessibility. However, this also leaves the system prone to under- or over-investment in terms of the number of bus routes, leading some stops and routes to be under-served or over-served.\nThe objective of this study is to examine the distribution of bus trips in Singapore by analyzing the number of trips by originating bus stops. It will consist of two levels of analysis:\n\nGeoVisualisation and Analysis: Visualizing the number of trips by originating bus stops and provide descriptive statistics of the distribution of trips by bus stops.\nLocal Indicators of Spatial Association Analysis (LISA): This analysis involves the calculation of Local Moran’s I to determine local spatial autocorrelation between a bus stop and its neighbors. Additionally, visualizations such as a LISA cluster map will be created for easier comparison."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#getting-started",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#getting-started",
    "title": "Take-Home_Ex1",
    "section": "",
    "text": "First, the necessary R packages will be loaded using the p_load() function of the pacman package. p_load() will also install any package which is not already installed. The following packages will be loaded:\n\nsf: For handling of geospatial data.\nsfdep: For determining the spatial dependence of spatial features. The three main categories of functionality relates to the determination of geometry neighbors, weights, and LISA.\ntidyverse: For manipulation of non-spatial data. This package contains ggplot2 for plotting, dplyr and tidyr for dataframe manipulation, and readr for reading comma-separated values (CSV).\ntmap: For thematic mapping, especially the mapping of simple features data frame.\nspdep: For drawing Moran scatterplot.\n\n\npacman::p_load(sf,sfdep,tidyverse,tmap, spdep)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#importing-required-data",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#importing-required-data",
    "title": "Take-Home_Ex1",
    "section": "",
    "text": "For the purpose of this study, two types of data will be used: geospatial data which consists of spatial features and their coordinates information, and aspatial data which consists of attributes which can be ascribed to the geospatial data. Specifically, the following datasets will be used for each type:\n\nGeospatial Data:\n\nBusStop.shp: This shape file contains the location of the bus stops in Singapore as at July 2023. This file can be retrieved from the Land Transport Authority (LTA) Data Mall (link).\n\nAspatial Data:\n\norigin_destination_bus_202309.csv: This CSV file contains the detail of bus trips from an originating bus stop to a destination bus stop, identified by their unique codes, each hour of the day during September 2023. The data is further broken down into weekend or weekday, but not by the specific day of the week. This data can be retrieved by using the LTA Data Mall’s API (link).\n\n\nThe first steps taken will be to import these files into the R environment in a manipulable format.\n\n\nGeospatial data can be imported using the st_read() function of the sf package. This will import the file into the R environment as a sf (simple features) data frame. st_transform() is added to transform the Coordinate Reference System (CRS) to EPSG: 3414, which is the CRS of Singapore.\n\n\n\n\n\n\nNote\n\n\n\nIn st_read():\n\ndsn: the directory where the shape file is stored\nlayer: the name of the shape file\n\n\n\n\nbusstop &lt;- st_read(dsn = 'data/geospatial',\n                   layer = 'BusStop') %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `D:\\phlong2023\\ISSS624\\Take-Home_Ex\\Take-Home_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nFrom the message provided by R, it can be seen that the busstop sf data frame has 5161 rows, 3 columns, and has a CRS of SVY 21.\nTo get a better grasp of the busstop data frame, glimpse() function can be used.\n\n\n\n\n\n\nNote\n\n\n\nThe data type for each column can be seen as well as some of their values. For sf data frames, there is a geometry column (POINT type) which contains the location information for each polygon.\n\n\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\nAdditionally, busstop can be visualized in order to spot any anomaly. This can be done using the qtm() function in the tmap package for quick plotting.\n\nqtm(busstop)\n\n\n\n\nThe visualization shows us that there are four bus stops in Malaysia. Let’s remove them so that only bus stops in Singapore will be considered. This is because these special bus stops might exhibit different behaviors due to their different context from the rest of the bus stops in Singapore.\nfilter() can be used in conjunction with a dplyr step to remove these bus stops.\n\nbusstop &lt;- busstop %&gt;%\n  filter(!BUS_STOP_N %in% c('46609','47701', '46211', '46219', '46239'))\n\n\n\n\n\n\n\nNote\n\n\n\nqtm() can be used again to check that the bus stops have been removed.\n\n\n\n\n\nThe read_csv() function of readr can be used to import the origin_destination_bus_202309 CSV file into the R environment as a data frame.\n\npassenger &lt;- read_csv('data/aspatial/origin_destination_bus_202309.csv')\n\nFrom the message provided by R, it can be seen that the passenger has 5,714,196 rows and 7 columns.\nhead() can be used instead of glimpse() to view the top five rows of the passenger data frame. This will also allow us to see the data type of each of the column.\n\nhead(passenger)\n\n# A tibble: 6 × 7\n  YEAR_MONTH DAY_TYPE   TIME_PER_HOUR PT_TYPE ORIGIN_PT_CODE DESTINATION_PT_CODE\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;              \n1 2023-09    WEEKENDS/…            17 BUS     24499          22221              \n2 2023-09    WEEKENDS/…            10 BUS     65239          65159              \n3 2023-09    WEEKDAY               10 BUS     65239          65159              \n4 2023-09    WEEKDAY                7 BUS     23519          23311              \n5 2023-09    WEEKENDS/…             7 BUS     23519          23311              \n6 2023-09    WEEKENDS/…            11 BUS     52509          42041              \n# ℹ 1 more variable: TOTAL_TRIPS &lt;dbl&gt;\n\n\nNote that the ORIGIN_PT_CODE and DESTINATION_PT_CODE are in the character (“chr”) data type. However, we would like it to be in the factor (“fctr”) data type for easier categorization and sorting. This can be done by using the as.factor() function.\n\npassenger$ORIGIN_PT_CODE &lt;- as.factor(passenger$ORIGIN_PT_CODE)\npassenger$DESTINATION_PT_CODE &lt;- as.factor(passenger$DESTINATION_PT_CODE)\n\nWe can use head() to check the data type of the passenger data frame.\n\nhead(passenger)\n\n# A tibble: 6 × 7\n  YEAR_MONTH DAY_TYPE   TIME_PER_HOUR PT_TYPE ORIGIN_PT_CODE DESTINATION_PT_CODE\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt; &lt;chr&gt;   &lt;fct&gt;          &lt;fct&gt;              \n1 2023-09    WEEKENDS/…            17 BUS     24499          22221              \n2 2023-09    WEEKENDS/…            10 BUS     65239          65159              \n3 2023-09    WEEKDAY               10 BUS     65239          65159              \n4 2023-09    WEEKDAY                7 BUS     23519          23311              \n5 2023-09    WEEKENDS/…             7 BUS     23519          23311              \n6 2023-09    WEEKENDS/…            11 BUS     52509          42041              \n# ℹ 1 more variable: TOTAL_TRIPS &lt;dbl&gt;"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#data-preparation",
    "title": "Take-Home_Ex1",
    "section": "",
    "text": "In order to perform our analysis, certain manipulations must be made in order to prepare the data. Specifically, the passenger data set will be filtered and summarzied. Subsequently, it will be combined with the busstop data set based on the bus stop code variable present in both data frames.\n\n\n\n\nFor the purpose of this study, the passenger data set needs to be filtered to only contain trips falling within one of the following time frames:\n\n\n\nPeak hour period\nBus tap on time\n\n\n\n\nWeekday morning peak\n6am to 9am\n\n\nWeekday afternoon peak\n5pm to 8pm\n\n\nWeekend/holiday morning peak\n11am to 2pm\n\n\nWeekend/holiday evening peak\n4pm to 7pm\n\n\n\nThis can be accomplished using the filter() function and the dplyr steps. We can create four separate data frames to store the four different time frames\n\n# Weekday morning peak 6am - 9am\npassenger_wd_69 &lt;- passenger %&gt;%\n  filter(DAY_TYPE == 'WEEKDAY') %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 & TIME_PER_HOUR &lt;= 9)\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\npassenger_wd_1720 &lt;- passenger %&gt;%\n  filter(DAY_TYPE == 'WEEKDAY') %&gt;%\n  filter(TIME_PER_HOUR &gt;= 17 & TIME_PER_HOUR &lt;= 20)\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\npassenger_weh_1114 &lt;- passenger %&gt;%\n  filter(DAY_TYPE == 'WEEKENDS/HOLIDAY') %&gt;%\n  filter(TIME_PER_HOUR &gt;= 11 & TIME_PER_HOUR &lt;= 14)\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\npassenger_weh_1619 &lt;- passenger %&gt;%\n  filter(DAY_TYPE == 'WEEKENDS/HOLIDAY') %&gt;%\n  filter(TIME_PER_HOUR &gt;= 16 & TIME_PER_HOUR &lt;= 19)\n\nAfter the different trips have been categorized into their separate data frames, the total number trips for each origin bus stop can be tallied into a single statistic for the study period. This can be accomplished using the summarize() function. The example below shows this operation using passenger_wd_69.\n\n\n\n\n\n\nNote\n\n\n\nThe group_by() function is used to instruct R to conduct operations based on the groups created by group_by(). In this case, the summary operations will be done based on the origin bus stop codes.\n\n\n\n# Tallying the trips by origin bus stop for Weekday morning peak 6am - 9am\npassenger_wd_69_tallied &lt;- passenger_wd_69 %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\npassenger_wd_69_tallied\n\n# A tibble: 5,020 × 2\n   ORIGIN_PT_CODE TRIPS\n   &lt;fct&gt;          &lt;dbl&gt;\n 1 01012           1640\n 2 01013            764\n 3 01019           1322\n 4 01029           2373\n 5 01039           2562\n 6 01059           1582\n 7 01109            144\n 8 01112           7993\n 9 01113           6734\n10 01119           3736\n# ℹ 5,010 more rows\n\n\nAs can be seen, the newly created data frame consists only of the total trip numbers for each origin bus stop. This can be repeated for the other time frames.\n\n# Tallying the trips by origin bus stop for Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\npassenger_wd_1720_tallied &lt;- passenger_wd_1720 %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n# Tallying the trips by origin bus stop for Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\npassenger_weh_1114_tallied &lt;- passenger_weh_1114 %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n# Tallying the trips by origin bus stop for Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\npassenger_weh_1619_tallied &lt;- passenger_weh_1619 %&gt;%\n  group_by(ORIGIN_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n\n\n\n\nIn order to adequately visualize the busstop sf data frame, we need to define a mapping layer. An example of a mapping layer would be to use the Master Plan 2019 Planning Sub-zone created by the Urban Redevelopment Authority (URA). However, for the purpose of this study, a hexagon layer will be used to ensure standardization of the size of each polygon and the evenly spaced gaps between a polygon and its neighbors.\nThe steps in this section will detail the creation of the hexagon layer using the busstop data frame and visualize the layer on a map of Singapore.\n\n\n\nThe steps taken in this section is based on the guide provided by Kenneth Wong of Urban Data Palette (link).\nFirstly, a hexagon or honeycomb grid can be created based on the busstop data frame using the st_make_grid() function.\n\n\n\n\n\n\nNote\n\n\n\nThere are some notable arguments in the st_make_grid() function:\n\ncellsize = c(500,500): This argument indicates the size of each hexagon, calculated as the distance between opposite edges. If the cell size is large, each hexagon can encompasses multiple bus stops, whereas if a smaller cell size can help us differentiate between individual bus stop. However, a smaller cell size with many hexagons will take more time to create. For this study, hexagons of 250m (this distance is the perpendicular distance between the centre of the hexagon and its edges) will be created with the parameter of 500.\nwhat = ‘polygons’: We would like to create polygons on a grid.\nsquare = FALSE: The default argument is TRUE, which would create a square grid. FALSE is specified in order to create a hexagon grid.\n\n\n\n\narea_honeycomb_grid = st_make_grid(busstop, cellsize = c(500,500), what = 'polygons', square = FALSE)\n\narea_honeycomb_grid\n\nGeometry set for 5040 features \nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3470.122 ymin: 26193.43 xmax: 48720.12 ymax: 50586.47\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nThe area_honeycomb_grid contains 136906 features of the same Projected CRS as the busstop data frame. If the plot() function is used, the hexagon grid will be displayed. However, this grid contains no information and might be too small to discern the individual cell.\n\n#qtm(area_honeycomb_grid)\n\nThe area_honey_comb needs to be converted to a sf data frame for further manipulation using st_sf(). Additionally, we can assign a unique id to each of the hexagon cell in area_honey_comb using mutate().\n\nhoneycomb_grid_sf = st_sf(area_honeycomb_grid) %&gt;%\n  # add grid ID\n  mutate(grid_id = 1:length(lengths(area_honeycomb_grid)))\n\nFollowing this, we can use lengths() and st_intersect() to determine the allocation of bus stop in each cell. The goal is to create a new column, consisting of the number of bus stop in each of the cell. The filter() function can then be added to remove all cells with no bus stop and create the final sf data frame.\n\n# Counting the number of bus stop in each cell\nhoneycomb_grid_sf$n_busstop = lengths(st_intersects(honeycomb_grid_sf,busstop))\n\n# Removing all cells without bus stop\nhoneycomb_count = filter(honeycomb_grid_sf, n_busstop &gt; 0)\n\nAt this point, the hexagon grid of bus stop can be drawn onto a map of Singapore using the functions of the tmap package. Additionally, the n_busstop column can be passed to the tm_fill() function to shade the cell based on the number of bus stops in it.\n\n\n\n\n\n\nNote\n\n\n\n\ntm_basemap: Choosing the basemap layer on which the hexagon grid will be drawn. OpenStreetMap is chosen due to its high fidelity while not being overly crowded. Additionally, OpenStreetMap displays icon for bus stops in Singapore, allowing user to visually check any cell.\n\nIf an incorrect CRS was specified in the earlier steps, the basemap will be of an incorrect location or alignment.\n\n\n\n\n\ntmap_mode('plot')\n\nbushexmap &lt;- tm_shape(honeycomb_count)+\n  tm_fill(\n    col = \"n_busstop\",\n    palette = \"Blues\",\n    style = \"cont\",\n    title = \"Number of bus stop\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of bus stop: \" = \"n_busstop\"\n    ),\n    popup.format = list(\n      n_busstop = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(main.title = 'Distribution of Bus Stops', main.title.position = 'center')\n\nbushexmap\n\n\n\n\nFrom the illustration, we can see that each cell might contain up to ten bus stops. A bar chat can be drawn with the ggplot2 package to visualize the distribution of number of bus stop in each cell.\n\nggplot(honeycomb_count, aes(x=n_busstop))+\n  geom_bar()+\n  theme_classic()+\n  geom_text(aes(label = ..count..), stat = \"count\", vjust = -0.5, colour = \"black\")\n\n\n\n\nAs can be seen, the majority of cells contain 1-2 bus stop with only 214 cells containing more than 6 bus stops. This shows that the cells adequately capture solitary bus stop, as well as pairs of bus stops (bus stops which are opposite each other, served by the same bus services).\n\n\n\nIn order to conduct geospatial analysis, a data frame which contains the hexagon cells as well as the number of bus trips for each cells must be created. This can be done using the left_join argument.\n\n\n\n\n\n\nNote\n\n\n\nThere are important arguments which can be used to create a cleaner combined data frame.\n\nby = join_by(BUS_STOP_N == ORIGIN_PT_CODE)): Indicate the column by which the two data frames can be matched and joined. In this case, the bus stop code will be used.\nselect(1,4,5): Indicate the index number of the columns to be kept in the final data frame. Only the bus stop number (column 1), total number of trips (column 4), and geometry (column 5) will be kept.\nreplace(is.na(.),0): Replace all value of NA with 0. This is to ensure that bus stop with no trips in a given time frame is accurately tallied at 0.\n\n\n\n\n# Weekday morning peak 6am - 9am\npassenger_wd_69_combined &lt;- left_join(busstop, passenger_wd_69_tallied, by = join_by(BUS_STOP_N == ORIGIN_PT_CODE))%&gt;%\n  select(1,4,5)%&gt;%\n  replace(is.na(.),0)\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\npassenger_wd_1720_combined &lt;- left_join(busstop, passenger_wd_1720_tallied, by = join_by(BUS_STOP_N == ORIGIN_PT_CODE))%&gt;%\n  select(1,4,5)%&gt;%\n  replace(is.na(.),0)\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\npassenger_weh_1114_combined &lt;- left_join(busstop, passenger_weh_1114_tallied, by = join_by(BUS_STOP_N == ORIGIN_PT_CODE))%&gt;%\n  select(1,4,5)%&gt;%\n  replace(is.na(.),0)\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\npassenger_weh_1619_combined &lt;- left_join(busstop, passenger_weh_1619_tallied, by = join_by(BUS_STOP_N == ORIGIN_PT_CODE))%&gt;%\n  select(1,4,5)%&gt;%\n  replace(is.na(.),0)\n\nIt is important to note that the bus stops and their total trips have not been tallied into the hexagon cells. st_join() can be used to accomplish this for each time frame.\n\n\n\n\n\n\nNote\n\n\n\nThe by argument in st_join() can be passed the function st_within to specify that we would like to join the two data frames where the geometry in the latter is within the geometry of the former. In this case, it would mean that two rows will be joined where the bus stop lies within a particular polygon.\n\nThe group_by() and summarise() functions here are used similarly to before, they sums up the total number of trips for all the bus stops in the hexagon, based on its grid_id, and create a new column called TOTAL_TRIP.\n\n\n\n\n# Weekday morning peak 6am - 9am\nhex_passenger_wd_69 &lt;- st_join(honeycomb_count, passenger_wd_69_combined, by = st_within(sparse = FALSE), largest = TRUE) %&gt;%\n  group_by(grid_id)%&gt;%\n  summarise(TOTAL_TRIP = sum(TRIPS))\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nhex_passenger_wd_1720 &lt;- st_join(honeycomb_count, passenger_wd_1720_combined, by = st_within(sparse = FALSE), largest = TRUE) %&gt;%\n  group_by(grid_id)%&gt;%\n  summarise(TOTAL_TRIP = sum(TRIPS))\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nhex_passenger_weh_1114 &lt;- st_join(honeycomb_count, passenger_weh_1114_combined, by = st_within(sparse = FALSE), largest = TRUE) %&gt;%\n  group_by(grid_id)%&gt;%\n  summarise(TOTAL_TRIP = sum(TRIPS))\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nhex_passenger_weh_1619 &lt;- st_join(honeycomb_count, passenger_weh_1619_combined, by = st_within(sparse = FALSE), largest = TRUE) %&gt;%\n  group_by(grid_id)%&gt;%\n  summarise(TOTAL_TRIP = sum(TRIPS))\n\nIn sum, the analysis will revolve around the four following data frames which contain the spatial information of the hexagon as well as the total number of trips for each interested time frame:\n\nhex_passenger_wd_69: Weekday morning peak 6am - 9am\nhex_passenger_wd_1720: Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nhex_passenger_weh_1114: Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nhex_passenger_weh_1619: Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#cleanup-step",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#cleanup-step",
    "title": "Take-Home_Ex1",
    "section": "",
    "text": "Before we move on to Geovisualization and the analysis of LISA, it would be wise to remove objects which will no longer be used. This will help to free up memory for other tasks. rm() can be used to perform this task\n\nrm(list = c('area_honeycomb_grid', 'bushexmap', 'honeycomb_count', 'honeycomb_grid_sf',       'passenger_wd_1720', 'passenger_wd_1720_tallied', 'passenger_wd_1720_combined',    'passenger_wd_69', 'passenger_wd_69_tallied', 'passenger_wd_69_combined',      'passenger_weh_1114', 'passenger_weh_1114_tallied', 'passenger_weh_1114_combined',      'passenger_weh_1619', 'passenger_weh_1619_tallied', 'passenger_weh_1619_combined'))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#exploratory-data-analysis",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#exploratory-data-analysis",
    "title": "Take-Home_Ex1",
    "section": "",
    "text": "The beginning step of the analysis would be to visualize the distribution of bus trips on the hexagon layer. This can be accomplished with the mapping functions of the tmap package. However, unlike the geovisualization of bus stop per hexagon, the number of trips for each hexagon depending on the time frame varies widely. Let’s confirm this by drawing a histogram of the distribution of trips in each time frame.\n\nweekday_morning_hist &lt;- ggplot(hex_passenger_wd_69, aes(x=TOTAL_TRIP))+\n  geom_histogram()+\n  scale_x_continuous(labels = scales::comma)+\n  ggtitle('Weekday Morning')+\n  theme_classic()\n\nweekday_afternoon_hist &lt;- ggplot(hex_passenger_wd_1720, aes(x=TOTAL_TRIP))+\n  geom_histogram()+\n  scale_x_continuous(labels = scales::comma)+\n  ggtitle('Weekday Evening')+\n  theme_classic()\n  \nweekend_morning_hist &lt;- ggplot(hex_passenger_weh_1114, aes(x=TOTAL_TRIP))+\n  geom_histogram()+\n  scale_x_continuous(labels = scales::comma)+\n  ggtitle('Weekend Morning')+\n  theme_classic()\n  \nweekend_evening_hist &lt;- ggplot(hex_passenger_weh_1619, aes(x=TOTAL_TRIP))+\n  geom_histogram()+\n  scale_x_continuous(labels = scales::comma)+\n  ggtitle('Weekend Evening')+\n  theme_classic()\n  \n  \ngridExtra::grid.arrange(weekday_morning_hist, weekday_afternoon_hist, weekend_morning_hist, weekend_evening_hist, nrow = 2, ncol = 2)\n\n\n\n\nUpon a brief inspection, it is possible to see that the range of trips between the different time periods are very different from each other, with Weekday Evening trips going above 300,000 for some hexagons, while Weekend Noon only ranging around 80,000 for its hexagons. By plotting this on map, we will get to see the geospatial distribution of the number of trips for each time frame.\nBefore plotting, the summary() function can be used to compute the average number of trips for each time frame. By seeing the quantile statistics, the difference in trips between each time frame can be better illuminated.\n\n# Apply summary() to each data frame\nweekday_morning_summary &lt;- summary(hex_passenger_wd_69$TOTAL_TRIP)\nweekday_afternoon_summary &lt;- summary(hex_passenger_wd_1720$TOTAL_TRIP)\nweekend_morning_summary &lt;- summary(hex_passenger_weh_1114$TOTAL_TRIP)\nweekend_evening_summary &lt;- summary(hex_passenger_weh_1619$TOTAL_TRIP)\n\n# Combine the summary results into one data frame\nsummary_df &lt;- data.frame(unclass(weekday_morning_summary), unclass(weekday_afternoon_summary), unclass(weekend_morning_summary), unclass(weekend_evening_summary))\n\ncolnames(summary_df) &lt;- c('Weekday Morning', 'Weekday Afternoon', 'Weekend Morning', 'Weekend Evening')\n\nsummary_df\n\n        Weekday Morning Weekday Afternoon Weekend Morning Weekend Evening\nMin.              0.000             0.000           0.000           0.000\n1st Qu.         202.500           469.750         119.000         153.750\nMedian         1282.000          1526.000         560.500         564.000\nMean           3862.767          3874.821        1436.913        1469.692\n3rd Qu.        4405.250          3716.500        1652.250        1466.500\nMax.         136490.000        310285.000       81616.000      106402.000\n\n\nFrom the summary table, it is possible to see that the two Weekday data frames resemble each other more while the two Weekend data frames are more similar. In terms of the Mean number of across hexagon cells, Weekday Morning and Weekday Afternoon are relatively similar. However, the Max number of trips for Weekday Afternoon is larger than Weekday Morning’s by roughly 127.3%. Similarly, Weekend/Holiday Evening and Weekend/Holiday Morning have a similar Mean number of trips, but the Max number for Weekend/Holiday Evening is higher than that of Weekend/Holiday Morning by 30.4%. Overall, the number of trips in all quantile are roughly double during the Weekday than compared to the Weekends.\n\n\n\nBefore we map all four time frames, however, it is important to consider that the ‘style’ argument of tm_fill() can take on many values (pretty, quantile, equal, etc.). In order to pick an appropriate ‘style’, we can pick one time frame and plot it using three different styles to determine the best way to depict the distribution.\n\ntmap_mode('view')\n\n### Weekday morning peak 6am - 9am\n# Quantile style\nweekday_morning_quantile &lt;- tm_shape(hex_passenger_wd_69) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"quantile\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekday Morning Peak (Quantile)', title.position = c('right', 'top'), scale = 0.7)\n\n# Jenks style\nweekday_morning_jenks &lt;- tm_shape(hex_passenger_wd_69) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"jenks\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekday Morning Peak (Jenks)', title.position = c('right', 'top'), scale = 0.7)\n\n# Equal style\nweekday_morning_equal &lt;- tm_shape(hex_passenger_wd_69) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"equal\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekday Morning Peak (Equal)', title.position = c('right', 'top'), scale = 0.7)\n\ntmap_arrange(weekday_morning_quantile, weekday_morning_jenks, weekday_morning_equal, nrow = 3, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs can be seen, the ‘quantile’ and ‘jenks’ style can better display the difference in distribution of trips between the different hexagons, allowing for more differentiated shades. However, the ‘quantile’ function suffers from its final grouping, containing values from roughly 5,539 to 136,490; this resulted int the oversaturation of the high value hexagons. On the other hand, the ‘jenks’ method “divides the features into classes whose boundaries are where there are relatively big differences in the data values” (Reference). Therefore, it is possible to move forward using the ‘jenks’ style for visualization, but by adjusting the breaks to provide more stratification in the hexagon colors for better visualization..\n\nIt is good to remove the 3 plots created to plot the different styles since they will not be used and will only take up memory.\n\nrm(list=c('weekday_morning_equal','weekday_morning_quantile','weekday_morning_jenks'))\n\n\nThe functions of the tmap package will be used to create the maps.\n\ntmap_mode('view')\n\n# Weekday morning peak 6am - 9am\nweekday_morning &lt;- tm_shape(hex_passenger_wd_69) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"jenks\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekday Morning Peak', title.position = c('right', 'top'))\n\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nweekday_afternoon &lt;- tm_shape(hex_passenger_wd_1720) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"jenks\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekday Afternoon Peak', title.position = c('right', 'top'))\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweekend_noon &lt;- tm_shape(hex_passenger_weh_1114) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"jenks\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekend/holiday Morning Peak', title.position = c('right', 'top'))\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweekend_evening &lt;- tm_shape(hex_passenger_weh_1619) +\n  tm_fill(\n    col = \"TOTAL_TRIP\",\n    palette = \"Blues\",\n    style = \"jenks\",\n    title = \"Number of Trips\",\n    id = \"grid_id\",\n    showNA = FALSE,\n    alpha = 0.7,\n    popup.vars = c(\n      \"Number of Trips: \" = \"TOTAL_TRIP\"\n    ),\n    popup.format = list(\n      TOTAL_TRIP = list(format = \"f\", digits = 0)\n    )\n  ) +\n  tm_borders(col = \"grey40\", lwd = 0.7)+\n  tm_basemap(server = c('Esri.WorldGrayCanvas'))+\n  tm_layout(title = 'Weekend/holiday Evening Peak', title.position = c('right', 'top'))\n\ntmap_arrange(weekday_morning, weekday_afternoon, weekend_noon, weekend_evening, nrow = 2, ncol = 2, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nSearch for the bus stop near your place and compare the numbers between the four maps by zooming in! Do you think it’s accurate?\n\n\nFrom the rough visualization, it’s clear that not all bus stops experience a similar level of traffic throughout different timing of the days. Additionally, based on the quantiles created by tmap, it seems that the ranges of passenger traffic are radically different between the four time windows. For example, certain grids during Weekday Morning Peak, a hexagon could reach 328,545 passenger trips, whereas the highest number during Weekend/holiday Morning Peak only reaches 112,330. It appears that Weekend Evening Peak 17:00 - 20:00 is the period with the highest level of activity.\nAn important observation seems to be that there darker shaded hexagons tend to be clustered, indicating a positive spatial autocorrelation. However, there are clearly hexagons which are much darker than its surrounding tiles (such as the one near Tampines), indicating negative spatial autocorrelation. By conducting LISA analysis, it will be possible to determine the level of spatial autocorrelation for each hexagon, visualize them, as well as to depict the relationship between a hexagon and its neighbors through a LISA cluster map."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#defining-the-neighborhood",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#defining-the-neighborhood",
    "title": "Take-Home_Ex1",
    "section": "",
    "text": "Before the LISA analysis can be conducted, it is important to define our neighborhood, or the neighbors of each polygon. This is based on the ideas that neighbors, or spatial objects which are related to other spatial objects based on sharing a common boundary or lying with a certain distance of one another, might affect each other.\nIn this case, we would like to identify the neighbors of each hexagon so that LISA analysis can determine if the number of trips in a hexagon in a time frame is correlated to the number of trips of the hexagons around it, either in the same direction or opposite direction.\nThe first step to determining the neighborhood is to choose a method by which neighbors are classified:\n\nContiguity-based Method: Based on the sharing of boundaries, either edges and/or points (Queen and Rook method).\nDistance-based Method: Based on the distances between the centroid (central point of each hexagon) of each polygon. This can either be set to a distance where each hexagon has at least one neighbor (Fixed Distance) or where each polygon has a certain number of neighbors (Adaptive Distance).\n\nIt is important to choose the appropriate method according to each situation. However, in this study, Contiguity-based methods can be preemptively ruled out due to the fact that some cells have no contiguous neighbors, as can be seen below.\n\n\n\nIsolated Cells\n\n\nIf the contiguity method is used, the LISA calculation for these cells would not be conducive for analysis as they technically have no neighbors. This can be confirmed by using the st_contiguity() function to create a Queen contiguity matrix for one time frame\n\nwm_q &lt;- st_contiguity(st_geometry(hex_passenger_wd_1720))\n\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 1520 \nNumber of nonzero links: 6874 \nPercentage nonzero weights: 0.2975242 \nAverage number of links: 4.522368 \n9 regions with no links:\n561 726 980 1047 1415 1505 1508 1512 1520\nLink number distribution:\n\n  0   1   2   3   4   5   6 \n  9  39 109 205 291 364 503 \n39 least connected regions:\n1 7 22 38 98 169 187 195 211 218 258 259 264 267 287 454 562 607 642 696 708 732 751 784 869 1021 1022 1046 1086 1214 1464 1471 1482 1500 1501 1503 1506 1510 1519 with 1 link\n503 most connected regions:\n10 13 16 17 24 25 31 35 42 43 48 53 55 60 63 67 73 77 80 81 84 85 87 88 91 92 97 102 107 111 117 121 127 133 140 141 143 148 149 150 154 155 156 157 163 164 165 173 174 175 183 184 185 191 192 193 194 200 201 202 205 206 207 208 216 229 239 243 244 246 257 266 271 278 279 283 284 291 292 298 300 301 302 304 309 310 312 313 316 321 324 325 327 337 338 339 340 343 352 355 363 368 390 391 400 402 403 407 414 418 423 425 431 436 437 438 440 443 450 451 452 461 466 467 468 469 473 477 480 481 485 489 493 494 496 502 503 507 513 514 517 518 523 529 534 539 543 548 549 550 552 556 558 564 568 573 574 576 577 581 590 591 594 598 599 604 605 609 615 619 624 626 633 636 637 638 648 649 650 654 655 657 658 659 669 670 671 677 680 681 682 687 688 690 691 700 701 704 705 706 713 716 717 724 727 728 729 740 741 755 757 758 760 771 774 775 776 777 782 783 787 788 789 792 793 794 795 799 800 806 807 810 811 812 813 819 820 823 824 825 830 831 832 841 843 844 846 847 848 850 851 852 853 854 860 863 865 866 867 871 872 876 877 878 880 881 882 884 885 887 888 891 893 896 899 902 905 906 910 914 919 921 926 927 928 930 931 935 937 943 944 945 946 947 948 954 958 959 962 963 968 969 971 972 973 977 984 985 986 987 988 990 996 997 998 999 1004 1011 1012 1013 1014 1024 1025 1026 1028 1029 1036 1037 1038 1042 1050 1051 1054 1056 1057 1062 1063 1064 1066 1067 1068 1069 1076 1078 1079 1080 1083 1089 1093 1100 1101 1102 1105 1106 1110 1111 1117 1120 1121 1122 1128 1133 1134 1135 1136 1141 1142 1144 1145 1146 1147 1148 1150 1156 1157 1158 1162 1163 1164 1166 1169 1170 1171 1172 1176 1177 1178 1179 1180 1184 1186 1190 1191 1192 1193 1194 1201 1202 1203 1204 1205 1206 1207 1210 1211 1217 1218 1219 1220 1221 1227 1233 1234 1235 1239 1244 1245 1251 1253 1254 1255 1261 1265 1266 1271 1272 1273 1277 1281 1283 1289 1299 1301 1302 1303 1304 1316 1318 1324 1325 1326 1327 1329 1330 1331 1334 1335 1336 1337 1343 1344 1345 1352 1353 1355 1356 1361 1365 1366 1368 1369 1371 1372 1377 1380 1381 1382 1384 1388 1391 1393 1395 1398 1406 1408 1412 1417 1418 1420 1424 1425 1426 1427 1428 1433 1434 1435 1436 1440 1441 1442 1446 1447 1449 1451 1453 1456 1457 1459 1460 1461 1462 1469 with 6 links\n\n\nAs can be seen from the weight matrix, 10 hexagon cells have 0 neighbor. Therefore, a Distance-based Method would be suitable for analysis. Both Fixed Distance and Adaptive Distance Weight Matrix can be created for comparison to find the most appropriate method.\n\n\n\n\nst_dist_band() of sfdep is incredibly powerful in that it can create a neighbor list based on distance between the centroid of polygons and a lower and upper bound distance to other centroid. The default arguments for st_dist_band() will define a lower and upper bound distance from the centroid of a polygon so that each hexagon will have at least one neighbor. This is the equivalent of the steps in spdep of the function knearneigh() of k=1.\nst_inverse_distance() of a sfdep can be combined with st_dist_band() in a dplyr step to create a new column in each data frame of the different time frames to create a neighbor list and a inverse distance weight list. Additionally, st_lag() can be used to create a spatially lagged value column for total trips based on the weight of neighbors.\n\n# Weekday morning peak 6am - 9am\nwd69_nb &lt;- hex_passenger_wd_69 %&gt;%\n  mutate(nb = st_dist_band(area_honeycomb_grid),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nwd1720_nb &lt;- hex_passenger_wd_1720 %&gt;%\n  mutate(nb = st_dist_band(area_honeycomb_grid),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweh1114_nb &lt;- hex_passenger_weh_1114 %&gt;%\n  mutate(nb = st_dist_band(area_honeycomb_grid),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweh1619_nb &lt;- hex_passenger_weh_1619 %&gt;%\n  mutate(nb = st_dist_band(area_honeycomb_grid),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n\n\n\nSince the hexagon tiles is stable across all time frame, it is possible to plot the neighbor relationship for only one time frame in order to visualize the neighbors list created. Let’s take Weekday morning peak 6am - 9am. By visualizing, the appropriateness of the Fixed Distance Method can be roughly determined.\n\nplot(wd69_nb$area_honeycomb_grid, border = 'lightgrey')\nplot(wd69_nb$nb, st_centroid(wd69_nb$area_honeycomb_grid), add=TRUE)\nplot(st_knn(wd69_nb$area_honeycomb_grid, k = 1), st_centroid(wd69_nb$area_honeycomb_grid), add=TRUE, col = 'red', length = 0.08)\n\n\n\n\nDue to the large number of hexagons, the visualization is too dense to delineate any helpful details. However, the summary() function might be of some help to study the neighbors list. Similar to be fore, we ony need to test one time frame.\n\nsummary(wd69_nb$nb)\n\nNeighbour list object:\nNumber of regions: 1520 \nNumber of nonzero links: 76822 \nPercentage nonzero weights: 3.325052 \nAverage number of links: 50.54079 \nLink number distribution:\n\n 1  2  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 \n 2  1  5  1  5  5  1  4  3  3  4  4  3 12 10  8  7  7  9 11 14  7 10 12 13 15 \n31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 \n27 21 15 15 19 18 19 26 25 28 29 33 22 28 24 32 32 25 26 36 32 33 43 35 31 45 \n57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 \n31 35 35 36 48 35 36 47 39 47 38 37 27 32 30 16 25 13 13  3  2 \n2 least connected regions:\n1505 1520 with 1 link\n2 most connected regions:\n729 1076 with 77 links\n\n\nAs can be seen, there are many hexagons with less than 30 neighbors. However, the average number of links is still over 50. This is a draw back of the Fixed Distance method, hexagon cells in denser areas will have more neighbors while those in the periphery or isolated positions will have fewer neighbors. Yet, this lack of neighbor might affect the LISA calculation as the effect of spatial autocorrelation might be smoothed out for those cells with many neighbors\nBetween the Fixed Distance and Adaptive Distance Matrix, an Adaptive Distance Matrix would be more appropriate to the non-uniform nature of bus stop spatial distribution across the map. Using Adaptive Distance would allow for the specification of the number of neighbors, allowing for the standardisation of the LISA analysis process across hexagons.\n\n\n\n\nThe creation of the Adaptive Distance Weight list is largely similar to that of the Fixed Distance Weight list thanks to the sfdep package. The only major amendment is the usage of st_knn() instead of st_distance_band(). st_knn() allows for the forcing of a certain of neighbors for each hexagon cell. This can be accomplished by passing the k argument to st_knn().\n\n# Weekday morning peak 6am - 9am\nwd69_nb &lt;- hex_passenger_wd_69 %&gt;%\n  mutate(nb = st_knn(area_honeycomb_grid, k = 6),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\n\n\nwd1720_nb &lt;- hex_passenger_wd_1720 %&gt;%\n  mutate(nb = st_knn(area_honeycomb_grid, k = 6),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweh1114_nb &lt;- hex_passenger_weh_1114 %&gt;%\n  mutate(nb = st_knn(area_honeycomb_grid, k = 6),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweh1619_nb &lt;- hex_passenger_weh_1619 %&gt;%\n  mutate(nb = st_knn(area_honeycomb_grid, k = 6),\n         wt = st_inverse_distance(nb, area_honeycomb_grid),\n         lag_trip = st_lag(TOTAL_TRIP,nb,wt),\n         .before = 1) # to put them in the front\n\nSimilar to before, the summary() function can be used to check the average number of neighbors for each cell.\n\nsummary(wd69_nb$nb)\n\nNeighbour list object:\nNumber of regions: 1520 \nNumber of nonzero links: 9120 \nPercentage nonzero weights: 0.3947368 \nAverage number of links: 6 \nNon-symmetric neighbours list\nLink number distribution:\n\n   6 \n1520 \n1520 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 with 6 links\n1520 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 with 6 links\n\n\nIt can be seen that all hexagon cells now have 6 neighbors. The LISA calculation can commence."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#local-indicators-of-spatial-autocorrelation-lisa",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#local-indicators-of-spatial-autocorrelation-lisa",
    "title": "Take-Home_Ex1",
    "section": "",
    "text": "The statistical test used for LISA in this study will be the Local Moran’s I. The hypothesis for the Local Moran’s I will be as follow for each time frame:\n\nNull Hypothesis (H0): No Spatial Autocorrelation\nAlternative Hypothesis (H1): There is Spatial Autocorrelation, Positive or Negative\n\nThe result of the test can be determined using the z-score or p-value, we will be using the p-value.\n\n\nlocal_moran() of the sfdep package can be used to calculate Local Moran’s I Statistic and other related statistics. the unnest() function is used to unpack the Local Moran’s statistics into separate columns.\nNote some important arguments when using the local_moran() function.\n\n\n\n\n\n\nNote\n\n\n\n\nnsim: The number of simulations to run. The simulations will create random patterns on the map by reassigning the values and calculate the p-value as the proportions of values as extreme or more extreme than the actual observed values.\nalternative = ‘two.sided’: The default test for local_moran() is a two-sided tests, which is aligned with the H1. ‘greater’ or ‘less’ can be passed to alternative to conduct other types of tests.\n\n\n\n\n# Weekday morning peak 6am - 9am\nwd69_lisa &lt;- wd69_nb %&gt;%\n  mutate(local_moran = local_moran(TOTAL_TRIP, nb, wt, nsim = 199),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nwd1720_lisa &lt;- wd1720_nb %&gt;%\n  mutate(local_moran = local_moran(TOTAL_TRIP, nb, wt, nsim = 199),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweh1114_lisa &lt;- weh1114_nb %&gt;%\n  mutate(local_moran = local_moran(TOTAL_TRIP, nb, wt, nsim = 199),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweh1619_lisa &lt;- weh1619_nb %&gt;%\n  mutate(local_moran = local_moran(TOTAL_TRIP, nb, wt, nsim = 199),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\n# Examining the first 5 rows of the new data frame\nhead(weh1619_lisa)\n\nSimple feature collection with 6 features and 17 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 3720.122 ymin: 27925.48 xmax: 4970.122 ymax: 31533.92\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 18\n      ii       eii  var_ii  z_ii  p_ii p_ii_sim p_folded_sim skewness kurtosis\n   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 0.0525 -0.00412  0.00490 0.808 0.419     0.05        0.025    -3.00    11.4 \n2 0.0695  0.00212  0.00707 0.802 0.423     0.09        0.045    -4.41    30.1 \n3 0.0893  0.00308  0.0109  0.827 0.408     0.03        0.015    -3.54    16.9 \n4 0.0585  0.000808 0.00673 0.703 0.482     0.04        0.02     -4.75    28.4 \n5 0.0719  0.00239  0.00634 0.873 0.382     0.02        0.01     -4.65    29.7 \n6 0.0975  0.0103   0.00633 1.10  0.273     0.03        0.015    -2.05     5.21\n# ℹ 9 more variables: mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;, nb &lt;nb&gt;,\n#   wt &lt;list&gt;, lag_trip &lt;dbl&gt;, grid_id &lt;int&gt;, TOTAL_TRIP &lt;dbl&gt;,\n#   area_honeycomb_grid &lt;POLYGON [m]&gt;\n\n\nA host of statistics related to the Local Moran’s I have been added to the data frame including the I statistic (ii), the p-value (p_ii), and the mean cluster (mean). This will help us to create visualizations that will shed light onto the phenomenon of spatial autocorrelation in the different time frames.\n\n\n\n\n\nIn order to effectively visualize the Local Moran’s I statistics for each time frame, it is preferable to plot the Local Moran’s I values and p-values together. At this point, creating the visualization for each time frame separately instead of all together will allow for easier analysis.\n\n\n\n\n\n\nNote\n\n\n\nAs we would like to only display p-values which indicate statistical significance, we will use a filter and create a custom color palette to indicate that any p-value above 0.05 will not be displayed.\n\n\n\n\n\n\n\n\nNote\n\n\n\nSeveral functions are added to make the map interactive and aesthetically pleasing\n\ntmap_mode(‘view’): Creates an interactive map which allow zooming and interacting with cells on the map\npop.vars: Identifying the legend and value which pops up when a cell is selected. In this case, it is the number of bus stops.\npopup.format: Specifying the format of the variable to be displayed when selecting a cell.\n\n\n\nWeekday Morning Peak 6am - 9am\n\n\nShow the code\np_value_color = c('#bdd7e7','#6baed6', '#2171b5')\n\ntmap_mode('view')\n\n# Spatially Lagged Values\nwd69.lag &lt;- tm_shape(wd69_lisa)+\n  tm_fill('lag_trip',\n          style = \"jenks\", \n          title = \"Spatially Lagged Trips\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"Spatially Lagged Trips: \" = \"lag_trip\"),\n          popup.format = list(\n            lag_trip = list(format = \"f\", digits = 0)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Spatially Lagged Trips\", main.title.position = \"center\")\n\n# Local Moran's I Statistics\nwd69.localmi &lt;- wd69_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('ii',\n          style = \"pretty\", \n          title = \"Local Moran's I Statistics\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"I Statistic: \" = \"ii\"),\n          popup.format = list(\n            ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekday Morning Local Moran's I values\", main.title.position = \"center\")\n\n# Local Moran's I p-values\nwd69.pvalue &lt;- wd69_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('p_ii',\n          breaks = c(-Inf, 0.001, 0.01, 0.05),\n          palette = rev(p_value_color),\n          title = \"Local Moran's I p-values\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"p-value: \" = \"p_ii\"),\n          popup.format = list(\n            p_ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekday Morning Local Moran's I p-values\", main.title.position = \"center\")\n\ntmap_arrange(wd69.lag, wd69.localmi, wd69.pvalue, nrow = 3, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the illustrations, it can be determined that there is spatial clustering in the number of trips, especially in the pattern of hexagons with high number of spatially lagged trips surrounding one with a fewer spatially lagged trips; this pattern is notable around the Jurong and Choa Chu Kang areas in the West and Tampines Area in the East. One can also note this pattern in the Ang Mo Kio and Yishun area in the North and those hexagons around the Woodlands causeway. This is reinforced when one looks at the p-values plot. The surrounding polygons with high spatially lagged trips often have a p-value of less than 0.001, which indicates statistically significant spatial autocorrelation. Their Local Moran’s I Statistics are relatively close to zero, either in the positive or negative direction. They have a small, negative Local Moran’s I, suggesting that they are surrounded by neighbours which are dissimilar to them, likely due to their high spatially lagged values. A possible interpretation of this result is that these are major population centres, also known as the Heartlands, where people in the surrounding areas are congregating due to them hosting major bus interchanges in the morning to get to places of employment or education.\nWeekday Afternoon Peak 5pm - 8pm (17:00 - 20:00)\n\n\nShow the code\ntmap_mode('view')\n\n# Spatially Lagged Values\nwd1720.lag &lt;- tm_shape(wd1720_lisa)+\n  tm_fill('lag_trip',\n          style = \"jenks\", \n          title = \"Spatially Lagged Trips\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"Spatially Lagged Trips: \" = \"lag_trip\"),\n          popup.format = list(\n            lag_trip = list(format = \"f\", digits = 0)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Spatially Lagged Trips\", main.title.position = \"center\")\n\n# Local Moran's I Statistics\nwd1720.localmi &lt;- wd1720_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('ii',\n          style = \"pretty\", \n          title = \"Local Moran's I Statistics\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"I Statistic: \" = \"ii\"),\n          popup.format = list(\n            ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekday Afternoon Local Moran's I values\", main.title.position = \"center\")\n\n# Local Moran's I p-values\nwd1720.pvalue &lt;- wd1720_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('p_ii',\n          breaks = c(-Inf, 0.001, 0.01, 0.05),\n          palette = rev(p_value_color),\n          title = \"Local Moran's I p-values\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"p-value: \" = \"p_ii\"),\n          popup.format = list(\n            p_ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekday Afternoon Local Moran's I p-values\", main.title.position = \"center\")\n\ntmap_arrange(wd1720.lag, wd1720.localmi, wd1720.pvalue, nrow = 3, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Local Moran’s I result for the Weekday afternoon peak 5pm - 8pm is similar to that of the weekday morning peak. A similar pattern of hexagons with high number of spatially lagged trips and statistically significant p-value surrounding those with fewer spatially lagged trips and non-significant p-value reappear here. Interestingly, one of these clusters in Jurong in the West and the two in Ang Mo Kio and Yishun in the North seem to have dissipated in this time window. However, the cluster in Tampines, Choa Chu Kang, and the Woodlands causeway remain. This reinforces the previous observation that these areas consist of major interchanges where the flows of people would congregate before dispersing again. Possibly, this is due to the flow of people returning home after work. This is reinforced by the emergence of individual cells near the Marina Reservoir, also known as part of the Downtown Core, and the office buildings near Harbourfront in the South. They have statistically significant p-value and relatively high spatially lagged trips, possibly indicating flow of people leaving their workplaces.\nWeekend/holiday Morning Peak 11am - 2pm (11:00 - 14:00)\n\n\nShow the code\ntmap_mode('view')\n\n# Spatially Lagged Values\nweh1114.lag &lt;- tm_shape(weh1114_lisa)+\n  tm_fill('lag_trip',\n          style = \"jenks\", \n          title = \"Spatially Lagged Trips\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"Spatially Lagged Trips: \" = \"lag_trip\"),\n          popup.format = list(\n            lag_trip = list(format = \"f\", digits = 0)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Spatially Lagged Trips\", main.title.position = \"center\")\n\n# Local Moran's I Statistics\nweh1114.localmi &lt;- weh1114_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('ii',\n          style = \"pretty\", \n          title = \"Local Moran's I Statistics\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"I Statistic: \" = \"ii\"),\n          popup.format = list(\n            ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Local Moran's I values\", main.title.position = \"center\")\n\n# Local Moran's I p-values\nweh1114.pvalue &lt;- weh1114_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('p_ii',\n          breaks = c(-Inf, 0.001, 0.01, 0.05),\n          palette = rev(p_value_color),\n          title = \"Local Moran's I p-values\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"p-value: \" = \"p_ii\"),\n          popup.format = list(\n            p_ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Local Moran's I p-values\", main.title.position = \"center\")\n\ntmap_arrange(weh1114.lag, weh1114.localmi, weh1114.pvalue, nrow = 3, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn addition to the clusters in the Heartlands as seen previously, the Weekend/holiday Noon Peak 11am – 2pm (11:00 – 14:00) result shows a pattern of cells with statistically significant p-value emerge in the central of Singapore, in the areas of Tiong Bahru, Outram Park, and Orchard Road. These cells are surrounded by other cells with high spatially lagged trips but non-significant p-values. A possible interpretation for these cells is that these are popular areas for people to congregate on the weekends, increasing their number of trips, and due to their proximity, they exhibit statistically significant spatial autocorrelation. A more micro-level analysis might reveal why the bus stops within these areas are more prominent than others. For Orchard, road, the interpretation might be more straightforward, as perennially popular location for locals and tourists alike.\nWeekend/holiday Evening Peak 4pm - 7pm (16:00 - 19:00)\n\n\nShow the code\ntmap_mode('view')\n\n# Spatially Lagged Values\nweh1619.lag &lt;- tm_shape(weh1619_lisa)+\n  tm_fill('lag_trip',\n          style = \"jenks\", \n          title = \"Spatially Lagged Trips\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"Spatially Lagged Trips: \" = \"lag_trip\"),\n          popup.format = list(\n            lag_trip = list(format = \"f\", digits = 0)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Spatially Lagged Trips\", main.title.position = \"center\")\n\n# Local Moran's I Statistics\nweh1619.localmi &lt;- weh1619_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('ii',\n          style = \"pretty\", \n          title = \"Local Moran's I Statistics\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"I Statistic: \" = \"ii\"),\n          popup.format = list(\n            ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Local Moran's I values\", main.title.position = \"center\")\n\n# Local Moran's I p-values\nweh1619.pvalue &lt;- weh1619_lisa %&gt;%\n  filter(p_ii &lt; 0.05) %&gt;%\n  tm_shape()+\n  tm_fill('p_ii',\n          breaks = c(-Inf, 0.001, 0.01, 0.05),\n          palette = rev(p_value_color),\n          title = \"Local Moran's I p-values\",\n          id = 'grid_id',\n          popup.vars = c(\n            \"p-value: \" = \"p_ii\"),\n          popup.format = list(\n            p_ii = list(format = \"f\", digits = 5)))+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = \"Weekend/holiday Morning Local Moran's I p-values\", main.title.position = \"center\")\n\ntmap_arrange(weh1619.lag, weh1619.localmi, weh1619.pvalue, nrow = 3, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLastly, for the Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00) Local Moran’s I result, it is possible to find what seems to be the converge of other the patterns in the previous time windows. There are clusters of statistically significant cells with higher spatially lagged trips emerging in the Heartlands, Tiong Bahru, Orchard Road, and Harbourfront; the notable exception would be the lack of statistically significant cells in the Downtown Core. Aside from the pattern in major population centres, the pattern reinforces the previous observation that there is more activity at bus stops in popular areas for locals and tourists to visit and return during the evening peak period. A possible case for this would be the single cell on Sentosa island, a mostly purely leisure destination.\nOverall, the geospatial autocorrelation pattern that seems to emerge is the movement of people to and from work during the weekday and to leisure spots during the weekend and holiday. This pattern reveals itself through hexagons with higher level of spatially lagged trips, often bus interchanges in population centre, being surrounded by less similar neighbors. Or, hexagons with higher level of spatially lagged trips, often in leisure spots, being nearer to more similar neighbors and hexagons with higher spatially lagged trips but non-significant autocorrelation in the Downtown Core.\nThe observation made can further be examined by visualizing the structure of the relationship between the values of a hexagon and its similarity to its neighbors, or what is categorized in Local Moran’s I as low-low, low-high, high-low, high-high. This is can be done using the Moran Scatterplot andn LISA Cluster Map.\n\n\n\nThe Moran Scatterplot assign each of the hexagon cell of bus stops to one of four quadrants:\n\nHigh - High: Areas of high values surrounded by similar neighbors\nLow - Low: Areas of low values surrounded by similar neighbors\nHigh - Low: Areas of high values surrounded by dissimilar neighbors\nLow - High: Areas of low values surrounded by dissimilar neighbors\n\nThe Moran Scatterplot visualization allows users to roughly comprehend the spatial clustering in the data set. This can be done using the moran.plot() function of the spdep package.\n\n\n\n\n\n\nNote\n\n\n\nDue to the usage of sfdep package, certain functions must be combined with the lisa objects in order for moran.plot() to work correctly.\n\nscale(): The scale function works to center and scale the values. This involves subtracting the value by the mean then dividing it by the standard deviation.\nas.vector(): This function transforms the scaled values into a more easily plottable object.\nnb2listw(): This function transform the neighbor list into a listw object which can be accepted by moran.plot()\n\n\n\n\npar(mfrow = c(2,2))\n\n# Weekday morning peak 6am - 9am\nwd69_scatter &lt;- moran.plot(as.vector(scale(wd69_lisa$TOTAL_TRIP)), nb2listw(wd69_lisa$nb),\n           labels = as.character(wd69_lisa$grid_id),\n           xlab = 'z-Trip',\n           ylab = 'Spatially Lagged z-Trip',\n           main = 'Weekday Morning')\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nwd1720_scatter &lt;- moran.plot(as.vector(scale(wd1720_lisa$TOTAL_TRIP)), nb2listw(wd1720_lisa$nb),\n           labels = as.character(wd1720_lisa$grid_id),\n           xlab = 'z-Trip',\n           ylab = 'Spatially Lagged z-Trip',\n           main = 'Weekday Afternoon')\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweh1114_scatter &lt;- moran.plot(as.vector(scale(weh1114_lisa$TOTAL_TRIP)), nb2listw(weh1114_lisa$nb),\n           labels = as.character(weh1114_lisa$grid_id),\n           xlab = 'z-Trip',\n           ylab = 'Spatially Lagged z-Trip',\n           main = 'Weekend/holiday Noon')\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweh1619_scatter &lt;- moran.plot(as.vector(scale(weh1619_lisa$TOTAL_TRIP)), nb2listw(weh1619_lisa$nb),\n           labels = as.character(weh1619_lisa$grid_id),\n           xlab = 'z-Trip',\n           ylab = 'Spatially Lagged z-Trip',\n           main = 'Weekend/holiday Evening')\n\n\n\n\nThe draw back of the Moran Scatterplot is that we cannot visualize the spatial distribution of the hexagons, as well as the fact that it does not indicate significance of the Local Moran’s I. Additionally, due to density of certain segments, it is difficult to discern their position.\n\n\n\nThe LISA Cluster to which each hexagon belongs can be found in the mean, median, and psyal columns created by local_moran(). This can be used in combination with tmap to create our cluster map. The median will be used for the most accurate representation, accounting for outliers. Similar to before, we will only highlight polygons with a statistically significant value (p_value &lt; 0.05).\nThe four segments of the LISA Cluster Map are similar to those of the Moran Scatterplot:\n\nHigh - High: Areas of high values surrounded by similar neighbors\nLow - Low: Areas of low values surrounded by similar neighbors\nHigh - Low: Areas of high values surrounded by dissimilar neighbors\nLow - High: Areas of low values surrounded by dissimilar neighbors\n\n\ntmap_mode('view')\n\ncluster_palette = c('#0000FF', '#FFB6C1', '#7EC0EE', '#FF0000')\n\n# Weekday morning peak 6am - 9am\nwd69_cluster &lt;- wd69_lisa %&gt;%\n  filter(p_ii &lt;= 0.05) %&gt;%\n  tm_shape()+\n  tm_fill(col = 'mean',\n          title = 'Weekday Morning',\n          palette = cluster_palette)\n\n# Weekday afternoon peak 5pm - 8pm (17:00 - 20:00)\nwd1720_cluster &lt;- wd1720_lisa %&gt;%\n  filter(p_ii &lt;= 0.05) %&gt;%\n  tm_shape()+\n  tm_fill(col = 'mean',\n          title = 'Weekday Afternoon',\n          palette = cluster_palette)\n\n# Weekend/holiday morning peak 11am - 2pm (11:00 - 14:00)\nweh1114_cluster &lt;- weh1114_lisa %&gt;%\n  filter(p_ii &lt;= 0.05) %&gt;%\n  tm_shape()+\n  tm_fill(col = 'mean',\n          title = 'Weekend/holiday Morning',\n          palette = cluster_palette)\n\n# Weekend/holiday evening peak 4pm - 7pm (16:00 - 19:00)\nweh1619_cluster &lt;- weh1619_lisa %&gt;%\n  filter(p_ii &lt;= 0.05) %&gt;%\n  tm_shape()+\n  tm_fill(col = 'mean',\n          title = 'Weekend/holiday Evening',\n          palette = cluster_palette)\n\ntmap_arrange(wd69_cluster, wd1720_cluster, weh1114_cluster, weh1619_cluster, ncol = 2, sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDue to the display of only statistically significant hexagons, the pattern in the LISA Cluster Map is similar to that of the mapping of Local Moran’s I values and p-value. However, it is possible to observe a that there seems to be an interlacing of Low-High cells next to High-High cells. This means that there are cells with low values surrounded by neighbors with high values next cells with high values surrounded by neighbors with high values. Possibly, this might result from some bus stops in a cell which see very few passengers that are near more frequented bus stops in neighboring cells.\nWhat is more interesting that there are groups of statistically significant cells surrounding a non-significant cells. This is the case, for example, for Tampines Interchange whose cell is not statistically significant by itself. This pattern is similar to those in the previous visualizations as well. However, if the raw trip number is used, one will find that this cell often has the highest number of trips. It is possible that due to its and, potentially, other interchanges’ high trip values due to their special statuses, that they are spatial outliers. However, for their neighbors, their high number of trips help to define their level of spatial autocorrelation in the negative positive direction."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#conclusion",
    "href": "Take-Home_Ex/Take-Home_Ex1/Take-Home_Ex1.html#conclusion",
    "title": "Take-Home_Ex1",
    "section": "",
    "text": "This study aimed to conduct exploratory data analysis and analysis of LISA on the number of trips by origin bus stop in Singapore for four time frames: Weekday Morning, Weekday Afternoon, Weekend/holiday Morning, Weekend/holiday Evening. The analysis was done based on a layer of hexagon cells, each consisting of a certain number of bus stops.\nData preparation was done on aspatial and geospatial data sets which were retrieved from LTA Data Mall. For aspatial data, this required separating the bus stop trips by origin bus stops in September 2023 into four different time frames. Subsequently, the number of trips were tallied by the origin bus stops. For geospatial data, hexagon layers were created based on the geometry of the bus stops’ location in Singapore. The hexagons have an edge-to-edge distance of 500 metre. Finally the aspatial and geospatial data sets were combined so that each hexagon would contain a certain number of bus stops and their total number of trips for each of the four time frame.\nExploratory Data Analysis in the form of descriptive analysis and geovisualization shows that each hexagon can contain a wide range of bus trips, due to its number of bus stops as well as the popularity of the bus stops. Additionally, the range of trips in each time frame are different, with higher values tending to be during the Weekday periods. It was also found that there seems to be visual clusters where hexagons with higher number of trips tend to be nearer to each other. This provided the rationale for LISA analysis.\nBefore LISA analysis was conducted, the neighborhood was defined using the Adaptive Distance Matrix, due to the inappropriateness of the Contiguity and Fixed Distance Matrix methods. The neighbor list, weight list using inverse distance matrix, and spatially lagged number of trips were then created for each hexagon for each time frame.\nA null and alternative hypotheses were defined before conducting the LISA analysis. The LISA analysis consisted of calculating the relevant Local Moran’s I statistics for each hexagon for each time frame and visualizing them. In addition, the Moran scatter plot and LISA cluster map were created using the quadrant structure. In order to maintain visual comprehensibility, only hexagons with a statistically significant p-value were visualized. From these analysis, it was found that there were a different pattern of bus stop usage from Weekday Morning to Weekday Afternoon and Weekend/Holiday Noon to Weekend/Holiday Evening as people go and return from work or leisure activities. There were clustering around areas with high number of bus trips, resulting in a number of High-High and Low-High, where less frequented bus stops were neighbors with highly frequented bus stops. Lastly, it was determined that major bus interchanges and stops, which have very high number of trips, could be spatial outliers which are not statistically significant due to their high values, but do affect the spatial relationships of their neighbors.\n\n\nFuture studies might consider studying the flow of bus trips in order to have better grasp of the demand during different time frames. This might better explain the effect of bus interchanges, where many bus services terminate and begin.\nAdditionally, the usage of bus stops can be considered in conjunction with the usage of MRT stations as they can work in tandem, especially where bus interchanges are concerned.\nFor future analysis, different types of bus services should be differentiated as feeder bus services are different from long-haul or express bus services, albeit being highly essential to the transportation needs in local communities. This could be done by adding an extra variable to classify the bus stop based on the majority of their bus services."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS624",
    "section": "",
    "text": "Welcome to ISSS624 Geospatial Analytics Applications!\nIn this webpage, I am going to share with you my learning journey of geospatial analytics."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/data/geospatial/Retails.html",
    "href": "In-Class_Ex/In-Class_Ex4/data/geospatial/Retails.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/data/geospatial/Liesure&Recreation.html",
    "href": "In-Class_Ex/In-Class_Ex4/data/geospatial/Liesure&Recreation.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/data/geospatial/F&B.html",
    "href": "In-Class_Ex/In-Class_Ex4/data/geospatial/F&B.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/data/geospatial/Business.html",
    "href": "In-Class_Ex/In-Class_Ex4/data/geospatial/Business.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex3/data/geospatial/MPSZ-2019.html",
    "href": "In-Class_Ex/In-Class_Ex3/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_EHSA.html",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_EHSA.html",
    "title": "In-Class_Ex2_EHSA",
    "section": "",
    "text": "Loading R packages. The plotly library is added to create interactive maps.\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse, knitr)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_EHSA.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_EHSA.html#getting-started",
    "title": "In-Class_Ex2_EHSA",
    "section": "",
    "text": "Loading R packages. The plotly library is added to create interactive maps.\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse, knitr)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_EHSA.html#the-data",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_EHSA.html#the-data",
    "title": "In-Class_Ex2_EHSA",
    "section": "The Data",
    "text": "The Data\n\nImporting geospatial data\nst_read() can be used to read the shape file data set into an R sf data frame\n\nhunan &lt;- st_read(dsn = 'data/geospatial',\n                 layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImporting time series file\nread_csv() can be used to read the time series file into an R data frame\n\nGDPPC &lt;- read_csv('data/aspatial/Hunan_GDPPC.csv')"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_EHSA.html#creating-a-time-series",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_EHSA.html#creating-a-time-series",
    "title": "In-Class_Ex2_EHSA",
    "section": "Creating a Time Series",
    "text": "Creating a Time Series\nspacetime() can be used to create a Space Time Cube\n\nGDPPC_st &lt;- spacetime(GDPPC, hunan,\n                      .loc_col = 'County',\n                      .time_col = 'Year')\n\nis_spacetime_cube() can be used to check whether the created object is actually a spacetime cube\n\nis_spacetime_cube(GDPPC_st)\n\n[1] TRUE\n\n\n\nCreating Inverse Distance Weight Matrix Columns for GI*\n\nGDPPC_nb &lt;- GDPPC_st %&gt;%\n  activate('geometry') %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale = 1,\n                                  alpha = 1),\n         .before = 1)%&gt;%\n  set_nbs('nb') %&gt;%\n  set_wts('wt')\n\n\n\nComputing GI*\nComputing GI* using the newly created data frame with the neighbor list and weight matrix for each county for each year\n\ngi_stars &lt;- GDPPC_nb %&gt;%\n  group_by(Year) %&gt;%\n  mutate(gi_star = local_gstar_perm(GDPPC, nb, wt)) %&gt;%\n  unnest(gi_star)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_EHSA.html#man-kendall-test",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_EHSA.html#man-kendall-test",
    "title": "In-Class_Ex2_EHSA",
    "section": "Man-Kendall Test",
    "text": "Man-Kendall Test\n\nPerforming Emerging Hotspot Analysis\nemerging_hotspot_analysis() can be used to perform the Emerging Hotspot Analysis using the space time cube object\n\nehsa &lt;- emerging_hotspot_analysis(\n  x = GDPPC_st,\n  .var = 'GDPPC',\n  k = 1, #Comparing the Time Series sequentially (e.g. 2012 vs 2013)\n  nsim = 99\n)\n\nPlotting the distribution of hotspot type\n\nggplot(ehsa, aes(x=classification))+\n  geom_bar()+\n  theme_classic()\n\n\n\n\n\n\nVisualizing EHSA\n\nehsa_rename &lt;- ehsa %&gt;%\n  rename(County = location)\n\nhunan_ehsa &lt;- left_join(hunan, ehsa_rename,\n                        by = 'County')\n\nehsa_sig &lt;- hunan_ehsa %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode('plot')\ntm_shape(hunan_ehsa) +\n  tm_polygons()+\n  tm_borders(alpha = 0.5)+\n  tm_shape(ehsa_sig)+\n  tm_fill('classification')+\n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "To prepare a choropleth map showing the distribution of passenger trips at planning sub-zone by integrating Passenger Volume by Origin Destination Bus Stops and bus stop data sets downloaded from LTA DataMall and Planning Sub-zone boundary of URA Master Plan 2019 from data.gov.sg."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#the-task",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#the-task",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "To prepare a choropleth map showing the distribution of passenger trips at planning sub-zone by integrating Passenger Volume by Origin Destination Bus Stops and bus stop data sets downloaded from LTA DataMall and Planning Sub-zone boundary of URA Master Plan 2019 from data.gov.sg."
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#getting-started",
    "title": "In-Class Exercise 1",
    "section": "Getting Started",
    "text": "Getting Started\nLoading the necessary packages in R:\n\ntmap: for thematic mapping\nsf: for geospatial data handling\ntidyverse: for non-spatial data handling\n\n\npacman::p_load(tmap, tidyverse, sf, knitr)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#importing-the-od-data",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#importing-the-od-data",
    "title": "In-Class Exercise 1",
    "section": "Importing the OD Data",
    "text": "Importing the OD Data\nFirstly we will import the Passenger Volume by Origin Destination Bus Stops data downloaed from LTA DataMall by using read_csv() of readr package\n\n# eval:false\nodbus &lt;- read_csv('data/aspatial/origin_destination_bus_202308.csv')\n\nWe can check the odbus tibble dataframe to explore the data types\n\nglimpse(odbus)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"4406…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"1722…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …\n\n\nWe can convert ORIGIN_PT_CODE and DESTINATION_PT_CODE into Factor data, a data type unique to R, in order to speed up sorting\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\nWe can confirm that the data types of ORIGIN_PT_CODE and DESTINATION_PT_CODE using glimpse()\n\nglimpse(odbus)\n\nRows: 5,709,512\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-08\", \"2023-08\", \"2023-08\", \"2023-08\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 17, 7, 17, 14, 10, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;fct&gt; 04168, 04168, 80119, 80119, 44069, 44069, 20281, 2…\n$ DESTINATION_PT_CODE &lt;fct&gt; 10051, 10051, 90079, 90079, 17229, 17229, 20141, 2…\n$ TOTAL_TRIPS         &lt;dbl&gt; 7, 2, 3, 10, 5, 4, 3, 22, 3, 3, 7, 1, 3, 1, 3, 1, …"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#extracting-the-study-data",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#extracting-the-study-data",
    "title": "In-Class Exercise 1",
    "section": "Extracting the study data",
    "text": "Extracting the study data\nIf we want to pick out the commuter data between 7 and 9 o clock on weekdays\n\norigin_7_9 &lt;- odbus %&gt;%   filter(DAY_TYPE == 'WEEKDAY') %&gt;%   filter(TIME_PER_HOUR &gt;=7 & TIME_PER_HOUR &lt;=9) %&gt;%   group_by(ORIGIN_PT_CODE)%&gt;%   summarise(TRIPS = sum(TOTAL_TRIPS))\n\nWe can check the data table using the code below\n\nkable(head(origin_7_9))\n\n\n\n\nORIGIN_PT_CODE\nTRIPS\n\n\n\n\n01012\n1617\n\n\n01013\n813\n\n\n01019\n1620\n\n\n01029\n2383\n\n\n01039\n2727\n\n\n01059\n1415\n\n\n\n\n\nWe will save the output in rds format for future use\n\nwrite_rds(origin_7_9, 'data/rds/origin_7_9.rds')\n\nWe can read the origin7_9.rds into R using the code below\n\norigin_7_9 &lt;- read_rds('data/rds/origin_7_9.rds')"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#working-with-geospatial-data",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#working-with-geospatial-data",
    "title": "In-Class Exercise 1",
    "section": "Working with Geospatial Data",
    "text": "Working with Geospatial Data\nTwo geospatial data will be used in this study:\n\nBusStop: Location of bus stops in the last quarter of 2022\nMPSZ-2019: Master Plan Boundary (No Sea) of Singapore in 2019\n\n\nImporting geospatial data\nWe can import the BusStop shape file into an R simple feature dataframe using st_read()\n\nbusstop &lt;- st_read(dsn = 'data/geospatial',\n                   layer = 'BusStop')\n\nReading layer `BusStop' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nWe can check the structure and data types of the new busstop dataframe using glimpse()\n\nglimpse(busstop)\n\nRows: 5,161\nColumns: 4\n$ BUS_STOP_N &lt;chr&gt; \"22069\", \"32071\", \"44331\", \"96081\", \"11561\", \"66191\", \"2338…\n$ BUS_ROOF_N &lt;chr&gt; \"B06\", \"B23\", \"B01\", \"B05\", \"B05\", \"B03\", \"B02A\", \"B02\", \"B…\n$ LOC_DESC   &lt;chr&gt; \"OPP CEVA LOGISTICS\", \"AFT TRACK 13\", \"BLK 239\", \"GRACE IND…\n$ geometry   &lt;POINT [m]&gt; POINT (13576.31 32883.65), POINT (13228.59 44206.38),…\n\n\nAs the busstop data frame has a CRS of SVY21, we want to transform it into a CRS of SVY21 / Singapore TM (EPSG 3414) using st_transform()\n\nbusstop &lt;- st_transform(busstop, crs = 3414)\n\nWe can next import the Master Plan Sub-zone Boundary 2019 shape file into a simple feature dataframe using st_read()\n\nmpsz &lt;- st_read(dsn = 'data/geospatial',\n                layer = 'MPSZ-2019')\n\nReading layer `MPSZ-2019' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nWe can see that the CRS for the mpsz dataframe is WGS 84 (or EPSG 4326), we want it to be SVY21 (or EPSG 3414). We can do this by using st_transform()\n\nmpsz &lt;- st_transform(mpsz, 3414)\n\nWe can double check the CRS of mpsz using st_geometry(). We can see that the Projected CRS is now SVY21\n\nst_geometry(mpsz)\n\nGeometry set for 332 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#geospatial-data-wrangling",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#geospatial-data-wrangling",
    "title": "In-Class Exercise 1",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\n\nCombining busstop and mpsz\nThis code below populates the planning subzone code (SUBZONE_C) of mpsz data frame into the busstop data frame. st_intersection() is used to perform point and polygon overlap and the output will be in point simple feature object.\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\nWe will save the new data frame into rds format\n\nwrite_rds(busstop_mpsz, 'data/rds/busstop_mpsz.csv')\n\nNext, we are going to append the planning subzone code from busstop_mpsz data frame onto origin_7_9 data frame\n\norigin_data &lt;- left_join(origin_7_9, busstop_mpsz,\n                         by = c('ORIGIN_PT_CODE' = 'BUS_STOP_N')) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C)\n\nIt is good practice to check for duplicate records\n\nduplicate &lt;- origin_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nIf duplicated records are found, the code chunk below will be used to retain only the unique records\n\norigin_data &lt;- unique(origin_data)\n\nWe can re-reun the code chunk to check for duplicate records in the new data frame. We will now see that the duplicate dataframe contains 0 observation.\n\nduplicate &lt;- origin_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nNow, we can append the bus stop code and number of trips starting from that code onto the original mpsz data frame (which contains the geometry information for mapping)\n\nmpsz_origtrip &lt;- left_join(mpsz, origin_data,\n                         by = c('SUBZONE_C' = 'ORIGIN_SZ'))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#choropleth-visualization",
    "href": "In-Class_Ex/In-Class_Ex1/In-Class_Ex1.html#choropleth-visualization",
    "title": "In-Class Exercise 1",
    "section": "Choropleth Visualization",
    "text": "Choropleth Visualization\nTo create a choropleth visualization, we can using the tmap package\n\ntm_shape(mpsz_origtrip)+\n  tm_fill('TRIPS',\n          n = 6,\n          style = 'quantile',\n          palette = 'Blues')+\n  tm_layout(main.title = 'Passenger Trips Generated at Planning Sub-zone Level',\n            main.title.position = 'center',\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = '8star', size = 2)+\n  tm_scale_bar()+\n  tm_grid(alpha = 0.2)+\n  tm_credits('Source: Planning Sub-zone Boundary from Urban Redevelopment Authority (URA) \\n and Population Data from Department of Statistics (DOS)',\n             position = c('left','bottom'))\n\n\n\n\nWe can use a map using custom breaks for comparison. Before that, we can use the summary function to determine appropriate breakpoints\n\nsummary(mpsz_origtrip$TRIPS)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n     1.0    386.5   1773.0   4191.5   5002.0 295128.0       21 \n\n\nThen, we can draw the map using the tmap package\n\ntm_shape(mpsz_origtrip)+\n  tm_fill('TRIPS',\n          breaks = c(0, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000),\n          palette = 'Blues')+\n  tm_layout(main.title = 'Passenger Trips Generated at Planning Sub-zone Level',\n            main.title.position = 'center',\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = '8star', size = 2)+\n  tm_scale_bar()+\n  tm_grid(alpha = 0.2)+\n  tm_credits('Source: Planning Sub-zone Boundary from Urban Redevelopment Authority (URA) \\n and Population Data from Department of Statistics (DOS)',\n             position = c('left','bottom'))\n\n\n\n\nIt can be seen that due to the large variations in number of trips between different planning sub-zones, the custom breaks are not as insightful as the ‘quantile’ style built into tmap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "Spatial interaction represents the flow of people, material, or information between locations in geographical space. It encompasses everything from freight shipments, energy flows, and the global trade in rare antiquities, to flight schedules, rush hour woes, and pedestrian foot traffic.\nEach spatial interaction, as an analogy for a set of movements, is composed of a discrete origin/destination pair. Each pair can be represented as a cell in a matrix where rows are related to the locations (centroids) of origin, while columns are related to locations (centroids) of destination. Such a matrix is commonly known as an origin/destination matrix, or spatial interaction matrix.\nWe will by an OD Matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded in the previous exercises.\n\n\n\nThe following package will be loaded in with the p_load() function of pacman: sf, tidyverse, tmap, DT, stplanr.\n\npacman::p_load(sf, tidyverse, tmap, DT, stplanr)\n\n\n\n\n\n\nWe will import the Passenger Volume by Origin Destination Bus Stops using read_csv().\n\nodbus &lt;- read_csv('data/aspatial/origin_destination_bus_202310.csv')\n\nglimpse() can be used to display the data type and some rows of the odbus data frame.\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nORIGIN_PT_CODE and DESTINATION_PT_CODE are in character data type whereas they should be converted into factor data type for easier manipulation.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\n\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\n\n\n\nWe will only look at commuting flows on weekday between 6 and 9 o’clock. This can be extracted using the filter() function.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == 'WEEKDAY') %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\ndatatable() can be used to view odbus6_9\n\ndatatable(odbus6_9)\n\n\n\n\n\n\nWe will save the output in rds format for future use.\n\nwrite_rds(odbus6_9, 'data/rds/odbus6_9.rds')\n\nread_rds() can be used to import the rds file into R.\n\nodbus6_9 &lt;- read_rds('data/rds/odbus6_9.rds')\n\n\n\n\n\nTwo geospatial data sets will be used:\n\nBusStop: This data provides the location of bus stops as at July 2023\nMPSZ-2019: this data provides the sub-zone boundary of URA Master Plan 2019.\n\nBoth data sets are in ESRI shapefile format.\n\n\n\nbusstop &lt;- st_read(dsn = 'data/geospatial',\n                   layer = 'BusStop') %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = 'data/geospatial',\n                layer = 'MPSZ-2019') %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\nWe can write the mpsz sf tibble data frame into an rds file for future use.\n\nwrite_rds(mpsz, \"data/rds/mpsz.rds\")\n\n\n\n\n\n\n\nWe can populate the planning subzone code (SUBZONE_C) of mpsz sf data frame into busstop sf data frame\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\ndatatable(busstop_mpsz)\n\n\n\n\n\n\nBefore moving to the next step, it is wise to save the output into rds format.\n\nwrite_rds(busstop_mpsz, 'data/rds/busstop_mpsz.rds')\n\nWe are going to append the planning subzone code from busstop_mpsz data frame onto odbus6_9 data frame.\n\nod_data &lt;- left_join(odbus6_9, busstop_mpsz, by = c('ORIGIN_PT_CODE' = 'BUS_STOP_N')) %&gt;%\n  rename(ORGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nBefore continuing, it is a good practice for us to check for duplicating records\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup\n\nIf duplicated records are found, we can remove them using unique().\n\nod_data &lt;- unique(od_data)\n\nWe can reconfirm whether the duplicated records have been removed.\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nWe can confirm that there is no more duplicate records.\nNow, we can update od_data with the planning subzone codes for destination subzone.\n\nod_data &lt;- left_join(od_data, busstop_mpsz, by = c('DESTIN_BS'= 'BUS_STOP_N'))\n\nNext, we can check for duplicate record and proceed to remove them\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nod_data &lt;- unique(od_data)\n\nNext, we can rename the new subzone column and summarise the total number of trips by each origin and destination subzones.\n\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\nNow, we can save the output into an rds file format.\n\nwrite_rds(od_data, 'data/rds/od_data.rds')\n\n\nod_data &lt;- read_rds('data/rds/od_data.rds')\n\n\n\n\n\nWe can prepare a desire line by using the stplanr package.\n\n\nWe will not plot the intra-zonal flows.\n\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ != od_data$DESTIN_SZ,]\n\n\n\n\nod2line() is used to create the desire lines.\n\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = 'SUBZONE_C')\n\n\n\n\nWe can use the tmap package to visualize the desire line.\n\ntmap_mode('plot')\ntm_shape(mpsz)+\n  tm_polygons() +\n  flowLine %&gt;%\n  tm_shape()+\n  tm_lines(lwd = 'MORNING_PEAK',\n           style = 'quantile',\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\n\n\n\nWhen the flow data are very messy, and highly skewed like the one shown above, it is wiser to focus on selected flows. For example, flow greater than or equal to 5000 as shown below.\n\ntm_shape(mpsz)+\n  tm_polygons()+\n  flowLine %&gt;%\n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\n  tm_shape()+\n  tm_lines(lwd = 'MORNING_PEAK',\n           style = 'quantile',\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#overview",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "Spatial interaction represents the flow of people, material, or information between locations in geographical space. It encompasses everything from freight shipments, energy flows, and the global trade in rare antiquities, to flight schedules, rush hour woes, and pedestrian foot traffic.\nEach spatial interaction, as an analogy for a set of movements, is composed of a discrete origin/destination pair. Each pair can be represented as a cell in a matrix where rows are related to the locations (centroids) of origin, while columns are related to locations (centroids) of destination. Such a matrix is commonly known as an origin/destination matrix, or spatial interaction matrix.\nWe will by an OD Matrix by using Passenger Volume by Origin Destination Bus Stops data set downloaded in the previous exercises."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#getting-started",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "The following package will be loaded in with the p_load() function of pacman: sf, tidyverse, tmap, DT, stplanr.\n\npacman::p_load(sf, tidyverse, tmap, DT, stplanr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#preparing-the-flow-data",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#preparing-the-flow-data",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "We will import the Passenger Volume by Origin Destination Bus Stops using read_csv().\n\nodbus &lt;- read_csv('data/aspatial/origin_destination_bus_202310.csv')\n\nglimpse() can be used to display the data type and some rows of the odbus data frame.\n\nglimpse(odbus)\n\nRows: 5,694,297\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2023-10\", \"2023-10\", \"2023-10\", \"2023-10\", \"2023-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKDAY\", \"WEEKENDS/HOLIDAY\",…\n$ TIME_PER_HOUR       &lt;dbl&gt; 16, 16, 14, 14, 17, 17, 17, 7, 14, 14, 10, 20, 20,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"04168\", \"04168\", \"80119\", \"80119\", \"44069\", \"2028…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"10051\", \"10051\", \"90079\", \"90079\", \"17229\", \"2014…\n$ TOTAL_TRIPS         &lt;dbl&gt; 3, 5, 3, 5, 4, 1, 24, 2, 1, 7, 3, 2, 5, 1, 1, 1, 1…\n\n\nORIGIN_PT_CODE and DESTINATION_PT_CODE are in character data type whereas they should be converted into factor data type for easier manipulation.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\n\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)\n\n\n\n\nWe will only look at commuting flows on weekday between 6 and 9 o’clock. This can be extracted using the filter() function.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == 'WEEKDAY') %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\ndatatable() can be used to view odbus6_9\n\ndatatable(odbus6_9)\n\n\n\n\n\n\nWe will save the output in rds format for future use.\n\nwrite_rds(odbus6_9, 'data/rds/odbus6_9.rds')\n\nread_rds() can be used to import the rds file into R.\n\nodbus6_9 &lt;- read_rds('data/rds/odbus6_9.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#working-with-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#working-with-geospatial-data",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "Two geospatial data sets will be used:\n\nBusStop: This data provides the location of bus stops as at July 2023\nMPSZ-2019: this data provides the sub-zone boundary of URA Master Plan 2019.\n\nBoth data sets are in ESRI shapefile format.\n\n\n\nbusstop &lt;- st_read(dsn = 'data/geospatial',\n                   layer = 'BusStop') %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5161 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = 'data/geospatial',\n                layer = 'MPSZ-2019') %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex3\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\nWe can write the mpsz sf tibble data frame into an rds file for future use.\n\nwrite_rds(mpsz, \"data/rds/mpsz.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#geospatial-data-wrangling",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "We can populate the planning subzone code (SUBZONE_C) of mpsz sf data frame into busstop sf data frame\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\n\ndatatable(busstop_mpsz)\n\n\n\n\n\n\nBefore moving to the next step, it is wise to save the output into rds format.\n\nwrite_rds(busstop_mpsz, 'data/rds/busstop_mpsz.rds')\n\nWe are going to append the planning subzone code from busstop_mpsz data frame onto odbus6_9 data frame.\n\nod_data &lt;- left_join(odbus6_9, busstop_mpsz, by = c('ORIGIN_PT_CODE' = 'BUS_STOP_N')) %&gt;%\n  rename(ORGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nBefore continuing, it is a good practice for us to check for duplicating records\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup\n\nIf duplicated records are found, we can remove them using unique().\n\nod_data &lt;- unique(od_data)\n\nWe can reconfirm whether the duplicated records have been removed.\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nWe can confirm that there is no more duplicate records.\nNow, we can update od_data with the planning subzone codes for destination subzone.\n\nod_data &lt;- left_join(od_data, busstop_mpsz, by = c('DESTIN_BS'= 'BUS_STOP_N'))\n\nNext, we can check for duplicate record and proceed to remove them\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\nod_data &lt;- unique(od_data)\n\nNext, we can rename the new subzone column and summarise the total number of trips by each origin and destination subzones.\n\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\nNow, we can save the output into an rds file format.\n\nwrite_rds(od_data, 'data/rds/od_data.rds')\n\n\nod_data &lt;- read_rds('data/rds/od_data.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#visualizing-spatial-interaction",
    "href": "Hands-on_Ex/Hands-on_Ex3/Hands-on_Ex3.html#visualizing-spatial-interaction",
    "title": "Hands-on_Ex3",
    "section": "",
    "text": "We can prepare a desire line by using the stplanr package.\n\n\nWe will not plot the intra-zonal flows.\n\nod_data1 &lt;- od_data[od_data$ORIGIN_SZ != od_data$DESTIN_SZ,]\n\n\n\n\nod2line() is used to create the desire lines.\n\nflowLine &lt;- od2line(flow = od_data1, \n                    zones = mpsz,\n                    zone_code = 'SUBZONE_C')\n\n\n\n\nWe can use the tmap package to visualize the desire line.\n\ntmap_mode('plot')\ntm_shape(mpsz)+\n  tm_polygons() +\n  flowLine %&gt;%\n  tm_shape()+\n  tm_lines(lwd = 'MORNING_PEAK',\n           style = 'quantile',\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\n\n\n\nWhen the flow data are very messy, and highly skewed like the one shown above, it is wiser to focus on selected flows. For example, flow greater than or equal to 5000 as shown below.\n\ntm_shape(mpsz)+\n  tm_polygons()+\n  flowLine %&gt;%\n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\n  tm_shape()+\n  tm_lines(lwd = 'MORNING_PEAK',\n           style = 'quantile',\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise:\n\nHunan County Boundary Layer: Geospatial data set in ESRI shapefile format\nHunan_2012.csv: Selected local development indicators in 2012\n\n\n\nWe will use the p_load() function of the pacman package to load the required packages: spdep (for spatial weights), sf, tmap, and tidyverse.\n\npacman::p_load(spdep, tmap, sf, knitr, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#the-study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#the-study-area-and-data",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "",
    "text": "Two data sets will be used in this hands-on exercise:\n\nHunan County Boundary Layer: Geospatial data set in ESRI shapefile format\nHunan_2012.csv: Selected local development indicators in 2012\n\n\n\nWe will use the p_load() function of the pacman package to load the required packages: spdep (for spatial weights), sf, tmap, and tidyverse.\n\npacman::p_load(spdep, tmap, sf, knitr, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#getting-the-data-into-the-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#getting-the-data-into-the-r-environment",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Getting the Data into the R Environment",
    "text": "Getting the Data into the R Environment\n\nImport Shapefile into R Environment\nst_read() can be used to import the Hunan shapefile into a sf dataframe\n\nhunan &lt;- st_read(dsn = 'data/geospatial',\n                 layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImport Attribute Data (aspatial) into R Environment\nread_csv() can be used to import the Hunan_2012.csv into R as a data frame\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\nPerforming Relational Join\nSince both data frames have 88 rows and share the ‘County’ column, we can use left_join() to update the hunan sf data frame with with attribute fields of hunan2012 data frame.\n\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nThe left_join() argument automatically seeks out the shared field for joining. In this case, it is ‘by = join_by(County)’."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#visualizing-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#visualizing-regional-development-indicator",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Visualizing Regional Development Indicator",
    "text": "Visualizing Regional Development Indicator\nwe can prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of the tmap package.\n\nbasemap &lt;- tm_shape(hunan)+\n  tm_polygons() +\n  tm_text('NAME_3', size = 0.3) #A basemap is created showing the boundaries and names of counties in Hunan\n\ngdppc &lt;- qtm(hunan, 'GDPPC') # A choropleth map showing the distribution of GDPPC in Hunan\n\ntmap_arrange(basemap, gdppc, asp = 1, ncol = 2) # Arranging basemap and gdppc along two columns"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#computing-contiguity-spatial-weights",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Computing Contiguity Spatial Weights",
    "text": "Computing Contiguity Spatial Weights\nWe can use poly2nb() of spep to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries.\nIn poly2nb(), you can pass TRUE or FALSE to the queen argument in order to indicate whether to use the queen method. The default is TRUE.\n\nComputing (QUEEN) contiguity based neighbours\n\nwm_q &lt;- poly2nb(hunan, queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours (area 85). There are two area units with only 1 neighbour (30 and 65).\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. To see the neighbors for the first polygon in the object, you can specify it similar to a list of list\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan spdf class\nWe can retrieve the county name of Polygon ID = 1 by specifying it its position in the hunan data fram\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nSimilarly, you can extract the name of its neighbors using their Polygon ID in wm_q\n\nhunan$County[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can also retreive the GDPPC of these five counties\n\nnb1 &lt;- wm_q[[1]]\nnb1_gdppc &lt;- hunan$GDPPC[nb1]\nnb1_gdppc\n\n[1] 20981 34592 24473 21311 22879\n\n\nAdditionally, you can display the complete neighbor list using str() However, this output will cut across several pages.\n\n\nCreating (ROOK) Contiguity Based Neighbours\nWe can use Rook contiguity instead of Queen contiguity by passing FALSE to the queen argument of poly2nb\n\nwm_r &lt;- poly2nb(hunan, queen = FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nSimilar to Queen, the number of area units in Hunan remains unchanged at 88. However, the most connected area unit has only 10 neighbours (area 85). The two area units with only one neighbour remain the same (area 30 and 65).\n\n\nVisualizing Contiguity Weights\nA connectivity graph takes a point and displays a line to each neighboring point.\nWe are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typical method for this will be polygon centroids.\nWe can use the sf package to get Latitude and Longitude of polygon centroids before moving onto the graphs.\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object. We need the coordinates in a separate data frame. To do this we will use a mapping function.\nThe mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of hunan. Our function will be st_centroid. We will be using map_dbl() variation of map from thhe purrr package.\nTo get our longitude values, we map the st_centroid function over the geometry column of hunan and access the longitude value through double bracket notation [[]] and 1 ([[1]]]). This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe can do the same for latitude, only with [[2]] instead.\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have longitude and latitude, we can use cbind to put them together into the same object (coords) as two separate columns\n\ncoords_hunan &lt;- cbind(longitude, latitude)\n\nWe can check the first few observation of this new object using head()\n\nhead(coords_hunan)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\nPlotting Queen Contiguity Based Neighbours Map\nThe contiguity map will draw a line between the centroid of each polygon and the centroids of its neighbors based on the Queen Contiguity.\n\nplot(hunan$geometry, border = 'lightgrey')\nplot(wm_q,coords_hunan, pch = 19, cex = 0.6, add = TRUE, col = 'red')\n\n\n\n\nIf we use plot(wm_q, coords_hunan) by itself, it will only provide a contiguity map with no border for each county.\n\n\nPlotting Rook Contiguity Based Neighbours Map\nWe can easily make a Rook contiguity map instead of a Queen contiguity map by using wm_r instead of wm_q\n\nplot(hunan$geometry, border = 'lightgrey')\nplot(wm_r, coords_hunan, pch = 19, cex = 0.6, add = TRUE, col = 'red')\n\n\n\n\n\n\nPlotting both Queen and Rook Contiguity Based Neighbours Maps\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, main = 'Queen Contiguity', border = 'lightgrey')\nplot(wm_q, coords_hunan, pch = 19, cex = 0.6, add = TRUE, col = 'red')\nplot(hunan$geometry, main = 'Rook Contiguity', border = 'lightgrey')\nplot(wm_r, coords_hunan, pch = 19, cex = 0.6, add = TRUE, col = 'red')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#computing-distance-based-neighbours",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Computing Distance Based Neighbours",
    "text": "Computing Distance Based Neighbours\nDistance-based weight matrices can be derived using dnearneigh() of spdep.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument.\nIf unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat = TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\nDetermine the Cut-off Distance\nFirst, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of sdpep\nConvert the k nearest neighbour object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb()\nReturn the length of neighbour relationship edges by using nbdist() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\nk1 &lt;- knn2nb(knearneigh(coords_hunan))\nk1dists &lt;- unlist(nbdists(k1, coords_hunan, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\nComputing Fixed Distance Weight Watrix\ndnearneigh() can be used to compute the distance weight matrix. It will create an object containing the neighbors of a each id based on their distance in km with a lower bound d1=0 and upper bound d2=62\n\nwm_d62 &lt;- dnearneigh(coords_hunan, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nstr() can be used to display the content of wm_d62\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords_hunan, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n\nPlotting Fixed Distance Weight Matrix\nWe can plot the distance weight matrix using the code chunk below\n\nplot(hunan$geometry, border = 'lightgrey')\nplot(wm_d62, coords_hunan, add = TRUE) #add centroids and links between neighbors\nplot(k1, coords_hunan, add = TRUE, col = 'red', length = 0.08) #add red coloration to the nearest neighbor based on distance\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot two separate plots next to each other, one with centroid for each region and the links to all its neighbors, and one with centroid for each region and the link to its 1st nearest neighbor.\n\npar(mfrow = c(1,2))\nplot(hunan$geometry, border = 'lightgrey', main = '1st Nearest Neighbor')\nplot(k1, coords_hunan, add = TRUE, col = 'red', length = 0.08)\nplot(hunan$geometry, border = 'lightgrey', main = 'Distance Link')\nplot(wm_d62, coords_hunan, add = TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\nComputing Adaptive Distance Weight Matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have fewwer neighbours. Having many neighbours smooths the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly by using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry\n\nknn6 &lt;- knn2nb(knearneigh(coords_hunan, k = 6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly we can display the content of the matrix by using str()\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords_hunan, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\n\nPlotting Distance Based Neighbours\nWe can plot the weight matrix using the code below\n\nplot(hunan$geometry, border = 'lightgrey')\nplot(knn6, coords_hunan, pch = 19, cex = 0.6, add = TRUE, col = 'red')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#weight-based-on-idw",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#weight-based-on-idw",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Weight Based on IDW",
    "text": "Weight Based on IDW\nWe can derive a spatial weight matrix based on the Inversed Distance method\nnbdists() can be used to compute the distances between areas\n\ndist &lt;- nbdists(wm_q, coords_hunan, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/x)\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034\n\n\n\nRow-standardised Weights Matrix\nNext, we assign weights to each neighboring polygon.\nEach neighboring polygon will be assigned equal weight (style = “W”). This is accomplished by assigning the fraction of 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summarise the neighbors’ values, it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\nFor this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style='W', zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy = TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset. However, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nWe can use the same method to derive a row standardised distance weight matrix.\n\nrswm_ids &lt;- nb2listw(wm_q, glist = ids, style = 'B', zero.policy = TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\nTo see the weight of the first polygon’s neighbours\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\nWe can see the summary of the weights by using summary()\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Spatial_Weights.html#application-of-spatial-weight-matrix",
    "title": "Hands-on_Ex2_Spatial_Weights",
    "section": "Application of Spatial Weight Matrix",
    "text": "Application of Spatial Weight Matrix\nIn this section we will create four different spatial lagged variables:\n\nspatial lag with row-standardized weights\nspatial lag as a sum of neighbouring values\nspatial window average\nspatial window sum\n\n\nSpatial Lag with Row-standardized Weights\nWe will compute the average neighbor GDPPC value for each polygon\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecalled in the previous section, we retrieved the GDPPC of these five counties\n\nnb1 &lt;- wm_q[[1]]\nnb1_gdppc &lt;- hunan$GDPPC[nb1]\nnb1_gdppc\n\n[1] 20981 34592 24473 21311 22879\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights?\nFor better comparison, we can try to print both series of values\n\nprint(GDPPC.lag[wm_q[[1]]])\n\n[1] 22724.80 24143.25 27737.50 25093.00 22259.09\n\nprint(nb1_gdppc)\n\n[1] 20981 34592 24473 21311 22879\n\n\nPossible Answer: Most neighbors were adjusted slightly based on their weights, particularly neighbor id 3. This accounts geographical distance into the GDPPC value of each neighbor, accounting for the influence on the value of GDPPC by the values of GDPPC of its neighbours.\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c('NAME_3', 'lag GDPPC')\nhunan &lt;- left_join(hunan,lag.res)\n\nWe can see the new spatial lag GDPPC using head()\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we can plot the GDPPC and spatial lag GDPPC for comparison\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\nSpatial Lag as a Sum of Neighboring Values\nWe can calculate spatial lag a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist= in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbor structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q,\n                       glist = b_weights,\n                       style = 'B')\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c('NAME_3', 'lag_sum GDPPC')\n\nWe can take a glimpse of the newly created data frame\n\nlag.res\n\n          NAME_3 lag_sum GDPPC\n1        Anxiang        124236\n2        Hanshou        113624\n3         Jinshi         96573\n4             Li        110950\n5          Linli        109081\n6         Shimen        106244\n7        Liuyang        174988\n8      Ningxiang        235079\n9      Wangcheng        273907\n10         Anren        256221\n11       Guidong         98013\n12         Jiahe        104050\n13         Linwu        102846\n14       Rucheng         92017\n15       Yizhang        133831\n16      Yongxing        158446\n17        Zixing        141883\n18     Changning        119508\n19      Hengdong        150757\n20       Hengnan        153324\n21      Hengshan        113593\n22       Leiyang        129594\n23        Qidong        142149\n24        Chenxi        100119\n25     Zhongfang         82884\n26       Huitong         74668\n27      Jingzhou         43184\n28        Mayang         99244\n29       Tongdao         46549\n30      Xinhuang         20518\n31          Xupu        140576\n32      Yuanling        121601\n33      Zhijiang         92069\n34 Lengshuijiang         43258\n35    Shuangfeng        144567\n36        Xinhua        132119\n37       Chengbu         51694\n38        Dongan         59024\n39       Dongkou         69349\n40       Longhui         73780\n41      Shaodong         94651\n42       Suining        100680\n43        Wugang         69398\n44       Xinning         52798\n45       Xinshao        140472\n46      Shaoshan        118623\n47    Xiangxiang        180933\n48       Baojing         82798\n49     Fenghuang         83090\n50       Guzhang         97356\n51       Huayuan         59482\n52        Jishou         77334\n53      Longshan         38777\n54          Luxi        111463\n55      Yongshun         74715\n56         Anhua        174391\n57           Nan        150558\n58     Yuanjiang        122144\n59      Jianghua         68012\n60       Lanshan         84575\n61      Ningyuan        143045\n62     Shuangpai         51394\n63       Xintian         98279\n64       Huarong         47671\n65      Linxiang         26360\n66         Miluo        236917\n67     Pingjiang        220631\n68      Xiangyin        185290\n69          Cili         64640\n70       Chaling         70046\n71        Liling        126971\n72       Yanling        144693\n73           You        129404\n74       Zhuzhou        284074\n75       Sangzhi        112268\n76       Yueyang        203611\n77        Qiyang        145238\n78      Taojiang        251536\n79      Shaoyang        108078\n80      Lianyuan        238300\n81     Hongjiang        108870\n82      Hengyang        108085\n83       Guiyang        262835\n84      Changsha        248182\n85       Taoyuan        244850\n86      Xiangtan        404456\n87           Dao         67608\n88     Jiangyong         33860\n\n\nQuestion: Can you understand the meaning of Spatial Lag as a Sum of Neighboring Values?\nAnswer: Instead of using the GDPPC value of the polygon, this method sums the GDPPC values of all of its neighbors\nWe can append the lag_sum GDPPC field into the hunan sf data frame\n\nhunan &lt;- left_join(hunan, lag.res)\n\nNext, we can plot the GDPPC and spatial lag as sum of neighbors GDPPC for comparison\n\ngdppc &lt;- qtm(hunan, 'GDPPC')\nlag_sum_gdppc &lt;- qtm(hunan, 'lag_sum GDPPC')\ntmap_arrange(gdppc, lag_sum_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\nSpatial Window Average\nThe spatial window average uses row-standardized weights and includes the diagonal element, or the self-weight. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nWe can take a good look at the neighbour list of area [1]\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNow, [1] has six neighbours instead of five, including itself.\nNow we can obtain the weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nLastly, we can create the lag variable from our weight structure and GDPPC variable\n\nlag_w_avg_gdppc &lt;- lag.listw(wm_qs, hunan$GDPPC)\n\nlag_w_avg_gdppc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw into a data frame similar to what we have done previously\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c('NAME_3', 'lag_window_avg GDPPC')\n\nNow, we can append this data frame onto the original hunan sf data frame\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial Window Average, kable() is used\n\nhunan %&gt;%\n  select('County', 'lag GDPPC', 'lag_window_avg GDPPC') %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nFinally, we can create two plots in order to compare how lag GDPPC and lag_window_avg GDPPC are plotted\n\nw_avg_gdppc &lt;- qtm(hunan, 'lag_window_avg GDPPC')\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp = 1, ncol = 2)\n\n\n\n\n\n\nSpatial Window Sum\nThe spatial window sum is the counterpart of the window average, but without using row-standardized weights.\nFirst, we create the neighbor list including self\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we can assign binary weights to the neighbour structure that includes the diagonal element similar to what was done in Spatial Lag as a Sum of Neighboring Values.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x+1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nSimilar to Spatial Window Average, [1] now has six neighbours\nNow we can use nb2listw() to assign weight values, which is now binary\n\nb_weights2 &lt;- nb2listw(wm_qs,\n                       glist = b_weights,\n                       style = 'B')\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert this object into a data frame\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c('NAME_3', 'w_sum GDPPC')\n\nNext, we will join it with the original hunan data frame\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select('County', 'lag_sum GDPPC', 'w_sum GDPPC') %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, we can draw plots to compare the two methods: Spatial Lag as a Sum of Neighboring Values and Spatial Window Sum\n\nw_sum_gdppc &lt;- qtm(hunan, 'w_sum GDPPC')\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp = 1, ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html",
    "title": "Hands-on_Ex2_Global_Measures",
    "section": "",
    "text": "The goal of this hands-on exercise is to compute Global and Local Measures of Spatial Autocorrelation (GLSA)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html#overview",
    "title": "Hands-on_Ex2_Global_Measures",
    "section": "",
    "text": "The goal of this hands-on exercise is to compute Global and Local Measures of Spatial Autocorrelation (GLSA)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html#getting-started",
    "title": "Hands-on_Ex2_Global_Measures",
    "section": "Getting Started",
    "text": "Getting Started\n\nThe Analytical Question\nIn spatial policy, one of the main development objectives of the local government and planners is to ensure equal distribution of development in the province.\nOur task is to apply appropriate spatial statistical methods to discover if development are evenly distributed geographically.\n\nIf the answer is No, then our next question will be “is there a sign of spatial clustering?”.\n\nIf the answer is Yes, then our next question will be “Where are the clusters?”.\n\n\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Province, People’s Republic of China (PRC).\n\n\nThe Study Area and Data\nTwo data sets will be used:\n\nHunan Province administrative boundary layer at county level. This is a geospatial dataset in ESRI shapefile format\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012\n\n\n\nLoading the Required Packages\nWe can use p_load() in the pacman package to load the required packages for data analysis: spdep (for spatial weights), sf, tmap, and tidyverse.\n\npacman::p_load(spdep, sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html#getting-the-data-into-r-environment",
    "title": "Hands-on_Ex2_Global_Measures",
    "section": "Getting the Data into R Environment",
    "text": "Getting the Data into R Environment\n\nImport shapefile into R\nst_read() can be used to import the Hunan shapefile into R as a simple features object.\n\nhunan &lt;- st_read(dsn = 'data/geospatial',\n                 layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImport csv file into R\nread_csv() can be used to import the Hunan_2012.csv into R.\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\nPerforming Relational Join\nleft_join() can be used to join the attribute fields in hunan2012 with the hunan simple feature object.\n\n\n\n\n\n\nNote\n\n\n\nNote that left_join() automatically seeks out the shared column to join the data frames. However it can also by specified with the syntax: by = join_by(County)\n\n\n\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\nVisualizing Regional Development Indicator\nThe tmap package can be used to prepare choropleth maps to show the distribution of GDP per capita (GDPPC) according to different breaks style (‘equal’, ‘quantile’).\n\nequal &lt;- tm_shape(hunan)+\n  tm_fill('GDPPC',\n          n = 5,\n          style = 'equal')+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = 'Equal Interval Classification')\n\nquantile &lt;- tm_shape(hunan)+\n  tm_fill('GDPPC',\n          n = 5,\n          style = 'quantile')+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = 'Equal Quantile Classification')\n\ntmap_arrange(equal, quantile, asp = 1, ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html#global-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html#global-spatial-autocorrelation",
    "title": "Hands-on_Ex2_Global_Measures",
    "section": "Global Spatial Autocorrelation",
    "text": "Global Spatial Autocorrelation\n\nComputing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units in the study area.\npoly2nb() is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. For this case study, we will use a Queen contiguity criteria, which look like below.\n\n\nwm_q &lt;- poly2nb(hunan, queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours (area 85). There are two area units with only 1 neighbour (30 and 65).\n\n\nRow-standardized Weights Matrix\nNext, we need to assign weights to each neighboring polygon.\nIn our case, each neighboring polygon will be assigned equal weight (style = ‘W’). This is accomplished by assigning 1/(#ofneighbors) to each neighboring county then summing the weighted income values.\nWhile this is the most intuitive way to summarize the neighbors’ values, it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons, thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\n\nrswm_q &lt;- nb2listw(wm_q,\n                   style = 'W',\n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments:\n\nstyle: can take values ‘W’, ‘B’, ‘C’, ‘U’, ‘minmax’ and ‘S’. B is the classic binary coding, W is row standardized (sums over all links to n), C is globally standardized (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nzero policy: if set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\n\nGlobal Spatial Autocorrelation: Moran’s I\n\nMoran’s I test\nmoran.test() in spdep can be used to perform Moran’s I statistical test\n\nmoran.test(hunan$GDPPC,\n           listw = rswm_q,\n           zero.policy = TRUE,\n           na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer: As the p-value is below the alpha level of 5%, the result of the Moran’s I test is statistically significant and since the Moran I statistics is positive, we can conclude that there is positive spatial autocorrelation, or that similar values are spatially clustered.\n\n\nMonte Carlo Moran’s I\nmoran.mc() can be used to performs permutation test for Moran’s I statistic. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm &lt;- moran.mc(hunan$GDPPC,\n                 listw = rswm_q,\n                 nsim = 999,\n                 zero.policy = TRUE,\n                 na.action = na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer: The permutation test supports the result of the Moran’s I. As the p-value is 0.001, only 0.1% of the values equal or exceed it, the result of the Moran’s I test is statistically significant and since the Moran I statistics is positive, we can conclude that there is positive spatial autocorrelation, or that similar values are spatially clustered.\n\n\nVisualizing Monte Carlo Moran’s I\nIt is good practice to examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram.\nmean() can be used to get the mean of the simulated values of statistic.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\nvar() can be used to get the variance of the simulated values of statistic.\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\nsummary() can be used to get the summary statistics of the simulated values of statistic.\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\nhist() and abline() can be used to create a histogram of the simulated values of statistic of the Monte Carlo Moran’s I\n\nhist(bperm$res,\n     freq = TRUE,\n     breaks = 20,\n     xlab = \"Simulated Moran's I\")\nabline(v=0,\n       col='red')\n\n\n\n\nQuestion: What statistical observation can you draw from the output above?\nAnswer: It can be seen that that a very small number of values exceed or equal the value of I at 0.3, meaning that the autocorrelation is statistically significant. Additionally, since the simulated values of statistic is not normally distributed, it demonstrates the reliability of the permutation test to identify statistically significant autocorrelation.\n\n\n\nGlobal Spatial Autocorrelation: Geary’s\n\nGeary’s C test\ngeary.test() can be used to perform Geary’s C test for spatial autocorrelation.\n\ngeary.test(hunan$GDPPC, listw = rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer: Geary’s C value ranges from 0 to 2 where 1 is no spatial autocorrelation. Since the statistic is 0.69, it suggests that there is slight positive spatial correlation. Additionally since the p-value is very small, the result is statistically significant.\n\n\nComputing Monte Carlo Geary’s C\nA permutation test (Monte Carlo Geary’s C) can be performed using geary.mc()\n\nset.seed(1234)\nbperm &lt;- geary.mc(hunan$GDPPC,\n                  listw = rswm_q,\n                  nsim = 999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer: The permutation test supports the result of the Geary’s C test. Since p-value is 0.001, the result is statistically significant. Furthermore, as the test statistic is 0.69, it can be concluded that there is positive spatial autocorrelation.\n\n\nVisualizing the Monte Carlo Geary’s C\nmean() can be used to get the mean of the simulated values of statistic.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\nvar() can be used to get the variance of the simulated values of statistic.\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\nsummary() can be used to get the summary statistic of the simulated values of statistic.\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\nhist() and abline() can be used to create a histogram of the simulated values of statistic of the Geary’s C.\n\nhist(bperm$res,\n     freq = TRUE,\n     breaks = 20,\n     xlab = 'Simulated Geary C')\nabline(v=1, col='red')\n\n\n\n\nQuestion: What statistical observation can you draw from the output?\nAnswer: The simulated values is normally distributed around 1, which is one of the implicit assumption of the Geary’s C test."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Global_Measures.html#spatial-correlogram",
    "title": "Hands-on_Ex2_Global_Measures",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in the data or model residuals.\nThey show how correlated are pairs of spatial observations when you increase the distance (lag) between them. They are plots of some index of autocorrelation (Moran’s I or Geary’s C) against distance.\nAlthough correlograms are not as fundamental as variograms (a keystone concept of geostatistic), they are very useful as an exploratory and descriptive tool. For this purpose, they actually provide richer information than variograms.\n\nCompute Moran’s I Correlogram\nsp.correlogram() can be used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used is Moran’s I. plot() is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q,\n                          hunan$GDPPC,\n                          order = 6,\n                          method = 'I', style = 'W')\n\nplot(MI_corr)\n\n\n\n\nPlotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nQuestion: What statistical observation can you draw from the plot above?\nAnswer: All pairs of results are statistically significant, except for number 4 with a p-value larger than 0.05. This shows that the list of IDs in number 4 do not exhibit spatial autocorrelation with their neighbors.\n\n\nCompute Geary’s C correlogram and plot\nsp.correlogram() can be used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used is Geary’s C. plot() is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q,\n                          hunan$GDPPC,\n                          order = 6,\n                          method = 'C', style = 'W')\nplot(GC_corr)\n\n\n\n\nWe will print out the analysis report using print().\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThis can be done using the tmap package. We can load this and other required packages (sf, tidyverse) using the code below.\n\npacman::p_load(sf, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#overview",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "",
    "text": "Choropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nThis can be done using the tmap package. We can load this and other required packages (sf, tidyverse) using the code below.\n\npacman::p_load(sf, tidyverse, tmap)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#importing-data-into-r",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Importing Data into R",
    "text": "Importing Data into R\n\nThe Data\nTwo datasets will be used:\n\nMaster Plan 2014 Subzone Boundary (Web) in ESRI shapefile format. It consists of geographical boundary of Singapore at the planning subzone level and is babsed on the URA Master Plan 2014.\nSingapore Residents by Planning Area/Subzone, Age Grouu, Sex, and Type of Dwelling, June 2011-2020 csv format. This is aspatial data. Its PA and SZ fields can be used to geocode to the Master Plan 2014 Subzone Boundary (Web) shapefile.\n\n\n\nImporting Geospatial Data into R\nst_read() can be used to read the Master Plan 2014 shapefile into an R dataframe.\n\nmpsz &lt;- st_read(dsn = 'data/geospatial',\n                layer = 'MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nglimpse() and head() can be used to look at the data types and first few rows of data\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\nhead(mpsz, 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\nImporting Attribute Data into R\nFor the resident population data, read_csv() will be used as it is stored as a csv\n\npopdata &lt;- read_csv('data/aspatial/respopagesexfa2011to2020.csv')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#data-preparation",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Data Preparation",
    "text": "Data Preparation\nBefore a thematic map can be prepared, you are required to prepare a data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\nThis table would have the rows be each unique PA and SZ and with the following new columns:\n\nYOUNG: number of people from age group 0-4 to age group 20-24\nECONOMY ACTIVE: number of people from age group 25-29 to age group 60-64\nAGED: number of people age group 65 +\nTOTAL: number of people in all age groups\nDEPENDENCY: the ratio between YOUNG + AGED against ECONOMY ACTIVE\n\n\nData Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider(): To pivot the dataframe from long to wide format with rows becoming new columns\nmutate(), filter(), and group_by(): Creating new columns, filtering, and group columns based on value of some columns\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;% #Getting only 2020 data\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;% #Summarizing by population based on the group_by\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP)%&gt;% #pivot wider based on names in AG and values from POP\n  mutate(YOUNG = rowSums(.[3:6])+rowSums(.[14])) %&gt;%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+rowSums(.[15]))%&gt;%\n  mutate(`AGED` = rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL` = rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, `ECONOMY ACTIVE`, `AGED`, `TOTAL`, `DEPENDENCY`)\n\n\n\nJoining the attribute data and geospatial data\nCurrently, the values of the PA and SZ fields are a mix of lower and uppercase characters while the values in SUBZONE_N and PLN_AREA_N are all uppercase.\nWe need to convert the values in PA and SZ fields to uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), #Apply the toupper function to multiple columns\n            .funs = list(toupper)) %&gt;% \n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nleft_join() can then be used to join the geographical data and attribute table based on SZ being the same as SUBZONE_N. left_join() is used with the simple feature dataframe (mpsz) as the left data table to ensure the output will be a simple features dataframe; it will also keep all observations in mpsz.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c('SUBZONE_N' = 'SZ'))\n\nNow, we can use write_rds to create a new rds (R Data Serialization) file with the new dataframe\n\nwrite_rds(mpsz_pop2020, 'data/rds/mpszpop2020.rds')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Choropleth Mapping Geospatial Data using tmap",
    "text": "Choropleth Mapping Geospatial Data using tmap\n\nPlotting a choropleth map quickly by using qtm()\nDefault visualization using qtm(). Note that tmap_mode() with “plot” is used to produce a static map. For interactive mode, “view” should be used.\n\ntmap_mode('plot')\nqtm(mpsz_pop2020,\n    fill = 'DEPENDENCY') #the DEPENDENCY column will be used for the color variation\n\n\n\n\n\n\nCreating a choropleth map by using tmap’s elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          style='quantile',\n          palette = 'Blues',\n          title = 'Dependency ration')+\n  tm_layout(main.title = 'Distribution of Dependency Ratio by planning subzone',\n            main.title.position = 'center',\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type='8star',size=2)+\n  tm_scale_bar()+\n  tm_grid(alpha = 0.2)+\n  tm_credits('Sourrce: Planning Sub-zone boundary from Urban Redevelopment Authority \\n and Population data from Department of Statistics (DOS)',\n             position = c('left','bottom'))\n\n\n\n\nThe following sections will explain each step of the process executed in the code chunk above\n\n\nDrawing a base map\nThe basic building block of tmap is tm_shape() which is used to define the input data and tm_polygons() which is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons()\n\n\n\n\n\n\nDrawing a choropleth map using tm_polygons()\ntm_polygons() can be modified with the target variable in order to draw the choropleth map showing the geographical distribution of the selected variable.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons('DEPENDENCY')\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”.\nThe default colour scheme used is YlOrRd of ColorBrewer.\nBy default, Missing value will be shaded in grey.\n\n\n\nDrawing a choropleth map using tm_fill() and tm_border()\ntm_polygons() is a wrapper of tm_fill() and tm_border():\n\ntm_fill() shades the polygons by using the default colour scheme\ntm_borders() adds the borders of the shapefile onto the choropleth map\n\nIf you use tm_fill() alone, there will be no border between the subzones. The planning subzones are shared according to the respective dependency values.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY')\n\n\n\n\ntm_borders() can be used to add the boundary of the planning subzones. tm_borders() has three arguments:\n\nalpha: transparency of the line\ncol: border colour\nlwd: line width\nlty: line type\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY')+\n  tm_borders(lwd = 0.1, alpha = 1)\n\n\n\n\n\n\nData classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\nPlotting choropleth maps with built-in classification methods\njenks data classification method\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 5, #number of classes\n          style = 'jenks')+\n  tm_borders(alpha = 0.5)\n\n\n\n\nequal data classification method\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 5,\n          style = 'equal')+\n  tm_borders(alpha = 0.5)\n\n\n\n\nquantile data classification method\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 5,\n          style = 'quantile')+\n  tm_borders(alpha = 0.5)\n\n\n\n\nThe distribution of quantile data classification method are more evenly distributed then equal data classification method.\nUsing the quantile style with different numbers of classes\n2 classes\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 2,\n          style = 'quantile')+\n  tm_borders(alpha = 0.5)\n\n\n\n\n6 classes\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 6,\n          style = 'quantile')+\n  tm_borders(alpha = 0.5)\n\n\n\n\n10 classes\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 10,\n          style = 'quantile')+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nPlotting choropleth map with custom break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nsummary() can be used to get some descriptive statistics on the variable ‘DEPENDENCY’ before setting break points.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6540  0.7063  0.7712  0.7657 19.0000      92 \n\n\nWith reference to the results above and the need to include a minimum and maximum (0 and 100), we can set our breaks with the vector c(0, 0.5, 0.6, 0.7, 0.8, 1.00)\nNow we can plot the choropleth map with custom breaks\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          breaks = c(0, 0.5, 0.6, 0.7, 0.8, 1.00))+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\nColour Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package\n\nUsing ColourBrewer palette\nTo change the colour, we assigned the preferred colour to the palette argument of tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 6,\n          style = 'quantile',\n          palette = 'Blues')+\n  tm_borders(alpha = 0.5)\n\n\n\n\nWe can also reverse the color scheme (darker for lower values) by adding a ‘-’ prefix to the palette argument\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          n = 6,\n          style = 'quantile',\n          palette = '-Blues')+\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#map-layouts",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Map Layouts",
    "text": "Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\nMap Legend\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          style = 'jenks',\n          palette = 'Blues',\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1)+\n  tm_layout(main.title = 'Distribution of Dependency Ratio by planning subzone \\n (Jenks Classification)',\n            main.title.position = 'center',\n            main.title.size = 1,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c('right','bottom'),\n            frame = FALSE)+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMap Style\ntmap allows a wide variety of layout settings to be changes. They can be called by using tmap_style()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          style = 'quantile',\n          palette = '-Greens')+\n  tm_borders(alpha = 0.5)+\n  tmap_style('classic')\n\n\n\n\n\n\nCartographic Furniture\nBeside map style, tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\ntm_compass() can be used to add a compass.\ntm_scale_bar() can be used to add a scale bar.\ntm_grid() can be used to add grid lines.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          style = 'quantile',\n          palette = 'Blues',\n          title = 'No. of persons')+\n  tm_layout(main.title = 'Distribution of Dependency Ratio by planning subzone \\n (Jenks Classification)',\n            main.title.position = 'center',\n            main.title.size = 1.2,\n            legend.height = 0.45,\n            legend.width = 0.35,\n            frame = TRUE)+\n  tm_borders(alpha = 0.5)+\n  tm_compass(type = '8star', size = 2)+\n  tm_scale_bar(width = 0.15)+\n  tm_grid(lwd = 0.1, alpha = 0.2)+\n  tm_credits('Source: Planning Sub-zone boundary from Urban Redevelopment Authority (URA) \\n and Population data from Department of Statistic (DOS)',\n             position = c('left','bottom'))\n\n\n\n\nTo reset to the default style, use tmap_style(‘white’)\n\ntmap_style('white')"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Drawing Small Multiple Choropleth Maps",
    "text": "Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the aesthetic arguments\nby defining a group-by variable in tm_facets()\nby creating multiple standalone maps with tmap_arrange()\n\n\nBy assigning multiple values to at least one of the aesthetic arguments\nThe ncols argument in tm_fill() can be used to make multiple choropleth maps\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c('YOUNG','AGED'),\n          style = 'equal',\n          palette = 'Blues')+\n  tm_layout(legend.position = c('right','bottom'))+\n  tm_borders(alpha = 0.5)+\n  tmap_style('white')\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(c('DEPENDENCY','AGED'),\n              style = c('equal','quantile'),\n              palette = list('Blues','Greens'))+\n  tm_layout(legend.position = c('right','bottom'))\n\n\n\n\n\n\nBy defining a group-by variable in tm_facets()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill('DEPENDENCY',\n          style = 'quantile',\n          palette = 'Blues',\n          thres.poly = 0)+\n  tm_facets(by = 'REGION_N',\n            free.coords = TRUE,\n            drop.shapes = TRUE)+\n  tm_layout(legend.show = FALSE,\n            title.position = c('center','center'),\n            title.size = 20)+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nBy creating multiple stand-alone maps with tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+\n  tm_polygons('YOUNG',\n              style = 'quantile',\n              palette = 'Blues')\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+\n  tm_polygons('AGED',\n              style = 'quantile',\n              palette = 'Blues')\n\ntmap_arrange(youngmap, agedmap, asp = 1, ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_Choropleth.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 1: Choropleth Mapping with R",
    "section": "Mapping Spatial Object Meeting a Selection Criterion",
    "text": "Mapping Spatial Object Meeting a Selection Criterion\nSelection function can be used to map spatial objects meeting the selection criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N=='CENTRAL REGION',])+\n  tm_fill('DEPENDENCY',\n          style = 'quantile',\n          palette = 'Blues',\n          legend.hist = TRUE,\n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1)+\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45,\n            legend.width = 5.0,\n            legend.position = c('right','bottom'),\n            frame = FALSE)+\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\nThis was made by Phan Hoang Long for ISSS624."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#overview",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Getting Started",
    "text": "Getting Started\nThe code chunk below installs and loads sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\n\nImporting polygon features data\nReading the Master Planning 2014 Subzone shapefile into a dataframe\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nReading the CyclingPath shapefile into a dataframe\n\ncyclingpath &lt;- st_read(dsn = \"data/geospatial\",layer = 'CyclingPathGazette')\n\nReading layer `CyclingPathGazette' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nRead the Pre-School Locations kml file into a dataframe using a complete path\n\npreschool &lt;- st_read('data/geospatial/PreSchoolsLocation.kml')\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#checking-the-content-of-a-simple-feature-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#checking-the-content-of-a-simple-feature-dataframe",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Checking the Content of a Simple Feature DataFrame",
    "text": "Checking the Content of a Simple Feature DataFrame\n\nWorking with st_geometry()\nUsing st_geometry() to retrieve basic information of the dataframe\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\n\n\n\nWorking with glimpse()\nUse glimpse() to get the data types of each column and some of their values\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\nWorking with head()\nhead() lets us inspect the top n rows of the dataframe\n\nhead(mpsz, n= 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#plotting-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Plotting Geospatial Data",
    "text": "Plotting Geospatial Data\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum. This can be seen using the plot() function.\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\nWe can choose to plot only the geometry (outline) by using st_geometry()\n\nplot(st_geometry(mpsz))\n\n\n\n\nWe can also choose the specific attribute of the dataframe we would like to plot by addressing it in the R dataframe\n\nplot(mpsz['PLN_AREA_N'])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#working-with-projection",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Working with Projection",
    "text": "Working with Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nThe process of projecting one dataframe from one coordinate system to another is called projection transformation.\n\nAssigning EPSG code to a simple feature data frame\nIdentifying the coordinate system of a dataframe using st_crs()\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nIn order to assign the correct EPSG code, use st_set_crs()\n\nmpsz3414 &lt;- st_set_crs(mpsz,3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nDouble check the new ESPG using st_crs()\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nTransforming the projection of preschool from WGS84 to SVY21\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nCheck the coordinate system for the preschool dataframe\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nPOINT Z (103.8072 1.299333 0)\n\n\nPOINT Z (103.826 1.312839 0)\n\n\nPOINT Z (103.8409 1.348843 0)\n\n\nPOINT Z (103.8048 1.435024 0)\n\n\nPOINT Z (103.839 1.33315 0)\n\n\nst_set_crs() is not appropriate here because we need to reproject the dataframe from one coordinate system to another coordinate system mathematically.\nThis can be performed using st_transform()\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\nDouble-check the coordinate system for preschool3414\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\nPOINT Z (25089.46 31299.16 0)\n\n\nPOINT Z (27189.07 32792.54 0)\n\n\nPOINT Z (28844.56 36773.76 0)\n\n\nPOINT Z (24821.92 46303.16 0)\n\n\nPOINT Z (28637.82 35038.49 0)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing and Converting Aspatial Data",
    "text": "Importing and Converting Aspatial Data\n\nImporting the Aspatial Data\nWe can read the listings csv into an R tibble dataframe using read_csv() of readr\n\nlistings &lt;- read_csv('data/aspatial/listings.csv')\n\nRows: 3483 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (37): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (7): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe can use list(), instead of glimpse() in order to see the columns, data types, and some rows of the new dataframe\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,483 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Vill… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… &lt;b&gt;The spa…\n 3  71903 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n10 369141 https://www.airbnb.co…   2.02e13 2023-09-23   city … Plac… A room in …\n# ℹ 3,473 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\n\n\nCreating a simple feature dataframe from an aspatial dataframe\nst_as_sf() can be used to convert the listing dataframe into a simple feature dataframe. Note that:\n\ncoords argument requires the column name of the x-coordinates first (longitude) then the column name of the y-coordinates (latitude)\ncrs argument requires the specific coordinates system. As we suspect the coordinate system of listings to be WGS84, this would be crs = 4326 . Singapore’s EPSG code is 3414 as we have used before.\nWe use %&gt;% in dplyr to nest st_transform() to reproject the new simple feature dataframe into SVY21 (EPSG: 3414) coordinates system.\n\n\nlistings_sf &lt;- st_as_sf(listings,\n                        coords = c('longitude','latitude'),\n                        crs=4326)%&gt;%\n  st_transform(crs=3414)\n\nglimpse() can be used to view the new simple feature dataframe, its data types, and some row values. Notice that a new column called geometry has been added and longitude and latitude have been dropped.\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.023092e+13, 2.023092e+1…\n$ last_scraped                                 &lt;date&gt; 2023-09-23, 2023-09-23, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"previ…\n$ name                                         &lt;chr&gt; \"Villa in Singapore · ★4.…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within a few hours\", \"wi…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52…\n$ host_total_listings_count                    &lt;dbl&gt; 15, 15, 15, 65, 65, 15, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; NA, NA, NA, NA, NA, 3, NA…\n$ beds                                         &lt;dbl&gt; 3, 1, 2, 1, 1, 5, 1, 1, 1…\n$ amenities                                    &lt;chr&gt; \"[\\\"Private backyard \\\\u2…\n$ price                                        &lt;chr&gt; \"$150.00\", \"$80.00\", \"$80…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 28, 28, 28, 1, 30, 28, 30…\n$ availability_60                              &lt;dbl&gt; 58, 58, 58, 1, 60, 58, 60…\n$ availability_90                              &lt;dbl&gt; 88, 88, 88, 1, 90, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 89, 89, 275, 274, 89,…\n$ calendar_last_scraped                        &lt;date&gt; 2023-09-23, 2023-09-23, …\n$ number_of_reviews                            &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 1, 1, 1…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 6, 51…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\nThe sf package offers a wide range of geoprocessing (GIS) functions.\nIn this section, you will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\nBuffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution\nWe can use st_buffer() to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist =5,\n                            nQuadSegs = 30)\n\nWe can then calculate the area of each of the buffers using st_area()\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, we can sum up all the areas of the buffers to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n\n\nPoint-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nWe can: first, identify pre-schools located inside each Planning Subzone by using st_intersects(), second, length() can be used to calculate number of pre-schools that falls inside each planning subzone.\n\nmpsz3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nsummary() can be used to check the summary statistics of the newly created PreSch Count column in mpsz3414\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\ntop_n() can be used to list the top n planning subzone with the highest number of pre-school\n\ntop_n(mpsz3414,1,`PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nWe can also calculate the density of preschool by planning subzone:\nFirst, st_area() can be used to derive the area of each planning subzone.\n\nmpsz3414$AREA &lt;- mpsz3414%&gt;%\n  st_area()\n\nNext, mutate() can be used to compute the density by using the previously created ‘PreSch Count’ and ‘AREA’ columns\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = (`PreSch Count`/AREA)*1000000)\n\nWe can extract the planning subzone with the highest preschool density using top_n()\n\ntop_n(mpsz3414,1,`PreSch Density`)\n\nSimple feature collection with 1 feature and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29501.64 ymin: 28623.75 xmax: 29976.93 ymax: 29362.03\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO SUBZONE_N SUBZONE_C CA_IND    PLN_AREA_N PLN_AREA_C\n1       27          8     CECIL    DTSZ08      Y DOWNTOWN CORE         DT\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D  X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 65AA82AF6F4D925D 2014-12-05 29730.2 29011.33\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   2116.095   196619.9 MULTIPOLYGON (((29808.18 28...            7\n            AREA   PreSch Density\n1 196619.9 [m^2] 35.60169 [1/m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#overview",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to import and wrangle geospatial data using appropriate R packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#getting-started",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Getting Started",
    "text": "Getting Started\nThe code chunk below installs and loads sf and tidyverse packages into R environment.\n\npacman::p_load(sf, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#importing-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing Geospatial Data",
    "text": "Importing Geospatial Data\n\nImporting polygon features data\nReading the Master Planning 2014 Subzone shapefile into a dataframe\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nReading the CyclingPath shapefile into a dataframe\n\ncyclingpath &lt;- st_read(dsn = \"data/geospatial\",layer = 'CyclingPathGazette')\n\nReading layer `CyclingPathGazette' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2558 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nRead the Pre-School Locations kml file into a dataframe using a complete path\n\npreschool &lt;- st_read('data/geospatial/PreSchoolsLocation.kml')\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex1\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#checking-the-content-of-a-simple-feature-dataframe",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#checking-the-content-of-a-simple-feature-dataframe",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Checking the Content of a Simple Feature DataFrame",
    "text": "Checking the Content of a Simple Feature DataFrame\n\nWorking with st_geometry()\nUsing st_geometry() to retrieve basic information of the dataframe\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\n\n\nWorking with glimpse()\nUse glimpse() to get the data types of each column and some of their values\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\nWorking with head()\nhead() lets us inspect the top n rows of the dataframe\n\nhead(mpsz, n= 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#plotting-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#plotting-geospatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Plotting Geospatial Data",
    "text": "Plotting Geospatial Data\nThe default plot of an sf object is a multi-plot of all attributes, up to a reasonable maximum. This can be seen using the plot() function.\n\nplot(mpsz)\n\n\n\n\nWe can choose to plot only the geometry (outline) by using st_geometry()\n\nplot(st_geometry(mpsz))\n\n\n\n\nWe can also choose the specific attribute of the dataframe we would like to plot by addressing it in the R dataframe\n\nplot(mpsz['PLN_AREA_N'])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#working-with-projection",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Working with Projection",
    "text": "Working with Projection\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using two geospatial data, we need to ensure that both geospatial data are projected using similar coordinate system.\nThe process of projecting one dataframe from one coordinate system to another is called projection transformation.\n\nAssigning EPSG code to a simple feature data frame\nIdentifying the coordinate system of a dataframe using st_crs()\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nIn order to assign the correct EPSG code, use st_set_crs()\n\nmpsz3414 &lt;- st_set_crs(mpsz,3414)\n\nDouble check the new ESPG using st_crs()\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nTransforming the projection of preschool from WGS84 to SVY21\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nCheck the coordinate system for the preschool dataframe\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nst_set_crs() is not appropriate here because we need to reproject the dataframe from one coordinate system to another coordinate system mathematically.\nThis can be performed using st_transform()\n\npreschool3414 &lt;- st_transform(preschool, crs = 3414)\n\nDouble-check the coordinate system for preschool3414\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#importing-and-converting-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#importing-and-converting-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Importing and Converting Aspatial Data",
    "text": "Importing and Converting Aspatial Data\n\nImporting the Aspatial Data\nWe can read the listings csv into an R tibble dataframe using read_csv() of readr\n\nlistings &lt;- read_csv('data/aspatial/listings.csv')\n\nWe can use list(), instead of glimpse() in order to see the columns, data types, and some rows of the new dataframe\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,483 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Vill… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… &lt;b&gt;The spa…\n 3  71903 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2023-09-23   previ… Home… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2023-09-23   city … Rent… **IMPORTAN…\n10 369141 https://www.airbnb.co…   2.02e13 2023-09-23   city … Plac… A room in …\n# ℹ 3,473 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\n\n\n\nCreating a simple feature dataframe from an aspatial dataframe\nst_as_sf() can be used to convert the listing dataframe into a simple feature dataframe. Note that:\n\ncoords argument requires the column name of the x-coordinates first (longitude) then the column name of the y-coordinates (latitude)\ncrs argument requires the specific coordinates system. As we suspect the coordinate system of listings to be WGS84, this would be crs = 4326 . Singapore’s EPSG code is 3414 as we have used before.\nWe use %&gt;% in dplyr to nest st_transform() to reproject the new simple feature dataframe into SVY21 (EPSG: 3414) coordinates system.\n\n\nlistings_sf &lt;- st_as_sf(listings,\n                        coords = c('longitude','latitude'),\n                        crs=4326)%&gt;%\n  st_transform(crs=3414)\n\nglimpse() can be used to view the new simple feature dataframe, its data types, and some row values. Notice that a new column called geometry has been added and longitude and latitude have been dropped.\n\nglimpse(listings_sf)\n\nRows: 3,483\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.023092e+13, 2.023092e+1…\n$ last_scraped                                 &lt;date&gt; 2023-09-23, 2023-09-23, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"previ…\n$ name                                         &lt;chr&gt; \"Villa in Singapore · ★4.…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1&…\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within a few hours\", \"wi…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52…\n$ host_total_listings_count                    &lt;dbl&gt; 15, 15, 15, 65, 65, 15, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; NA, NA, NA, NA, NA, 3, NA…\n$ beds                                         &lt;dbl&gt; 3, 1, 2, 1, 1, 5, 1, 1, 1…\n$ amenities                                    &lt;chr&gt; \"[\\\"Private backyard \\\\u2…\n$ price                                        &lt;chr&gt; \"$150.00\", \"$80.00\", \"$80…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 60, 60, 92, 9…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 28, 28, 28, 1, 30, 28, 30…\n$ availability_60                              &lt;dbl&gt; 58, 58, 58, 1, 60, 58, 60…\n$ availability_90                              &lt;dbl&gt; 88, 88, 88, 1, 90, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 89, 89, 275, 274, 89,…\n$ calendar_last_scraped                        &lt;date&gt; 2023-09-23, 2023-09-23, …\n$ number_of_reviews                            &lt;dbl&gt; 20, 24, 47, 22, 17, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 3, 0, 0, 1, 3…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 1…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 5, 5, 5, 52, 52, 5, 7, 52…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 1, 1, 0, 1, 1, 1…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 5, 5, 5, 51, 51, 5, 6, 51…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.14, 0.16, 0.31, 0.17, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex1/Hands-on_Ex1_SFEDA.html#geoprocessing-with-sf-package",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "Geoprocessing with sf package",
    "text": "Geoprocessing with sf package\nThe sf package offers a wide range of geoprocessing (GIS) functions.\nIn this section, you will learn how to perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\nBuffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution\nWe can use st_buffer() to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, dist =5,\n                            nQuadSegs = 30)\n\nWe can then calculate the area of each of the buffers using st_area()\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, we can sum up all the areas of the buffers to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n1774367 [m^2]\n\n\n\n\nPoint-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nWe can: first, identify pre-schools located inside each Planning Subzone by using st_intersects(), second, length() can be used to calculate number of pre-schools that falls inside each planning subzone.\n\nmpsz3414$`PreSch Count` &lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nsummary() can be used to check the summary statistics of the newly created PreSch Count column in mpsz3414\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\ntop_n() can be used to list the top n planning subzone with the highest number of pre-school\n\ntop_n(mpsz3414,1,`PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nWe can also calculate the density of preschool by planning subzone:\nFirst, st_area() can be used to derive the area of each planning subzone.\n\nmpsz3414$AREA &lt;- mpsz3414%&gt;%\n  st_area()\n\nNext, mutate() can be used to compute the density by using the previously created ‘PreSch Count’ and ‘AREA’ columns\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = (`PreSch Count`/AREA)*1000000)\n\nWe can extract the planning subzone with the highest preschool density using top_n()\n\ntop_n(mpsz3414,1,`PreSch Density`)\n\nSimple feature collection with 1 feature and 18 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 29501.64 ymin: 28623.75 xmax: 29976.93 ymax: 29362.03\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO SUBZONE_N SUBZONE_C CA_IND    PLN_AREA_N PLN_AREA_C\n1       27          8     CECIL    DTSZ08      Y DOWNTOWN CORE         DT\n        REGION_N REGION_C          INC_CRC FMEL_UPD_D  X_ADDR   Y_ADDR\n1 CENTRAL REGION       CR 65AA82AF6F4D925D 2014-12-05 29730.2 29011.33\n  SHAPE_Leng SHAPE_Area                       geometry PreSch Count\n1   2116.095   196619.9 MULTIPOLYGON (((29808.18 28...            7\n            AREA   PreSch Density\n1 196619.9 [m^2] 35.60169 [1/m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html",
    "title": "Hands-on_Ex2_Local_Measures",
    "section": "",
    "text": "The goal of this hands-on exercise is to compute Global and Local Measures of Spatial Autocorrelation (GLSA)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#overview",
    "title": "Hands-on_Ex2_Local_Measures",
    "section": "",
    "text": "The goal of this hands-on exercise is to compute Global and Local Measures of Spatial Autocorrelation (GLSA)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#getting-started",
    "title": "Hands-on_Ex2_Local_Measures",
    "section": "Getting Started",
    "text": "Getting Started\n\nThe Analytical Question\nIn spatial policy, one of the main development objectives of the local government and planners is to ensure equal distribution of development in the province.\nOur task is to apply appropriate spatial statistical methods to discover if development are evenly distributed geographically.\n\nIf the answer is No, then our next question will be “is there a sign of spatial clustering?”.\n\nIf the answer is Yes, then our next question will be “Where are the clusters?”.\n\n\nIn this case study, we are interested to examine the spatial pattern of a selected development indicator (i.e. GDP per capita) of Hunan Province, People’s Republic of China (PRC).\n\n\nThe Study Area and Data\nTwo data sets will be used:\n\nHunan Province administrative boundary layer at county level. This is a geospatial dataset in ESRI shapefile format\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012\n\n\n\nLoading the Required Packages\nWe can use p_load() in the pacman package to load the required packages for data analysis: spdep (for spatial weights), sf, tmap, and tidyverse.\n\npacman::p_load(spdep, sf, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#getting-the-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#getting-the-data-into-r-environment",
    "title": "Hands-on_Ex2_Local_Measures",
    "section": "Getting the Data into R Environment",
    "text": "Getting the Data into R Environment\n\nImport shapefile into R\nst_read() can be used to import the Hunan shapefile into R as a simple features object.\n\nhunan &lt;- st_read(dsn = 'data/geospatial',\n                 layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `D:\\phlong2023\\ISSS624\\Hands-on_Ex\\Hands-on_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\nImport csv file into R\nread_csv() can be used to import the Hunan_2012.csv into R.\n\nhunan2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\nPerforming Relational Join\nleft_join() can be used to join the attribute fields in hunan2012 with the hunan simple feature object.\n\n\n\n\n\n\nNote\n\n\n\nNote that left_join() automatically seeks out the shared column to join the data frames. However it can also by specified with the syntax: by = join_by(County)\n\n\n\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\n\n\nVisualizing Regional Development Indicator\nThe tmap package can be used to prepare choropleth maps to show the distribution of GDP per capita (GDPPC) according to different breaks style (‘equal’, ‘quantile’).\n\nequal &lt;- tm_shape(hunan)+\n  tm_fill('GDPPC',\n          n = 5,\n          style = 'equal')+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = 'Equal Interval Classification')\n\nquantile &lt;- tm_shape(hunan)+\n  tm_fill('GDPPC',\n          n = 5,\n          style = 'quantile')+\n  tm_borders(alpha = 0.5)+\n  tm_layout(main.title = 'Equal Quantile Classification')\n\ntmap_arrange(equal, quantile, asp = 1, ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#global-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#global-spatial-autocorrelation",
    "title": "Hands-on_Ex2_Local_Measures",
    "section": "Global Spatial Autocorrelation",
    "text": "Global Spatial Autocorrelation\n\nComputing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units in the study area.\npoly2nb() is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. For this case study, we will use a Queen contiguity criteria, which look like below.\n\n\nwm_q &lt;- poly2nb(hunan, queen = TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours (area 85). There are two area units with only 1 neighbour (30 and 65).\n\n\nRow-standardized Weights Matrix\nNext, we need to assign weights to each neighboring polygon.\nIn our case, each neighboring polygon will be assigned equal weight (style = ‘W’). This is accomplished by assigning 1/(#ofneighbors) to each neighboring county then summing the weighted income values.\nWhile this is the most intuitive way to summarize the neighbors’ values, it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons, thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data.\n\nrswm_q &lt;- nb2listw(wm_q,\n                   style = 'W',\n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments:\n\nstyle: can take values ‘W’, ‘B’, ‘C’, ‘U’, ‘minmax’ and ‘S’. B is the classic binary coding, W is row standardized (sums over all links to n), C is globally standardized (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nzero policy: if set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice.\n\n\n\nGlobal Spatial Autocorrelation: Moran’s I\n\nMoran’s I test\nmoran.test() in spdep can be used to perform Moran’s I statistical test\n\nmoran.test(hunan$GDPPC,\n           listw = rswm_q,\n           zero.policy = TRUE,\n           na.action = na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer: As the p-value is below the alpha level of 5%, the result of the Moran’s I test is statistically significant and since the Moran I statistics is positive, we can conclude that there is positive spatial autocorrelation, or that similar values are spatially clustered.\n\n\nMonte Carlo Moran’s I\nmoran.mc() can be used to performs permutation test for Moran’s I statistic. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm &lt;- moran.mc(hunan$GDPPC,\n                 listw = rswm_q,\n                 nsim = 999,\n                 zero.policy = TRUE,\n                 na.action = na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer: The permutation test supports the result of the Moran’s I. As the p-value is 0.001, only 0.1% of the values equal or exceed it, the result of the Moran’s I test is statistically significant and since the Moran I statistics is positive, we can conclude that there is positive spatial autocorrelation, or that similar values are spatially clustered.\n\n\nVisualizing Monte Carlo Moran’s I\nIt is good practice to examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram.\nmean() can be used to get the mean of the simulated values of statistic.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\nvar() can be used to get the variance of the simulated values of statistic.\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\nsummary() can be used to get the summary statistics of the simulated values of statistic.\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\nhist() and abline() can be used to create a histogram of the simulated values of statistic of the Monte Carlo Moran’s I\n\nhist(bperm$res,\n     freq = TRUE,\n     breaks = 20,\n     xlab = \"Simulated Moran's I\")\nabline(v=0,\n       col='red')\n\n\n\n\nQuestion: What statistical observation can you draw from the output above?\nAnswer: It can be seen that that a very small number of values exceed or equal the value of I at 0.3, meaning that the autocorrelation is statistically significant. Additionally, since the simulated values of statistic is not normally distributed, it demonstrates the reliability of the permutation test to identify statistically significant autocorrelation.\nQuestion: Recreate the graph using ggplot2\n\nbperm_df &lt;- data.frame(bperm$res)\n\nggplot(bperm_df, aes(x=bperm.res))+\n  geom_histogram(col = 'black', size = 0.3, fill = 'lightgrey', boundary = 0, bins = 27)+\n  theme_classic()+\n  labs(title = \"Histogram of Simulated Statistics\",\n       x = \"Simulated Moran's I\",\n       y = \"Frequency\")+\n  theme(plot.title = element_text(hjust = 0.5))+\n  scale_y_continuous(breaks=c(0,20,40,60,80,100))+\n  geom_vline(xintercept = 0, col = 'red')\n\n\n\n\n\n\n\nGlobal Spatial Autocorrelation: Geary’s\n\nGeary’s C test\ngeary.test() can be used to perform Geary’s C test for spatial autocorrelation.\n\ngeary.test(hunan$GDPPC, listw = rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer: Geary’s C value ranges from 0 to 2 where 1 is no spatial autocorrelation. Since the statistic is 0.69, it suggests that there is slight positive spatial correlation. Additionally since the p-value is very small, the result is statistically significant.\n\n\nComputing Monte Carlo Geary’s C\nA permutation test (Monte Carlo Geary’s C) can be performed using geary.mc()\n\nset.seed(1234)\nbperm &lt;- geary.mc(hunan$GDPPC,\n                  listw = rswm_q,\n                  nsim = 999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\nQuestion: What statistical conclusion can you draw from the output above?\nAnswer: The permutation test supports the result of the Geary’s C test. Since p-value is 0.001, the result is statistically significant. Furthermore, as the test statistic is 0.69, it can be concluded that there is positive spatial autocorrelation.\n\n\nVisualizing the Monte Carlo Geary’s C\nmean() can be used to get the mean of the simulated values of statistic.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\nvar() can be used to get the variance of the simulated values of statistic.\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\nsummary() can be used to get the summary statistic of the simulated values of statistic.\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\nhist() and abline() can be used to create a histogram of the simulated values of statistic of the Geary’s C.\n\nhist(bperm$res,\n     freq = TRUE,\n     breaks = 20,\n     xlab = 'Simulated Geary C')\nabline(v=1, col='red')\n\n\n\n\nQuestion: What statistical observation can you draw from the output?\nAnswer: The simulated values is normally distributed around 1, which is one of the implicit assumption of the Geary’s C test."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#spatial-correlogram",
    "title": "Hands-on_Ex2_Local_Measures",
    "section": "Spatial Correlogram",
    "text": "Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in the data or model residuals.\nThey show how correlated are pairs of spatial observations when you increase the distance (lag) between them. They are plots of some index of autocorrelation (Moran’s I or Geary’s C) against distance.\nAlthough correlograms are not as fundamental as variograms (a keystone concept of geostatistic), they are very useful as an exploratory and descriptive tool. For this purpose, they actually provide richer information than variograms.\n\nCompute Moran’s I Correlogram\nsp.correlogram() can be used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used is Moran’s I. plot() is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q,\n                          hunan$GDPPC,\n                          order = 6,\n                          method = 'I', style = 'W')\n\nplot(MI_corr)\n\n\n\n\nPlotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nQuestion: What statistical observation can you draw from the plot above?\nAnswer: All pairs of results are statistically significant, except for number 4 with a p-value larger than 0.05. This shows that the list of IDs in number 4 do not exhibit spatial autocorrelation with their neighbors.\n\n\nCompute Geary’s C correlogram and plot\nsp.correlogram() can be used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used is Geary’s C. plot() is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q,\n                          hunan$GDPPC,\n                          order = 6,\n                          method = 'C', style = 'W')\nplot(GC_corr)\n\n\n\n\nWe will print out the analysis report using print().\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#cluster-and-outlier-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#cluster-and-outlier-analysis",
    "title": "Hands-on_Ex2_Local_Measures",
    "section": "Cluster and Outlier Analysis",
    "text": "Cluster and Outlier Analysis\nLocal indicators of Spatial Association (LISA) are statistics that evaluate the existence of clusters in the spatial arrangement of a given variable. For instance, if we are sutdying cancer rates among census tracts in a given city, local clusters in the rates mean that there are areas that have higher or lower rates than is to be expected by chance alone; that is, the values occuring are above or below those of a random distribution in space.\n\nComputing local Moran’s I\nlocalmoran() can be used to compute local Moran’s I. It computes li values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\n\nflips &lt;- order(hunan$County) #This code arrange the county column index of hunan in alphabetical order according to the county names\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() returns a matrix of values whose columns are:\n\nli: the local Moran’s I statistics\nE.li: the expectation of local Moran statistic under the randomization hypothesis\nVar.li: the variance of local Moran statistic under the randomization hypothesis\nZ.li: the standard deviation of the local Moran statistic\nPr(): the p-value of local Moran statistics\n\nprintCoefmat() can be used to see these statistics for each of the county in our study.\n\nprintCoefmat(data.frame(\n  localMI[flips,],\n  row.names = hunan$County[flips]),\n  check.names = FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n\nMapping the local Moran’s I\nBefore mapping the local Moran’s I, we can append the local Moran’s I data frame (localMI) onto hunan sf data frame.\n\n\n\n\n\n\nNote\n\n\n\nBy using cbind(), all columns of local MI will be added to hunan. The orders of the counties in both data frame are the same so the statistics will match.\n\n\n\nhunan.localMI &lt;- cbind(hunan, localMI)%&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\nWe can then create a choropleth map of the local Moran’s I values\n\ntm_shape(hunan.localMI)+\n  tm_fill(col='Ii',\n          style='pretty',\n          palette = 'RdBu',\n          title = 'Local Moran Statistics')+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping the local Moran’s I p-values\nWe can also map the local Moran’s I p-values using similar code\n\ntm_shape(hunan.localMI)+\n  tm_fill(col='Pr.Ii',\n          breaks = c(-Inf,0.001,0.01,0.05,0.1,Inf),\n          palette='-Blues',\n          title = \"Local Moran's I p-values\")+\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nMapping both local Moran’s I values and p-values\ntmap_arrange() can be used with the code chunks above to put the two plots of local Moran’s I values and p-values side by side.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI)+\n  tm_fill(col='Ii',\n          style='pretty',\n          title = 'Local Moran Statistics')+\n  tm_borders(alpha=0.5)\n\npvalues.map &lt;- tm_shape(hunan.localMI)+\n  tm_fill(col='Pr.Ii',\n          breaks = c(-Inf,0.001, 0.01, 0.05, 0.1, Inf),\n          palette = '-Blues',\n          title = \"Local Moran's I p-values\")+\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalues.map, asp = 1, ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#creating-a-lisa-cluster-map",
    "title": "Hands-on_Ex2_Local_Measures",
    "section": "Creating a LISA Cluster Map",
    "text": "Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation.\nThe first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\nPlotting Moran Scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nmoran.plot() can be used to draw the Moran scatterplot.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels = as.character(hunan$County),\n                  xlab = 'GDPPC 2012',\n                  ylab = 'Spatially Lag GDPPC 2012')\n\n\n\n\nThe plot is split in 4 quadrants: The top right corner belongs to area that have high GDPPC and are surrounded by other areas that have the average level GDPPC. This is the high-high locations in the lesson slide.\n\n\nPlotting Moran Scatterplot with Standardised Variable\nFirst, scale() can be used to center and scale the variable. Here, centering is done by subtracting the mean (omitting NAs) of the corresponding columns, and scaling is done by dividing the centered variable by their standard deviations.\n\n\n\n\n\n\nNote\n\n\n\nThe as.vector() added is to make sure that the data type we get out of the process is a vector which map neatly into the data frame.\n\n\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC)%&gt;%\n  as.vector()\n\nWe can then plot our new standardised variable onto a Moran scatterplot.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels = as.character(hunan$County),\n                   xlab = 'z-GDPPC 2012',\n                   ylab = 'Spatially Lag z-GDPPC 2012')\n\n\n\n\n\n\nPreparing LISA Map Classes\nThe code chunk below shows the steps to prepare a LISA cluster map. This code create a vector of ‘0’ with length being equal to the number of rows of localMI.\n\nquadrant &lt;- vector(mode='numeric',length = nrow(localMI))\n\nNext, we can derive the spatially lagged variable of interest and center it around its mean\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\n\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)\n\nNext, we center the local Moran’s around the mean\n\nLM_I &lt;- localMI[,1]-mean(localMI[,1])\n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05\n\nNow, we need to define the four different quadrants and one special quadrant for non-significant Moran:\n\n# Low - Low \nquadrant[DV &lt; 0 & LM_I &gt; 0] &lt;- 1\n# Low - High\nquadrant[DV &lt; 0 & LM_I &lt; 0] &lt;- 3\n# High - Low\nquadrant[DV &gt; 0 & LM_I &lt; 0] &lt;- 2\n# High- High\nquadrant[DV &gt; 0 & LM_I &gt; 0] &lt;- 4\n\n# Non-Significant Moran\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\nPlotting LISA map\nWe can build the LISA map using the code below\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c('Insignificant','Low-Low','Low-High','High-Low','High-High')\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = 'quadrant',\n          style='cat',\n          palette = colors[c(sort(unique(quadrant)))+1],\n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(''))+\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other\n\ngdppc &lt;- qtm(hunan, 'GDPPC')\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c('Insignificant','Low-Low','Low-High','High-Low','High-High')\n\nLISAmap &lt;- tm_shape(hunan.localMI)+\n  tm_fill(col = 'quadrant',\n          style = 'cat',\n          palette = colors[sort(unique(quadrant))+1],\n          labels = clusters[sort(unique(quadrant))+1],\n          popup.vars = c(''))+\n  tm_view(set.zoom.limits = c(11,17))+\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, LISAmap, asp = 1, ncol = 2)\n\n\n\n\nWe can also bring up the local Moran’s I values and p-values map before for comparison\n\ntmap_arrange(localMI.map, pvalues.map, asp = 1, ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Hands-on_Ex2_Local_Measures",
    "section": "Hot Spot and Cold Spot Area Analysis",
    "text": "Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can also be used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\nGetis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995).\nIt looks at neighbours within a defined proximity to identify whether either high or low values cluster spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\nDeriving Distance-based Weight Matrix\nFirst, we need to define a new set of neighbours. While the spatial autocorrelation considered units with shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two types of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix\n\n\nDeriving the Centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. We will need to create a separate data frame to find the centroid for each polygon.\nThe needed dataframe can be created with map_dbl() which will map the function st_centroid() on the geometry column of each row of the hunan dataframe.\nFirst we find the longitude, which is in the geometry column at position [[1]].\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nNext, we find the latitude which is at position [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow, we can combine them to create a dataframe with the centroids’ longitude and latitude\n\ncoords_hunan &lt;- cbind(longitude, latitude)\n\n\n\nDetermine the Cut-off Distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh().\nConvert the knn object into a neighbours list of class nb with a list of integer vectors containing the neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists(). The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n\n\n\n\n\nNote\n\n\n\nIn simple terms, the goal of this step is to find the nearest neighbor for each centroid.\n\nThe first step is to identify the point coordinates of this neighbor.\nThe second step is to find the distance between the polygon and its neighbor.\n\nFrom this, we know the largest distance between a polygon and its neighbor. By setting this distance as the cut-off distance in our fixed distance weight matrix, we ensure that each polygon would have at least one neighbor.\n\n\n\nk1 &lt;- knn2nb(knearneigh(coords_hunan))\nk1dists &lt;- unlist(nbdists(k1, coords_hunan, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\nComputing Fixed Distance Weight Matrix\nNow that we have the cut-off distance, dnearneigh() can be used to compute the distance weight matrix.\n\nwm_d62 &lt;- dnearneigh(coords_hunan, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\n\n\n\n\n\nNote\n\n\n\nThe ‘B’ or binary style is used here which ascribe the value of 1 to each neighbor.\n\n\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\nComputing Adaptive Distance Weight Matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords_hunan, k = 8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex2/Hands-on_Ex2_Local_Measures.html#computing-gi-statistics",
    "title": "Hands-on_Ex2_Local_Measures",
    "section": "Computing Gi Statistics",
    "text": "Computing Gi Statistics\n\nGi Statistics using Fixed Distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstart values, with attributes “gstari” set to TRUE of FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding county in hunan sf data frame.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nThe code chunk above performs three tasks:\n\nConvert the output vector (gi.fixed) into a matrix object\nCombine hunan and gi.fixed to produce hunan.gi sf dataframe\nChange the field name of the gi values to gstat_fixed\n\n\n\nMapping Gi values with Fixed Distance Weights\nTo map the Gi values dervided using fixed distance weight matrix, simply use the tmap package and change the col argument of tm_fill()\n\ngdppc &lt;- qtm(hunan, fill = 'GDPPC')\n\nGimap &lt;- tm_shape(hunan.gi)+\n  tm_fill(col='gstat_fixed',\n          style = 'pretty',\n          palette = '-RdBu',\n          title = 'Local Gi')+\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp = 1, ncol = 2)\n\n\n\n\n\n\nGi Statistics using Adaptive Distance\nTo calculate Gi statistic using adaptive distance, simply replace the weight list in localG with the adaptive distance weight list.\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC,knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\nMapping Gi values with Adaptive Distance Weights\n\ngdppc &lt;- qtm(hunan, 'GDPPC')\n\nGimap &lt;- tm_shape(hunan.gi)+\n  tm_fill(col='gstat_adaptive',\n          style='pretty',\n          palette ='-RdBu',\n          title = 'Local Gi')+\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp = 1, ncol = 2)\n\n\n\n\nQuestion: What statistical observation can you draw from the Gi map above?\nAnswer: The Gi statistic calculated from the adaptive weight matrix display a higher value for counties on the right edge. Notably, the Gi values seems to be reversed between the fixed distance weights and adaptive distance weights list."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex3/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex3/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex1/data/geospatial/MPSZ-2019.html",
    "href": "In-Class_Ex/In-Class_Ex1/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2.html",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Loading R packages\n\npacman::p_load(sf, sfdep, tmap, tidyverse, knitr)\n\n\n\n\nFor this In-class Exercise, the Hunan data sets will be used. They are:\n\nhunan: a geographical data set in ESRI shapefile format\nHunan_2012: an attribute data set in csv format\n\n\n\n\nst_read() can be used to read the shape file data set into an R sf dataframe\n\nhunan &lt;- st_read(dsn = 'data/geospatial',\n                 layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nread_csv() can be used to read the attribute file into an R data frame\n\nhunan_2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\n\nleft_join() can be used to combine the two data sets\n\n\n\n\n\n\nNote\n\n\n\nIn order to retain the geospatial properties, the left data frame must be sf data.frame, in this case it is hunan\n\n\n\nhunan_GDPPC &lt;- left_join(hunan, hunan_2012,\n                            by = 'County')%&gt;%\n  select(1:4, 7, 15) #Retaining the city's name, ID, county name, county type, GDPPC, and geometry"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2.html#getting-started",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Loading R packages\n\npacman::p_load(sf, sfdep, tmap, tidyverse, knitr)\n\n\n\n\nFor this In-class Exercise, the Hunan data sets will be used. They are:\n\nhunan: a geographical data set in ESRI shapefile format\nHunan_2012: an attribute data set in csv format\n\n\n\n\nst_read() can be used to read the shape file data set into an R sf dataframe\n\nhunan &lt;- st_read(dsn = 'data/geospatial',\n                 layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nread_csv() can be used to read the attribute file into an R data frame\n\nhunan_2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\n\nleft_join() can be used to combine the two data sets\n\n\n\n\n\n\nNote\n\n\n\nIn order to retain the geospatial properties, the left data frame must be sf data.frame, in this case it is hunan\n\n\n\nhunan_GDPPC &lt;- left_join(hunan, hunan_2012,\n                            by = 'County')%&gt;%\n  select(1:4, 7, 15) #Retaining the city's name, ID, county name, county type, GDPPC, and geometry"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2.html#deriving-contiguity-weights-queens-model",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2.html#deriving-contiguity-weights-queens-model",
    "title": "In-class Exercise 2",
    "section": "Deriving Contiguity Weights: Queen’s Model",
    "text": "Deriving Contiguity Weights: Queen’s Model\nThe sfdep method entails the creation of a tibble data frame which contains the original data as well as the neighbors list and weights for each polygon , as opposed to creating the contiguity and weight separately in spdep.\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry), # Default is Queen\n         wt = st_weights(nb,\n                         style='W'),\n         .before = 1)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2.html#computing-global-morans-i-old-spdep-method",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2.html#computing-global-morans-i-old-spdep-method",
    "title": "In-class Exercise 2",
    "section": "Computing Global Moran’s I (old spdep method)",
    "text": "Computing Global Moran’s I (old spdep method)\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\nmoranI\n\n$I\n[1] 0.30075\n\n$K\n[1] 7.640659"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2.html#computing-local-morans-i-with-sfdep-method",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2.html#computing-local-morans-i-with-sfdep-method",
    "title": "In-class Exercise 2",
    "section": "Computing Local Moran’s I (with sfdep method)",
    "text": "Computing Local Moran’s I (with sfdep method)\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_GLSA.html",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_GLSA.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Loading R packages\n\npacman::p_load(sf, sfdep, tmap, tidyverse, knitr)\n\n\n\n\nFor this In-class Exercise, the Hunan data sets will be used. They are:\n\nhunan: a geographical data set in ESRI shapefile format\nHunan_2012: an attribute data set in csv format\n\n\n\n\nst_read() can be used to read the shape file data set into an R sf dataframe\n\nhunan &lt;- st_read(dsn = 'data/geospatial',\n                 layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nread_csv() can be used to read the attribute file into an R data frame\n\nhunan_2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\n\nleft_join() can be used to combine the two data sets\n\n\n\n\n\n\nNote\n\n\n\nIn order to retain the geospatial properties, the left data frame must be sf data.frame, in this case it is hunan\n\n\n\nhunan_GDPPC &lt;- left_join(hunan, hunan_2012,\n                            by = 'County')%&gt;%\n  select(1:4, 7, 15) #Retaining the city's name, ID, county name, county type, GDPPC, and geometry"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_GLSA.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_GLSA.html#getting-started",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Loading R packages\n\npacman::p_load(sf, sfdep, tmap, tidyverse, knitr)\n\n\n\n\nFor this In-class Exercise, the Hunan data sets will be used. They are:\n\nhunan: a geographical data set in ESRI shapefile format\nHunan_2012: an attribute data set in csv format\n\n\n\n\nst_read() can be used to read the shape file data set into an R sf dataframe\n\nhunan &lt;- st_read(dsn = 'data/geospatial',\n                 layer = 'Hunan')\n\nReading layer `Hunan' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex2\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n\nread_csv() can be used to read the attribute file into an R data frame\n\nhunan_2012 &lt;- read_csv('data/aspatial/Hunan_2012.csv')\n\n\n\n\nleft_join() can be used to combine the two data sets\n\n\n\n\n\n\nNote\n\n\n\nIn order to retain the geospatial properties, the left data frame must be sf data.frame, in this case it is hunan\n\n\n\nhunan_GDPPC &lt;- left_join(hunan, hunan_2012,\n                            by = 'County')%&gt;%\n  select(1:4, 7, 15) #Retaining the city's name, ID, county name, county type, GDPPC, and geometry"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_GLSA.html#deriving-contiguity-weights-queens-model",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_GLSA.html#deriving-contiguity-weights-queens-model",
    "title": "In-class Exercise 2",
    "section": "Deriving Contiguity Weights: Queen’s Model",
    "text": "Deriving Contiguity Weights: Queen’s Model\nThe sfdep method entails the creation of a tibble data frame which contains the original data as well as the neighbors list and weights for each polygon , as opposed to creating the contiguity and weight separately in spdep.\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry), # Default is Queen\n         wt = st_weights(nb,\n                         style='W'),\n         .before = 1)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_GLSA.html#computing-global-morans-i-old-spdep-method",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_GLSA.html#computing-global-morans-i-old-spdep-method",
    "title": "In-class Exercise 2",
    "section": "Computing Global Moran’s I (old spdep method)",
    "text": "Computing Global Moran’s I (old spdep method)\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\nmoranI\n\n$I\n[1] 0.30075\n\n$K\n[1] 7.640659"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_GLSA.html#computing-local-morans-i-with-sfdep-method",
    "href": "In-Class_Ex/In-Class_Ex2/In-class_Ex2_GLSA.html#computing-local-morans-i-with-sfdep-method",
    "title": "In-class Exercise 2",
    "section": "Computing Local Moran’s I (with sfdep method)",
    "text": "Computing Local Moran’s I (with sfdep method)\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html",
    "href": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html",
    "title": "In-class_Ex3",
    "section": "",
    "text": "pacman::p_load(tmap, sf, sp, DT, performance, reshape2, ggpubr, units, tidyverse)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#getting-started",
    "title": "In-class_Ex3",
    "section": "",
    "text": "pacman::p_load(tmap, sf, sp, DT, performance, reshape2, ggpubr, units, tidyverse)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#the-data",
    "href": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#the-data",
    "title": "In-class_Ex3",
    "section": "The Data",
    "text": "The Data\nThe following data will be used, as a continuation of Hands-on_Ex3:\n\nod_data.rds: weekday morning peak passenger flows at planning subzone level.\nmpsz.rds: URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.\n\nBeside these two data sets, an additional attribute data file called pop.csv will be provided.\n\nImporting Geospatial Data\n\nmpsz &lt;- read_rds('data/rds/mpsz.rds')\n\n\n\nConverting from sf data.table to SpatialPolygonsDataFrame\nThis is a way to convert a sf data.table to SpatialPolygonsDataFrame. However, the sf data.table is still the preferred format for analysis.\n\n# Untidy way\nmpsz_sp &lt;- as(mpsz, 'Spatial')"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#distance-matrix-between-centroids-of-each-zone.",
    "href": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#distance-matrix-between-centroids-of-each-zone.",
    "title": "In-class_Ex3",
    "section": "Distance matrix between centroids of each zone.",
    "text": "Distance matrix between centroids of each zone.\nspDists() of sp can be used to calculate the cent\n\ndist &lt;- spDists(mpsz_sp, longlat = FALSE)\n\n\nLabelling columns and row headers of distance matrix\n\nsz_names &lt;- mpsz$SUBZONE_C\n\nNext we will attach SUBZONE_C names to the rows and columns of the distance matrix.\n\ncolnames(dist) &lt;- paste0(sz_names)\nrownames(dist) &lt;- paste0(sz_names)\n\n\n\nPivoting distance value by SUBZONE_C\nNext, we will pivot the distance matrix into a long table by using melt.\n\ndistPair &lt;- melt(dist) %&gt;%\n  rename(dist = value)\n\n\n\nUpdating intra-zonal distances\n\ndistPair %&gt;%\n  filter(dist &gt; 0) %&gt;%\n  summary()\n\n      Var1             Var2             dist        \n MESZ01 :   331   MESZ01 :   331   Min.   :  173.8  \n RVSZ05 :   331   RVSZ05 :   331   1st Qu.: 7149.5  \n SRSZ01 :   331   SRSZ01 :   331   Median :11890.0  \n WISZ01 :   331   WISZ01 :   331   Mean   :12229.4  \n MUSZ02 :   331   MUSZ02 :   331   3rd Qu.:16401.7  \n MPSZ05 :   331   MPSZ05 :   331   Max.   :49894.4  \n (Other):107906   (Other):107906                    \n\n\nSince Min inter-zonal distances is 173, we can roughly estimate the intra-zonal distance (distance between the centroid and the polygon’s boundary).\n\ndistPair$dist &lt;- ifelse(distPair$dist == 0,\n                        50, distPair$dist)\n\nWe can also rename the column names in the table for easier manipulation further on.\n\ndistPair &lt;- distPair %&gt;%\n  rename(orig = Var1,\n         dest = Var2)\n\nWe can save distPair as an rds file for future use.\n\nwrite_rds(distPair, 'data/rds/distPair.rds')"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#preparing-flow-data",
    "href": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#preparing-flow-data",
    "title": "In-class_Ex3",
    "section": "Preparing flow data",
    "text": "Preparing flow data\nWe can import od_data.rds created previously into R using read_rds().\n\nod_data &lt;- read_rds('data/rds/od_data.rds')\n\nNext, the total passenger trip between and within planning subzones will be calculated.\n\nflow_data &lt;- od_data %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarize(TRIPS = sum(MORNING_PEAK))\n\nWe can see the top 5 rows of flow_data using head()\n\nhead(flow_data)\n\n# A tibble: 6 × 3\n# Groups:   ORIGIN_SZ [1]\n  ORIGIN_SZ DESTIN_SZ TRIPS\n  &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;\n1 AMSZ01    AMSZ01     2694\n2 AMSZ01    AMSZ02    10591\n3 AMSZ01    AMSZ03    14980\n4 AMSZ01    AMSZ04     3106\n5 AMSZ01    AMSZ05     7734\n6 AMSZ01    AMSZ06     2306\n\n\n\nSeparating intra-flow from passenger volume df\nWe can add three new fields into flow_data:\n\nFlowNoIntra: Number of trips, excluding intra-zonal trips.\noffset: A neglible value used for later analysis to offset intra-zonal trips.\n\n\nflow_data$FlowNoIntra &lt;- ifelse(flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 0, flow_data$TRIPS)\n\nflow_data$offset &lt;- ifelse(flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 0.000001, 1)\n\n\n\nCombining passenger volume data with distance value\nNow that we have the distance between the subzones (distPair) and the number of trips between them (flow_data), we can try to combine them into one data frame.\nBefore we can join flow_data and distPair, we need to convert data value type of ORIGIN_SZ and DESTIN_SZ of flow_data into factor type.\n\nflow_data$ORIGIN_SZ &lt;- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ &lt;- as.factor(flow_data$DESTIN_SZ)\n\nleft_join() can be used to combine flow_data and distPair\n\nflow_data1 &lt;- flow_data %&gt;%\n  left_join(distPair,\n            by = c('ORIGIN_SZ' = 'orig',\n                   'DESTIN_SZ' = 'dest'))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#preparing-origin-and-destination-attributes",
    "href": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#preparing-origin-and-destination-attributes",
    "title": "In-class_Ex3",
    "section": "Preparing Origin and Destination Attributes",
    "text": "Preparing Origin and Destination Attributes\n\nImporting Population Data\n\npop &lt;- read_csv('data/aspatial/pop.csv')\n\n\n\nGeospatial Data Wrangling\n\npop &lt;- pop %&gt;%\n  left_join(mpsz,\n            by = c('PA' = 'PLN_AREA_N',\n                   'SZ' = 'SUBZONE_N')) %&gt;%\n  select(1:6) %&gt;%\n  rename(SZ_NAME = SZ,\n         SZ = SUBZONE_C)\n\n\n\nPreparing Origin Attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(ORIGIN_SZ = 'SZ')) %&gt;%\n  rename(ORIGIN_AGE7_12 = AGE7_12,\n         ORIGIN_AGE13_24 = AGE13_24,\n         ORIGIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\n\n\nPreparing Destination Attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(DESTIN_SZ = 'SZ')) %&gt;%\n  rename(DESTIN_AGE7_12 = AGE7_12,\n         DESTIN_AGE13_24 = AGE13_24,\n         DESTIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#calibrating-spatial-interaction-models",
    "href": "In-Class_Ex/In-Class_Ex3/In-Class_Ex3.html#calibrating-spatial-interaction-models",
    "title": "In-class_Ex3",
    "section": "Calibrating Spatial Interaction Models",
    "text": "Calibrating Spatial Interaction Models\nWe will use the Poisson Regression Method to calibrate Spatial Interaction Models\n\nImporting the Modelling Data\n\nSIM_data &lt;- read_rds('data/rds/SIM_data.rds')\n\n\n\nVisualizing the Dependent Variable\nLet’s plot the distribution of the dependent variable (i.e. TRIPS) by making a histogram with ggplot2.\n\nggplot(SIM_data,\n       aes(x=TRIPS))+\n  geom_histogram()\n\n\n\n\nThe distribution is highly skewed and does not resemble a bell shape, also known as the normal distribution.\nNow, we can visualize the relation between the dependent variable and one of the key independent variable (distance between zones) in the Spatial Interaction Mode.\n\nggplot(SIM_data,\n       aes(x = dist,\n           y = TRIPS))+\n  geom_point()+\n  geom_smooth(method=lm)\n\n\n\n\nThe relationship does not resemble a linear relationship.\nHowever, if we create a scatter plot using the log transformed version of these variables, the relationship will better resemble a linear relationship.\n\nggplot(SIM_data,\n       aes(x = log(dist),\n           y = log(TRIPS)))+\n  geom_point()+\n  geom_smooth(method = lm)\n\n\n\n\n\n\nChecking for Variables with Zero Values\nSince Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that there is no 0 in the explanatory variables.\nsummary() can be used to compute the summary statistics of all variables in the data frame.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS           FlowNoIntra      \n Length:14274       Length:14274       Min.   :     1.0   Min.   :     1.0  \n Class :character   Class :character   1st Qu.:    11.0   1st Qu.:    11.0  \n Mode  :character   Mode  :character   Median :    56.0   Median :    56.0  \n                                       Mean   :   664.3   Mean   :   664.3  \n                                       3rd Qu.:   296.0   3rd Qu.:   296.0  \n                                       Max.   :104167.0   Max.   :104167.0  \n     offset       dist         ORIGIN_AGE7_12 ORIGIN_AGE13_24 ORIGIN_AGE25_64\n Min.   :1   Min.   :  173.8   Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.:1   1st Qu.: 3465.4   1st Qu.: 240   1st Qu.:  460   1st Qu.: 2210  \n Median :1   Median : 6121.0   Median : 710   Median : 1400   Median : 7030  \n Mean   :1   Mean   : 6951.8   Mean   :1037   Mean   : 2278   Mean   :10536  \n 3rd Qu.:1   3rd Qu.: 9725.1   3rd Qu.:1500   3rd Qu.: 3282   3rd Qu.:15830  \n Max.   :1   Max.   :26135.8   Max.   :6340   Max.   :16380   Max.   :74610  \n DESTIN_AGE7_12 DESTIN_AGE13_24 DESTIN_AGE25_64\n Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.: 250   1st Qu.:  460   1st Qu.: 2210  \n Median : 720   Median : 1430   Median : 7120  \n Mean   :1040   Mean   : 2305   Mean   :10648  \n 3rd Qu.:1500   3rd Qu.: 3290   3rd Qu.:15830  \n Max.   :6340   Max.   :16380   Max.   :74610  \n\n\nThe print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.\nWe can use ifelse() functions to replace 0 values to 0.99 so that the log function would not result in minus infinity (for 0) or 0 (for 1).\n\nSIM_data$ORIGIN_AGE7_12 &lt;- ifelse(SIM_data$ORIGIN_AGE7_12 == 0, 0.99, SIM_data$ORIGIN_AGE7_12)\n\nSIM_data$ORIGIN_AGE13_24 &lt;- ifelse(SIM_data$ORIGIN_AGE13_24 == 0, 0.99, SIM_data$ORIGIN_AGE13_24)\n\nSIM_data$ORIGIN_AGE25_64 &lt;- ifelse(SIM_data$ORIGIN_AGE25_64 == 0, 0.99, SIM_data$ORIGIN_AGE25_64)\n\nSIM_data$DESTIN_AGE7_12 &lt;- ifelse(SIM_data$DESTIN_AGE7_12 == 0, 0.99, SIM_data$DESTIN_AGE7_12)\n\nSIM_data$DESTIN_AGE13_24 &lt;- ifelse(SIM_data$DESTIN_AGE13_24 == 0, 0.99, SIM_data$DESTIN_AGE13_24)\n\nSIM_data$DESTIN_AGE25_64 &lt;- ifelse(SIM_data$DESTIN_AGE25_64 == 0, 0.99, SIM_data$DESTIN_AGE25_64)\n\nLet’s check the summary() again.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS           FlowNoIntra      \n Length:14274       Length:14274       Min.   :     1.0   Min.   :     1.0  \n Class :character   Class :character   1st Qu.:    11.0   1st Qu.:    11.0  \n Mode  :character   Mode  :character   Median :    56.0   Median :    56.0  \n                                       Mean   :   664.3   Mean   :   664.3  \n                                       3rd Qu.:   296.0   3rd Qu.:   296.0  \n                                       Max.   :104167.0   Max.   :104167.0  \n     offset       dist         ORIGIN_AGE7_12    ORIGIN_AGE13_24   \n Min.   :1   Min.   :  173.8   Min.   :   0.99   Min.   :    0.99  \n 1st Qu.:1   1st Qu.: 3465.4   1st Qu.: 240.00   1st Qu.:  460.00  \n Median :1   Median : 6121.0   Median : 710.00   Median : 1400.00  \n Mean   :1   Mean   : 6951.8   Mean   :1036.73   Mean   : 2278.59  \n 3rd Qu.:1   3rd Qu.: 9725.1   3rd Qu.:1500.00   3rd Qu.: 3282.50  \n Max.   :1   Max.   :26135.8   Max.   :6340.00   Max.   :16380.00  \n ORIGIN_AGE25_64    DESTIN_AGE7_12    DESTIN_AGE13_24    DESTIN_AGE25_64   \n Min.   :    0.99   Min.   :   0.99   Min.   :    0.99   Min.   :    0.99  \n 1st Qu.: 2210.00   1st Qu.: 250.00   1st Qu.:  460.00   1st Qu.: 2210.00  \n Median : 7030.00   Median : 720.00   Median : 1430.00   Median : 7120.00  \n Mean   :10535.93   Mean   :1039.98   Mean   : 2305.33   Mean   :10647.95  \n 3rd Qu.:15830.00   3rd Qu.:1500.00   3rd Qu.: 3290.00   3rd Qu.:15830.00  \n Max.   :74610.00   Max.   :6340.00   Max.   :16380.00   Max.   :74610.00  \n\n\nAll 0 values have been replaced by 0.99\n\n\nUnconstrained Spatial Interaction Model\nglm() can be used to calibrate an unconstrained spatial interaction model. Our explanatory variables are origin population by different age cohort, destination population by age cohort and distance between origin and destination in km (i.e. dist).\n\nuncSIM &lt;- glm(formula = TRIPS ~ \n                log(ORIGIN_AGE25_64)+\n                log(DESTIN_AGE25_64)+\n                log(dist),\n              family = poisson(link = 'log'),\n              data = SIM_data,\n              na.action = na.exclude)\n\nuncSIM\n\n\nCall:  glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + \n    log(dist), family = poisson(link = \"log\"), data = SIM_data, \n    na.action = na.exclude)\n\nCoefficients:\n         (Intercept)  log(ORIGIN_AGE25_64)  log(DESTIN_AGE25_64)  \n            17.00287               0.21001               0.01289  \n           log(dist)  \n            -1.51785  \n\nDegrees of Freedom: 14273 Total (i.e. Null);  14270 Residual\nNull Deviance:      36120000 \nResidual Deviance: 19960000     AIC: 20040000\n\n\n\n\nR-squared Function\nIn order to measure how much variation of the trips can be accounted by the model, we will calculate the R-squared value.\n\nCalcRSquared &lt;- function(observed,estimated){\n  r &lt;- cor(observed, estimated)\n  R2 &lt;- r^2\n  R2\n}\n\nNow that we have the function, we can plug in our observed and fitted values to compute R-squared.\n\nCalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)\n\n[1] 0.1694734\n\n\nWe can also calculate the McFadden Pseudo-R-squared.\n\nr2_mcfadden(uncSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.446\n  adj. R2: 0.446\n\n\n\n\nOrigin (Production) constrained SIM\nWe will fit an origin constrained SIM by using the code below.\n\norcSIM &lt;- glm(formula = TRIPS ~\n                ORIGIN_SZ +\n                log(DESTIN_AGE25_64)+\n                log(dist),\n              family = poisson(link = 'log'),\n              data = SIM_data,\n              na.action = na.exclude)\n\nsummary(orcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          19.9309957  0.0054015  3689.887  &lt; 2e-16 ***\nORIGIN_SZAMSZ02       0.6805710  0.0052686   129.175  &lt; 2e-16 ***\nORIGIN_SZAMSZ03       0.3597850  0.0054884    65.554  &lt; 2e-16 ***\nORIGIN_SZAMSZ04      -0.1106566  0.0060027   -18.434  &lt; 2e-16 ***\nORIGIN_SZAMSZ05      -0.3140561  0.0067998   -46.186  &lt; 2e-16 ***\nORIGIN_SZAMSZ06       0.0634425  0.0060258    10.528  &lt; 2e-16 ***\nORIGIN_SZAMSZ07      -1.1301580  0.0110298  -102.464  &lt; 2e-16 ***\nORIGIN_SZAMSZ08      -0.6330394  0.0102949   -61.491  &lt; 2e-16 ***\nORIGIN_SZAMSZ09       0.1064915  0.0063450    16.784  &lt; 2e-16 ***\nORIGIN_SZAMSZ10       0.5061899  0.0053889    93.931  &lt; 2e-16 ***\nORIGIN_SZAMSZ11      -1.3167911  0.0144870   -90.895  &lt; 2e-16 ***\nORIGIN_SZAMSZ12      -1.5103004  0.0127453  -118.499  &lt; 2e-16 ***\nORIGIN_SZBDSZ01       1.3626004  0.0051433   264.929  &lt; 2e-16 ***\nORIGIN_SZBDSZ02       0.9554084  0.0059655   160.156  &lt; 2e-16 ***\nORIGIN_SZBDSZ03       1.1476190  0.0054278   211.433  &lt; 2e-16 ***\nORIGIN_SZBDSZ04       2.0110410  0.0046344   433.940  &lt; 2e-16 ***\nORIGIN_SZBDSZ05       1.0658940  0.0053976   197.477  &lt; 2e-16 ***\nORIGIN_SZBDSZ06       1.2719222  0.0054774   232.213  &lt; 2e-16 ***\nORIGIN_SZBDSZ07      -0.5053039  0.0111553   -45.297  &lt; 2e-16 ***\nORIGIN_SZBDSZ08      -0.3556193  0.0102947   -34.544  &lt; 2e-16 ***\nORIGIN_SZBKSZ01      -0.3606399  0.0075473   -47.784  &lt; 2e-16 ***\nORIGIN_SZBKSZ02       0.1357265  0.0061394    22.107  &lt; 2e-16 ***\nORIGIN_SZBKSZ03       0.4101999  0.0058983    69.545  &lt; 2e-16 ***\nORIGIN_SZBKSZ04      -0.3418645  0.0070764   -48.310  &lt; 2e-16 ***\nORIGIN_SZBKSZ05      -0.2986750  0.0074073   -40.322  &lt; 2e-16 ***\nORIGIN_SZBKSZ06      -0.2637855  0.0068739   -38.375  &lt; 2e-16 ***\nORIGIN_SZBKSZ07       0.5498323  0.0051476   106.813  &lt; 2e-16 ***\nORIGIN_SZBKSZ08      -0.0527393  0.0061457    -8.582  &lt; 2e-16 ***\nORIGIN_SZBKSZ09      -0.1564691  0.0067300   -23.249  &lt; 2e-16 ***\nORIGIN_SZBLSZ01      -1.7551329  0.0176599   -99.385  &lt; 2e-16 ***\nORIGIN_SZBLSZ02      -1.9493637  0.0213859   -91.152  &lt; 2e-16 ***\nORIGIN_SZBLSZ03      -2.9057732  0.0535995   -54.213  &lt; 2e-16 ***\nORIGIN_SZBLSZ04      -1.4672066  0.0254726   -57.599  &lt; 2e-16 ***\nORIGIN_SZBMSZ01       0.1806064  0.0060563    29.821  &lt; 2e-16 ***\nORIGIN_SZBMSZ02      -1.4026549  0.0078244  -179.267  &lt; 2e-16 ***\nORIGIN_SZBMSZ03      -0.5976236  0.0063808   -93.660  &lt; 2e-16 ***\nORIGIN_SZBMSZ04      -0.5456513  0.0059061   -92.388  &lt; 2e-16 ***\nORIGIN_SZBMSZ05      -3.1095195  0.0188118  -165.297  &lt; 2e-16 ***\nORIGIN_SZBMSZ06      -3.0273827  0.0194319  -155.794  &lt; 2e-16 ***\nORIGIN_SZBMSZ07      -0.7378197  0.0066865  -110.345  &lt; 2e-16 ***\nORIGIN_SZBMSZ08      -0.9306150  0.0067188  -138.510  &lt; 2e-16 ***\nORIGIN_SZBMSZ09      -1.4137345  0.0101071  -139.876  &lt; 2e-16 ***\nORIGIN_SZBMSZ10      -1.7054195  0.0101582  -167.886  &lt; 2e-16 ***\nORIGIN_SZBMSZ11      -1.2418380  0.0076792  -161.714  &lt; 2e-16 ***\nORIGIN_SZBMSZ12      -1.3746537  0.0109769  -125.231  &lt; 2e-16 ***\nORIGIN_SZBMSZ13      -0.4339494  0.0069335   -62.587  &lt; 2e-16 ***\nORIGIN_SZBMSZ14      -0.9950458  0.0076302  -130.410  &lt; 2e-16 ***\nORIGIN_SZBMSZ15      -0.6544196  0.0068964   -94.892  &lt; 2e-16 ***\nORIGIN_SZBMSZ16      -1.5193747  0.0105329  -144.250  &lt; 2e-16 ***\nORIGIN_SZBMSZ17      -1.6536771  0.0180672   -91.529  &lt; 2e-16 ***\nORIGIN_SZBPSZ01       0.1484355  0.0064734    22.930  &lt; 2e-16 ***\nORIGIN_SZBPSZ02      -0.3602094  0.0073902   -48.741  &lt; 2e-16 ***\nORIGIN_SZBPSZ03      -0.1567975  0.0072226   -21.709  &lt; 2e-16 ***\nORIGIN_SZBPSZ04       0.4504873  0.0058418    77.115  &lt; 2e-16 ***\nORIGIN_SZBPSZ05       0.5028646  0.0053682    93.675  &lt; 2e-16 ***\nORIGIN_SZBPSZ06      -1.0125668  0.0105638   -95.853  &lt; 2e-16 ***\nORIGIN_SZBPSZ07      -0.3859065  0.0098561   -39.154  &lt; 2e-16 ***\nORIGIN_SZBSSZ01       0.1488497  0.0065504    22.724  &lt; 2e-16 ***\nORIGIN_SZBSSZ02       0.4269498  0.0055893    76.387  &lt; 2e-16 ***\nORIGIN_SZBSSZ03      -0.2437385  0.0062020   -39.300  &lt; 2e-16 ***\nORIGIN_SZBTSZ01       0.1987940  0.0066672    29.817  &lt; 2e-16 ***\nORIGIN_SZBTSZ02      -0.4571546  0.0090784   -50.356  &lt; 2e-16 ***\nORIGIN_SZBTSZ03      -0.2697243  0.0077941   -34.606  &lt; 2e-16 ***\nORIGIN_SZBTSZ04      -1.0997236  0.0115225   -95.441  &lt; 2e-16 ***\nORIGIN_SZBTSZ05      -1.0053122  0.0132594   -75.819  &lt; 2e-16 ***\nORIGIN_SZBTSZ06      -1.0841201  0.0102242  -106.035  &lt; 2e-16 ***\nORIGIN_SZBTSZ07      -2.3134497  0.0158499  -145.960  &lt; 2e-16 ***\nORIGIN_SZBTSZ08      -1.1581618  0.0121161   -95.589  &lt; 2e-16 ***\nORIGIN_SZCBSZ01      -1.0805930  0.0577831   -18.701  &lt; 2e-16 ***\nORIGIN_SZCCSZ01      -0.8145372  0.0152638   -53.364  &lt; 2e-16 ***\nORIGIN_SZCHSZ01       0.0377079  0.0133240     2.830 0.004654 ** \nORIGIN_SZCHSZ02      -0.6209553  0.0096388   -64.422  &lt; 2e-16 ***\nORIGIN_SZCHSZ03       1.6790244  0.0069559   241.381  &lt; 2e-16 ***\nORIGIN_SZCKSZ01       0.0839586  0.0059934    14.008  &lt; 2e-16 ***\nORIGIN_SZCKSZ02       0.4379511  0.0062289    70.309  &lt; 2e-16 ***\nORIGIN_SZCKSZ03       0.7956950  0.0051892   153.335  &lt; 2e-16 ***\nORIGIN_SZCKSZ04       1.2740323  0.0053165   239.637  &lt; 2e-16 ***\nORIGIN_SZCKSZ05       0.9326213  0.0061807   150.893  &lt; 2e-16 ***\nORIGIN_SZCKSZ06       0.3976273  0.0085639    46.431  &lt; 2e-16 ***\nORIGIN_SZCLSZ01      -0.7522917  0.0094655   -79.477  &lt; 2e-16 ***\nORIGIN_SZCLSZ02      -1.3937450  0.0153260   -90.940  &lt; 2e-16 ***\nORIGIN_SZCLSZ03      -0.7898683  0.0091016   -86.784  &lt; 2e-16 ***\nORIGIN_SZCLSZ04       0.8451512  0.0051258   164.882  &lt; 2e-16 ***\nORIGIN_SZCLSZ05      -1.6573818  0.0166091   -99.788  &lt; 2e-16 ***\nORIGIN_SZCLSZ06       0.9478181  0.0048182   196.716  &lt; 2e-16 ***\nORIGIN_SZCLSZ07      -0.2499753  0.0064632   -38.677  &lt; 2e-16 ***\nORIGIN_SZCLSZ08       0.1350119  0.0069296    19.483  &lt; 2e-16 ***\nORIGIN_SZCLSZ09      -1.3868782  0.0192743   -71.955  &lt; 2e-16 ***\nORIGIN_SZDTSZ02      -3.7535792  0.0871325   -43.079  &lt; 2e-16 ***\nORIGIN_SZDTSZ03      -3.8462041  0.0840156   -45.780  &lt; 2e-16 ***\nORIGIN_SZDTSZ13      -2.9738127  0.0349241   -85.151  &lt; 2e-16 ***\nORIGIN_SZGLSZ01      -1.5175198  0.0110135  -137.787  &lt; 2e-16 ***\nORIGIN_SZGLSZ02       0.2405712  0.0058742    40.954  &lt; 2e-16 ***\nORIGIN_SZGLSZ03       0.1940241  0.0061989    31.300  &lt; 2e-16 ***\nORIGIN_SZGLSZ04       1.0292572  0.0049028   209.931  &lt; 2e-16 ***\nORIGIN_SZGLSZ05       0.9864552  0.0050898   193.811  &lt; 2e-16 ***\nORIGIN_SZHGSZ01       0.3073609  0.0054307    56.597  &lt; 2e-16 ***\nORIGIN_SZHGSZ02       0.3827293  0.0054555    70.154  &lt; 2e-16 ***\nORIGIN_SZHGSZ03       0.2342580  0.0059240    39.544  &lt; 2e-16 ***\nORIGIN_SZHGSZ04       0.8750090  0.0049639   176.275  &lt; 2e-16 ***\nORIGIN_SZHGSZ05       1.1695280  0.0049468   236.420  &lt; 2e-16 ***\nORIGIN_SZHGSZ06      -0.0462411  0.0063805    -7.247 4.25e-13 ***\nORIGIN_SZHGSZ07       0.4488583  0.0055139    81.404  &lt; 2e-16 ***\nORIGIN_SZHGSZ08       0.2236095  0.0061279    36.490  &lt; 2e-16 ***\nORIGIN_SZHGSZ09      -1.6376674  0.0084442  -193.941  &lt; 2e-16 ***\nORIGIN_SZHGSZ10      -2.9849025  0.0501042   -59.574  &lt; 2e-16 ***\nORIGIN_SZJESZ01       0.3926525  0.0056268    69.783  &lt; 2e-16 ***\nORIGIN_SZJESZ02       0.1230160  0.0056864    21.633  &lt; 2e-16 ***\nORIGIN_SZJESZ03       0.0188276  0.0061020     3.085 0.002032 ** \nORIGIN_SZJESZ04      -1.3611618  0.0117184  -116.156  &lt; 2e-16 ***\nORIGIN_SZJESZ05      -2.0643662  0.0157083  -131.419  &lt; 2e-16 ***\nORIGIN_SZJESZ06       0.1556368  0.0055245    28.172  &lt; 2e-16 ***\nORIGIN_SZJESZ07      -1.7664532  0.0133171  -132.646  &lt; 2e-16 ***\nORIGIN_SZJESZ08      -0.9115981  0.0138203   -65.961  &lt; 2e-16 ***\nORIGIN_SZJESZ09       0.6121916  0.0060381   101.388  &lt; 2e-16 ***\nORIGIN_SZJESZ10      -1.1953045  0.0233216   -51.253  &lt; 2e-16 ***\nORIGIN_SZJESZ11      -1.4088748  0.0220921   -63.773  &lt; 2e-16 ***\nORIGIN_SZJWSZ01       0.5759093  0.0077741    74.081  &lt; 2e-16 ***\nORIGIN_SZJWSZ02       0.9769314  0.0053029   184.227  &lt; 2e-16 ***\nORIGIN_SZJWSZ03       1.3242695  0.0049068   269.882  &lt; 2e-16 ***\nORIGIN_SZJWSZ04       0.5621088  0.0057831    97.199  &lt; 2e-16 ***\nORIGIN_SZJWSZ05      -1.5744341  0.0146904  -107.174  &lt; 2e-16 ***\nORIGIN_SZJWSZ06      -0.9113320  0.0126913   -71.807  &lt; 2e-16 ***\nORIGIN_SZJWSZ07      -2.3083419  0.0357843   -64.507  &lt; 2e-16 ***\nORIGIN_SZJWSZ08       2.0114225  0.0047956   419.429  &lt; 2e-16 ***\nORIGIN_SZJWSZ09       1.9086705  0.0045255   421.759  &lt; 2e-16 ***\nORIGIN_SZKLSZ01       0.2743166  0.0056908    48.204  &lt; 2e-16 ***\nORIGIN_SZKLSZ02      -0.6443386  0.0074521   -86.463  &lt; 2e-16 ***\nORIGIN_SZKLSZ03      -0.3990113  0.0067213   -59.366  &lt; 2e-16 ***\nORIGIN_SZKLSZ04      -2.1413876  0.0138405  -154.719  &lt; 2e-16 ***\nORIGIN_SZKLSZ05      -1.0913697  0.0121512   -89.816  &lt; 2e-16 ***\nORIGIN_SZKLSZ06      -5.6240764  0.1857405   -30.279  &lt; 2e-16 ***\nORIGIN_SZKLSZ07      -1.1885897  0.0096830  -122.750  &lt; 2e-16 ***\nORIGIN_SZKLSZ08      -1.7018593  0.0114317  -148.872  &lt; 2e-16 ***\nORIGIN_SZLKSZ01      -1.6659670  0.0446420   -37.318  &lt; 2e-16 ***\nORIGIN_SZMDSZ01      -1.1210505  0.0318834   -35.161  &lt; 2e-16 ***\nORIGIN_SZMDSZ02      -0.5096299  0.0116645   -43.691  &lt; 2e-16 ***\nORIGIN_SZMDSZ03      -1.9187039  0.0198291   -96.762  &lt; 2e-16 ***\nORIGIN_SZMPSZ01      -0.5260512  0.0094201   -55.844  &lt; 2e-16 ***\nORIGIN_SZMPSZ02      -0.2905084  0.0077974   -37.257  &lt; 2e-16 ***\nORIGIN_SZMPSZ03       0.3342293  0.0063715    52.457  &lt; 2e-16 ***\nORIGIN_SZMUSZ02      -3.8337096  0.1105053   -34.693  &lt; 2e-16 ***\nORIGIN_SZNTSZ01      -2.9845040  0.0397028   -75.171  &lt; 2e-16 ***\nORIGIN_SZNTSZ02      -3.1812985  0.0249470  -127.522  &lt; 2e-16 ***\nORIGIN_SZNTSZ03      -0.9742991  0.0085424  -114.054  &lt; 2e-16 ***\nORIGIN_SZNTSZ05      -4.2086932  0.0579737   -72.597  &lt; 2e-16 ***\nORIGIN_SZNTSZ06      -4.5831822  0.0583494   -78.547  &lt; 2e-16 ***\nORIGIN_SZNVSZ01       0.3186962  0.0052944    60.195  &lt; 2e-16 ***\nORIGIN_SZNVSZ02      -0.5321136  0.0073747   -72.154  &lt; 2e-16 ***\nORIGIN_SZNVSZ03      -0.9911852  0.0090560  -109.451  &lt; 2e-16 ***\nORIGIN_SZNVSZ04      -0.8329721  0.0099590   -83.640  &lt; 2e-16 ***\nORIGIN_SZNVSZ05      -2.1460777  0.0182401  -117.657  &lt; 2e-16 ***\nORIGIN_SZPGSZ01      -0.5604078  0.0151515   -36.987  &lt; 2e-16 ***\nORIGIN_SZPGSZ02      -0.4025139  0.0085135   -47.279  &lt; 2e-16 ***\nORIGIN_SZPGSZ03       0.6975483  0.0055534   125.608  &lt; 2e-16 ***\nORIGIN_SZPGSZ04       1.2175486  0.0051080   238.363  &lt; 2e-16 ***\nORIGIN_SZPGSZ05       0.3895354  0.0069851    55.767  &lt; 2e-16 ***\nORIGIN_SZPLSZ01      -0.5572701  0.0134473   -41.441  &lt; 2e-16 ***\nORIGIN_SZPLSZ02      -0.9854214  0.0172337   -57.180  &lt; 2e-16 ***\nORIGIN_SZPLSZ03      -1.6991954  0.0472629   -35.952  &lt; 2e-16 ***\nORIGIN_SZPLSZ04      -2.2000217  0.0373580   -58.890  &lt; 2e-16 ***\nORIGIN_SZPLSZ05      -1.7086663  0.0260920   -65.486  &lt; 2e-16 ***\nORIGIN_SZPNSZ01       1.5292867  0.0055102   277.535  &lt; 2e-16 ***\nORIGIN_SZPNSZ02       0.7457519  0.0127815    58.346  &lt; 2e-16 ***\nORIGIN_SZPNSZ03      -1.3659046  0.0216180   -63.184  &lt; 2e-16 ***\nORIGIN_SZPNSZ04      -2.0025379  0.0360655   -55.525  &lt; 2e-16 ***\nORIGIN_SZPNSZ05      -0.9157959  0.0320955   -28.533  &lt; 2e-16 ***\nORIGIN_SZPRSZ01       0.0522611  0.0139142     3.756 0.000173 ***\nORIGIN_SZPRSZ02       1.3063371  0.0053809   242.774  &lt; 2e-16 ***\nORIGIN_SZPRSZ03       0.9963670  0.0054293   183.516  &lt; 2e-16 ***\nORIGIN_SZPRSZ04      -0.0300950  0.0088010    -3.419 0.000627 ***\nORIGIN_SZPRSZ05       1.6840313  0.0050839   331.245  &lt; 2e-16 ***\nORIGIN_SZPRSZ06      -0.8277202  0.0131296   -63.042  &lt; 2e-16 ***\nORIGIN_SZPRSZ07      -2.1698449  0.0177362  -122.340  &lt; 2e-16 ***\nORIGIN_SZPRSZ08       0.4559353  0.0072609    62.793  &lt; 2e-16 ***\nORIGIN_SZQTSZ01      -0.3517047  0.0078770   -44.650  &lt; 2e-16 ***\nORIGIN_SZQTSZ02      -0.8199353  0.0071544  -114.605  &lt; 2e-16 ***\nORIGIN_SZQTSZ03      -0.2457614  0.0065555   -37.490  &lt; 2e-16 ***\nORIGIN_SZQTSZ04      -1.2216614  0.0084050  -145.349  &lt; 2e-16 ***\nORIGIN_SZQTSZ05      -0.7219952  0.0072360   -99.778  &lt; 2e-16 ***\nORIGIN_SZQTSZ06      -0.6729363  0.0076658   -87.784  &lt; 2e-16 ***\nORIGIN_SZQTSZ07      -1.4497690  0.0109365  -132.563  &lt; 2e-16 ***\nORIGIN_SZQTSZ08      -0.2770151  0.0070193   -39.465  &lt; 2e-16 ***\nORIGIN_SZQTSZ09      -0.6157554  0.0078739   -78.202  &lt; 2e-16 ***\nORIGIN_SZQTSZ10      -0.3091547  0.0075471   -40.963  &lt; 2e-16 ***\nORIGIN_SZQTSZ11      -1.9698881  0.0151247  -130.243  &lt; 2e-16 ***\nORIGIN_SZQTSZ12      -2.6449643  0.0205857  -128.485  &lt; 2e-16 ***\nORIGIN_SZQTSZ13      -0.3754107  0.0088433   -42.452  &lt; 2e-16 ***\nORIGIN_SZQTSZ14      -1.6537473  0.0134378  -123.067  &lt; 2e-16 ***\nORIGIN_SZQTSZ15      -0.3435351  0.0131956   -26.034  &lt; 2e-16 ***\nORIGIN_SZRCSZ01      -1.7104390  0.0141179  -121.154  &lt; 2e-16 ***\nORIGIN_SZRCSZ06      -1.1250727  0.0094909  -118.542  &lt; 2e-16 ***\nORIGIN_SZRVSZ01      -3.0220116  0.0339694   -88.963  &lt; 2e-16 ***\nORIGIN_SZRVSZ02      -3.6040075  0.0297641  -121.086  &lt; 2e-16 ***\nORIGIN_SZRVSZ03      -3.2345594  0.0259149  -124.814  &lt; 2e-16 ***\nORIGIN_SZRVSZ04      -3.6900313  0.0575908   -64.073  &lt; 2e-16 ***\nORIGIN_SZRVSZ05      -2.9527570  0.0178582  -165.344  &lt; 2e-16 ***\nORIGIN_SZSBSZ01       0.0238445  0.0078563     3.035 0.002405 ** \nORIGIN_SZSBSZ02      -0.5780602  0.0093054   -62.121  &lt; 2e-16 ***\nORIGIN_SZSBSZ03       0.8961719  0.0054586   164.175  &lt; 2e-16 ***\nORIGIN_SZSBSZ04       0.8421798  0.0061888   136.080  &lt; 2e-16 ***\nORIGIN_SZSBSZ05      -0.1682984  0.0078342   -21.482  &lt; 2e-16 ***\nORIGIN_SZSBSZ06      -1.1482701  0.0196421   -58.460  &lt; 2e-16 ***\nORIGIN_SZSBSZ07      -0.8830317  0.0160709   -54.946  &lt; 2e-16 ***\nORIGIN_SZSBSZ08      -1.1039492  0.0174602   -63.226  &lt; 2e-16 ***\nORIGIN_SZSBSZ09      -0.5946691  0.0101961   -58.323  &lt; 2e-16 ***\nORIGIN_SZSESZ02       1.1144933  0.0050948   218.749  &lt; 2e-16 ***\nORIGIN_SZSESZ03       1.1058963  0.0049026   225.574  &lt; 2e-16 ***\nORIGIN_SZSESZ04       0.7427975  0.0056948   130.433  &lt; 2e-16 ***\nORIGIN_SZSESZ05      -0.2812684  0.0069596   -40.414  &lt; 2e-16 ***\nORIGIN_SZSESZ06       0.8168315  0.0055800   146.387  &lt; 2e-16 ***\nORIGIN_SZSESZ07      -2.2842043  0.0231232   -98.784  &lt; 2e-16 ***\nORIGIN_SZSGSZ01      -0.7313790  0.0098957   -73.909  &lt; 2e-16 ***\nORIGIN_SZSGSZ02      -1.1185406  0.0110919  -100.843  &lt; 2e-16 ***\nORIGIN_SZSGSZ03       0.1752618  0.0060508    28.965  &lt; 2e-16 ***\nORIGIN_SZSGSZ04       0.3764395  0.0056165    67.023  &lt; 2e-16 ***\nORIGIN_SZSGSZ05      -1.7203916  0.0118945  -144.637  &lt; 2e-16 ***\nORIGIN_SZSGSZ06       0.4630857  0.0052886    87.563  &lt; 2e-16 ***\nORIGIN_SZSGSZ07      -0.7051233  0.0073133   -96.417  &lt; 2e-16 ***\nORIGIN_SZSKSZ01       0.2053928  0.0100710    20.395  &lt; 2e-16 ***\nORIGIN_SZSKSZ02       1.2630428  0.0063490   198.935  &lt; 2e-16 ***\nORIGIN_SZSKSZ03      -0.3035297  0.0096788   -31.360  &lt; 2e-16 ***\nORIGIN_SZSKSZ04      -1.7952886  0.0359225   -49.977  &lt; 2e-16 ***\nORIGIN_SZSKSZ05      -0.3836861  0.0176686   -21.716  &lt; 2e-16 ***\nORIGIN_SZSLSZ01      -2.5916326  0.0348001   -74.472  &lt; 2e-16 ***\nORIGIN_SZSLSZ04      -0.2251549  0.0088517   -25.436  &lt; 2e-16 ***\nORIGIN_SZSRSZ01      -2.9590365  0.0173638  -170.414  &lt; 2e-16 ***\nORIGIN_SZTHSZ01      -1.9639893  0.0570321   -34.437  &lt; 2e-16 ***\nORIGIN_SZTHSZ03      -1.7281304  0.0272797   -63.349  &lt; 2e-16 ***\nORIGIN_SZTHSZ04      -2.7837906  0.0343179   -81.118  &lt; 2e-16 ***\nORIGIN_SZTHSZ06      -2.1800693  0.0205491  -106.091  &lt; 2e-16 ***\nORIGIN_SZTMSZ01       0.8228136  0.0066824   123.131  &lt; 2e-16 ***\nORIGIN_SZTMSZ02       2.3174781  0.0044978   515.243  &lt; 2e-16 ***\nORIGIN_SZTMSZ03       1.7061757  0.0048615   350.957  &lt; 2e-16 ***\nORIGIN_SZTMSZ04       1.2407899  0.0058389   212.504  &lt; 2e-16 ***\nORIGIN_SZTMSZ05      -0.1000526  0.0124079    -8.064 7.41e-16 ***\nORIGIN_SZTNSZ01      -2.0347519  0.0139596  -145.760  &lt; 2e-16 ***\nORIGIN_SZTNSZ02      -1.8682671  0.0107901  -173.146  &lt; 2e-16 ***\nORIGIN_SZTNSZ03      -2.1737183  0.0146759  -148.115  &lt; 2e-16 ***\nORIGIN_SZTNSZ04      -0.5006452  0.0081501   -61.428  &lt; 2e-16 ***\nORIGIN_SZTPSZ01      -0.6722487  0.0075606   -88.914  &lt; 2e-16 ***\nORIGIN_SZTPSZ02       0.4552916  0.0050191    90.711  &lt; 2e-16 ***\nORIGIN_SZTPSZ03      -0.7865781  0.0072250  -108.869  &lt; 2e-16 ***\nORIGIN_SZTPSZ04      -0.7049044  0.0066456  -106.071  &lt; 2e-16 ***\nORIGIN_SZTPSZ05      -0.5574925  0.0070366   -79.227  &lt; 2e-16 ***\nORIGIN_SZTPSZ06      -0.4247282  0.0068709   -61.815  &lt; 2e-16 ***\nORIGIN_SZTPSZ07      -0.2846984  0.0071030   -40.081  &lt; 2e-16 ***\nORIGIN_SZTPSZ08      -1.0898051  0.0110046   -99.031  &lt; 2e-16 ***\nORIGIN_SZTPSZ09      -0.8092746  0.0079160  -102.232  &lt; 2e-16 ***\nORIGIN_SZTPSZ10      -0.9332072  0.0086809  -107.502  &lt; 2e-16 ***\nORIGIN_SZTPSZ11      -0.0421981  0.0064343    -6.558 5.44e-11 ***\nORIGIN_SZTPSZ12      -0.6330081  0.0078324   -80.819  &lt; 2e-16 ***\nORIGIN_SZTSSZ01      -1.7650409  0.0517357   -34.116  &lt; 2e-16 ***\nORIGIN_SZTSSZ02       1.1707267  0.0094178   124.310  &lt; 2e-16 ***\nORIGIN_SZTSSZ03       0.6581679  0.0095894    68.635  &lt; 2e-16 ***\nORIGIN_SZTSSZ04       0.8736493  0.0104965    83.233  &lt; 2e-16 ***\nORIGIN_SZTSSZ05       0.0957248  0.0178709     5.356 8.49e-08 ***\nORIGIN_SZTSSZ06       1.7581609  0.0206810    85.013  &lt; 2e-16 ***\nORIGIN_SZWCSZ01       0.8097950  0.0105622    76.669  &lt; 2e-16 ***\nORIGIN_SZWCSZ02      -1.9966163  0.0345747   -57.748  &lt; 2e-16 ***\nORIGIN_SZWCSZ03      -5.0687420  0.1474971   -34.365  &lt; 2e-16 ***\nORIGIN_SZWDSZ01       1.4926003  0.0047216   316.124  &lt; 2e-16 ***\nORIGIN_SZWDSZ02       0.9916597  0.0055755   177.859  &lt; 2e-16 ***\nORIGIN_SZWDSZ03       1.5918065  0.0052180   305.062  &lt; 2e-16 ***\nORIGIN_SZWDSZ04       1.3717152  0.0060516   226.669  &lt; 2e-16 ***\nORIGIN_SZWDSZ05       0.6700111  0.0062287   107.569  &lt; 2e-16 ***\nORIGIN_SZWDSZ06       0.8115996  0.0060947   133.165  &lt; 2e-16 ***\nORIGIN_SZWDSZ07      -0.6488914  0.0093567   -69.351  &lt; 2e-16 ***\nORIGIN_SZWDSZ08      -0.3610234  0.0096440   -37.435  &lt; 2e-16 ***\nORIGIN_SZWDSZ09       1.4445461  0.0052279   276.317  &lt; 2e-16 ***\nORIGIN_SZYSSZ01      -0.2039272  0.0069548   -29.322  &lt; 2e-16 ***\nORIGIN_SZYSSZ02       0.8707707  0.0058957   147.697  &lt; 2e-16 ***\nORIGIN_SZYSSZ03       1.8348842  0.0050377   364.231  &lt; 2e-16 ***\nORIGIN_SZYSSZ04       1.0780641  0.0052960   203.564  &lt; 2e-16 ***\nORIGIN_SZYSSZ05       0.3222765  0.0069700    46.237  &lt; 2e-16 ***\nORIGIN_SZYSSZ06      -0.4424689  0.0124866   -35.435  &lt; 2e-16 ***\nORIGIN_SZYSSZ07      -1.0267883  0.0155821   -65.895  &lt; 2e-16 ***\nORIGIN_SZYSSZ08       0.1833117  0.0070935    25.842  &lt; 2e-16 ***\nORIGIN_SZYSSZ09       1.0766070  0.0050451   213.396  &lt; 2e-16 ***\nlog(DESTIN_AGE25_64)  0.0295428  0.0001051   280.998  &lt; 2e-16 ***\nlog(dist)            -1.7024691  0.0004625 -3681.042  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance: 12983718  on 13993  degrees of freedom\nAIC: 13068835\n\nNumber of Fisher Scoring iterations: 6\n\n\nWe can use our function to calculate the R-squared.\n\nCalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)\n\n[1] 0.4029115\n\n\n\n\nDestination Constrained\nSimilarly, we can fit a destination constrained SIM\n\ndecSIM &lt;- glm(formula = TRIPS ~\n                DESTIN_SZ +\n                log(ORIGIN_AGE25_64)+\n                log(dist),\n              family = poisson(link = 'log'),\n              data = SIM_data,\n              na.action = na.exclude)\n\nsummary(decSIM)\n\n\nCall:\nglm(formula = TRIPS ~ DESTIN_SZ + log(ORIGIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          19.4822997  0.0050784  3836.298  &lt; 2e-16 ***\nDESTIN_SZAMSZ02       0.1263056  0.0049743    25.392  &lt; 2e-16 ***\nDESTIN_SZAMSZ03       0.0421788  0.0049859     8.460  &lt; 2e-16 ***\nDESTIN_SZAMSZ04      -1.1668479  0.0074254  -157.143  &lt; 2e-16 ***\nDESTIN_SZAMSZ05      -1.2586639  0.0075854  -165.931  &lt; 2e-16 ***\nDESTIN_SZAMSZ06      -1.1414791  0.0073474  -155.359  &lt; 2e-16 ***\nDESTIN_SZAMSZ07      -1.5565804  0.0109476  -142.185  &lt; 2e-16 ***\nDESTIN_SZAMSZ08      -0.3990754  0.0074159   -53.813  &lt; 2e-16 ***\nDESTIN_SZAMSZ09      -1.0109118  0.0076802  -131.626  &lt; 2e-16 ***\nDESTIN_SZAMSZ10       0.0159285  0.0051765     3.077  0.00209 ** \nDESTIN_SZAMSZ11      -0.3653273  0.0094866   -38.510  &lt; 2e-16 ***\nDESTIN_SZAMSZ12       0.5297606  0.0053243    99.500  &lt; 2e-16 ***\nDESTIN_SZBDSZ01       1.0394822  0.0044226   235.037  &lt; 2e-16 ***\nDESTIN_SZBDSZ02       0.1956964  0.0059564    32.855  &lt; 2e-16 ***\nDESTIN_SZBDSZ03       0.3209267  0.0053718    59.742  &lt; 2e-16 ***\nDESTIN_SZBDSZ04       1.2429874  0.0043104   288.370  &lt; 2e-16 ***\nDESTIN_SZBDSZ05       0.8535842  0.0046360   184.122  &lt; 2e-16 ***\nDESTIN_SZBDSZ06       0.5181443  0.0053736    96.423  &lt; 2e-16 ***\nDESTIN_SZBDSZ07      -0.5849371  0.0110468   -52.951  &lt; 2e-16 ***\nDESTIN_SZBDSZ08      -1.2871050  0.0128623  -100.068  &lt; 2e-16 ***\nDESTIN_SZBKSZ01      -1.0633560  0.0077771  -136.730  &lt; 2e-16 ***\nDESTIN_SZBKSZ02      -0.4065316  0.0066712   -60.938  &lt; 2e-16 ***\nDESTIN_SZBKSZ03      -0.6815674  0.0066509  -102.477  &lt; 2e-16 ***\nDESTIN_SZBKSZ04      -0.4185485  0.0058306   -71.785  &lt; 2e-16 ***\nDESTIN_SZBKSZ05      -0.8887654  0.0073867  -120.319  &lt; 2e-16 ***\nDESTIN_SZBKSZ06      -0.9436078  0.0068625  -137.501  &lt; 2e-16 ***\nDESTIN_SZBKSZ07      -0.0067325  0.0048408    -1.391  0.16430    \nDESTIN_SZBKSZ08      -1.2680903  0.0079177  -160.160  &lt; 2e-16 ***\nDESTIN_SZBKSZ09      -0.0350151  0.0054287    -6.450 1.12e-10 ***\nDESTIN_SZBLSZ01      -0.3045203  0.0081978   -37.146  &lt; 2e-16 ***\nDESTIN_SZBLSZ02       0.6432424  0.0074449    86.400  &lt; 2e-16 ***\nDESTIN_SZBLSZ03       1.9595113  0.0084705   231.333  &lt; 2e-16 ***\nDESTIN_SZBLSZ04       0.0149756  0.0172081     0.870  0.38415    \nDESTIN_SZBMSZ01      -0.0378127  0.0055294    -6.838 8.00e-12 ***\nDESTIN_SZBMSZ02      -0.8458055  0.0054043  -156.505  &lt; 2e-16 ***\nDESTIN_SZBMSZ03      -1.1334399  0.0063720  -177.878  &lt; 2e-16 ***\nDESTIN_SZBMSZ04      -1.1164759  0.0057743  -193.353  &lt; 2e-16 ***\nDESTIN_SZBMSZ05      -1.1078742  0.0078703  -140.766  &lt; 2e-16 ***\nDESTIN_SZBMSZ06      -2.2787234  0.0155126  -146.895  &lt; 2e-16 ***\nDESTIN_SZBMSZ07      -0.2739089  0.0051924   -52.752  &lt; 2e-16 ***\nDESTIN_SZBMSZ08      -1.6825978  0.0071842  -234.209  &lt; 2e-16 ***\nDESTIN_SZBMSZ09      -3.0047801  0.0159980  -187.823  &lt; 2e-16 ***\nDESTIN_SZBMSZ10      -2.2232689  0.0096907  -229.423  &lt; 2e-16 ***\nDESTIN_SZBMSZ11      -1.9657136  0.0086445  -227.394  &lt; 2e-16 ***\nDESTIN_SZBMSZ12      -1.5359286  0.0089658  -171.310  &lt; 2e-16 ***\nDESTIN_SZBMSZ13      -0.5657561  0.0059960   -94.355  &lt; 2e-16 ***\nDESTIN_SZBMSZ14      -1.6904858  0.0084858  -199.214  &lt; 2e-16 ***\nDESTIN_SZBMSZ15      -1.5268383  0.0079959  -190.953  &lt; 2e-16 ***\nDESTIN_SZBMSZ16      -2.2045600  0.0130872  -168.452  &lt; 2e-16 ***\nDESTIN_SZBMSZ17      -2.2992381  0.0184895  -124.353  &lt; 2e-16 ***\nDESTIN_SZBPSZ01      -0.8549497  0.0065168  -131.191  &lt; 2e-16 ***\nDESTIN_SZBPSZ02      -1.7470549  0.0095751  -182.457  &lt; 2e-16 ***\nDESTIN_SZBPSZ03      -1.4015145  0.0090888  -154.203  &lt; 2e-16 ***\nDESTIN_SZBPSZ04      -0.5250632  0.0066496   -78.962  &lt; 2e-16 ***\nDESTIN_SZBPSZ05       0.3413171  0.0046404    73.553  &lt; 2e-16 ***\nDESTIN_SZBPSZ06      -0.8569188  0.0090795   -94.380  &lt; 2e-16 ***\nDESTIN_SZBPSZ07      -0.0751284  0.0089704    -8.375  &lt; 2e-16 ***\nDESTIN_SZBSSZ01       0.1015228  0.0055735    18.215  &lt; 2e-16 ***\nDESTIN_SZBSSZ02      -0.7066412  0.0063845  -110.682  &lt; 2e-16 ***\nDESTIN_SZBSSZ03       0.1622730  0.0046689    34.756  &lt; 2e-16 ***\nDESTIN_SZBTSZ01       0.5470615  0.0047984   114.009  &lt; 2e-16 ***\nDESTIN_SZBTSZ02      -0.1393371  0.0078266   -17.803  &lt; 2e-16 ***\nDESTIN_SZBTSZ03       0.1474771  0.0059428    24.816  &lt; 2e-16 ***\nDESTIN_SZBTSZ04      -1.2857827  0.0122000  -105.392  &lt; 2e-16 ***\nDESTIN_SZBTSZ05      -0.2629188  0.0081769   -32.154  &lt; 2e-16 ***\nDESTIN_SZBTSZ06      -0.8319920  0.0081401  -102.209  &lt; 2e-16 ***\nDESTIN_SZBTSZ07      -1.8829448  0.0121227  -155.324  &lt; 2e-16 ***\nDESTIN_SZBTSZ08      -1.5732123  0.0116752  -134.748  &lt; 2e-16 ***\nDESTIN_SZCBSZ01      -3.5334327  0.3333510   -10.600  &lt; 2e-16 ***\nDESTIN_SZCCSZ01      -0.2129306  0.0093782   -22.705  &lt; 2e-16 ***\nDESTIN_SZCHSZ01      -0.1494972  0.0113078   -13.221  &lt; 2e-16 ***\nDESTIN_SZCHSZ02       0.0041774  0.0063195     0.661  0.50860    \nDESTIN_SZCHSZ03       2.5565450  0.0046495   549.857  &lt; 2e-16 ***\nDESTIN_SZCKSZ01       0.0489719  0.0053801     9.102  &lt; 2e-16 ***\nDESTIN_SZCKSZ02      -0.3548993  0.0060671   -58.496  &lt; 2e-16 ***\nDESTIN_SZCKSZ03       0.5386351  0.0044913   119.928  &lt; 2e-16 ***\nDESTIN_SZCKSZ04      -0.4425512  0.0073837   -59.936  &lt; 2e-16 ***\nDESTIN_SZCKSZ05      -0.4092591  0.0077267   -52.967  &lt; 2e-16 ***\nDESTIN_SZCKSZ06       0.2207041  0.0074252    29.724  &lt; 2e-16 ***\nDESTIN_SZCLSZ01       0.2851460  0.0052362    54.457  &lt; 2e-16 ***\nDESTIN_SZCLSZ02      -1.9270528  0.0147688  -130.482  &lt; 2e-16 ***\nDESTIN_SZCLSZ03      -0.6266521  0.0086780   -72.212  &lt; 2e-16 ***\nDESTIN_SZCLSZ04      -0.1335581  0.0054216   -24.634  &lt; 2e-16 ***\nDESTIN_SZCLSZ05      -0.8912963  0.0096015   -92.829  &lt; 2e-16 ***\nDESTIN_SZCLSZ06       0.1781234  0.0048150    36.993  &lt; 2e-16 ***\nDESTIN_SZCLSZ07      -0.5609619  0.0062277   -90.075  &lt; 2e-16 ***\nDESTIN_SZCLSZ08      -0.3875308  0.0068390   -56.665  &lt; 2e-16 ***\nDESTIN_SZCLSZ09       0.2539453  0.0072623    34.968  &lt; 2e-16 ***\nDESTIN_SZDTSZ02      -2.5036295  0.0373421   -67.046  &lt; 2e-16 ***\nDESTIN_SZDTSZ03      -0.8956407  0.0149971   -59.721  &lt; 2e-16 ***\nDESTIN_SZDTSZ13      -1.6562176  0.0175441   -94.403  &lt; 2e-16 ***\nDESTIN_SZGLSZ01      -0.2716152  0.0056553   -48.029  &lt; 2e-16 ***\nDESTIN_SZGLSZ02      -0.1735665  0.0055548   -31.246  &lt; 2e-16 ***\nDESTIN_SZGLSZ03       0.7029507  0.0044934   156.441  &lt; 2e-16 ***\nDESTIN_SZGLSZ04       0.5788027  0.0045449   127.351  &lt; 2e-16 ***\nDESTIN_SZGLSZ05       0.6865291  0.0045131   152.118  &lt; 2e-16 ***\nDESTIN_SZHGSZ01       0.3275950  0.0043866    74.681  &lt; 2e-16 ***\nDESTIN_SZHGSZ02      -0.6326974  0.0063517   -99.610  &lt; 2e-16 ***\nDESTIN_SZHGSZ03      -1.0597982  0.0073914  -143.382  &lt; 2e-16 ***\nDESTIN_SZHGSZ04      -0.2267013  0.0052178   -43.448  &lt; 2e-16 ***\nDESTIN_SZHGSZ05      -0.3063050  0.0055452   -55.238  &lt; 2e-16 ***\nDESTIN_SZHGSZ06      -0.7483961  0.0065544  -114.182  &lt; 2e-16 ***\nDESTIN_SZHGSZ07       0.1096958  0.0051309    21.379  &lt; 2e-16 ***\nDESTIN_SZHGSZ08      -0.1374201  0.0056692   -24.240  &lt; 2e-16 ***\nDESTIN_SZHGSZ09       0.0775400  0.0060230    12.874  &lt; 2e-16 ***\nDESTIN_SZHGSZ10      -3.3017475  0.0289292  -114.132  &lt; 2e-16 ***\nDESTIN_SZJESZ01      -0.0489065  0.0057246    -8.543  &lt; 2e-16 ***\nDESTIN_SZJESZ02      -0.5101614  0.0060074   -84.921  &lt; 2e-16 ***\nDESTIN_SZJESZ03      -0.5328921  0.0064129   -83.097  &lt; 2e-16 ***\nDESTIN_SZJESZ04      -0.7348953  0.0082249   -89.351  &lt; 2e-16 ***\nDESTIN_SZJESZ05      -1.0864570  0.0111740   -97.231  &lt; 2e-16 ***\nDESTIN_SZJESZ06       0.2407920  0.0046801    51.451  &lt; 2e-16 ***\nDESTIN_SZJESZ07      -1.1523093  0.0090103  -127.888  &lt; 2e-16 ***\nDESTIN_SZJESZ08      -0.4627356  0.0094529   -48.952  &lt; 2e-16 ***\nDESTIN_SZJESZ09       0.0528616  0.0068126     7.759 8.53e-15 ***\nDESTIN_SZJESZ10       1.0240660  0.0084045   121.848  &lt; 2e-16 ***\nDESTIN_SZJESZ11       0.7875517  0.0076251   103.284  &lt; 2e-16 ***\nDESTIN_SZJWSZ01      -0.1533418  0.0076198   -20.124  &lt; 2e-16 ***\nDESTIN_SZJWSZ02      -0.0011019  0.0059389    -0.186  0.85280    \nDESTIN_SZJWSZ03       0.9063789  0.0046747   193.892  &lt; 2e-16 ***\nDESTIN_SZJWSZ04       0.7019286  0.0049743   141.112  &lt; 2e-16 ***\nDESTIN_SZJWSZ05      -0.5197057  0.0072971   -71.220  &lt; 2e-16 ***\nDESTIN_SZJWSZ06       0.3350986  0.0061171    54.780  &lt; 2e-16 ***\nDESTIN_SZJWSZ07      -0.5961960  0.0328336   -18.158  &lt; 2e-16 ***\nDESTIN_SZJWSZ08       0.8054662  0.0056006   143.819  &lt; 2e-16 ***\nDESTIN_SZJWSZ09       1.5860146  0.0040282   393.723  &lt; 2e-16 ***\nDESTIN_SZKLSZ01      -0.6500838  0.0063560  -102.279  &lt; 2e-16 ***\nDESTIN_SZKLSZ02      -0.7039434  0.0064465  -109.197  &lt; 2e-16 ***\nDESTIN_SZKLSZ03      -1.1972384  0.0075577  -158.413  &lt; 2e-16 ***\nDESTIN_SZKLSZ04      -1.7172228  0.0097573  -175.993  &lt; 2e-16 ***\nDESTIN_SZKLSZ05      -0.6042386  0.0093730   -64.466  &lt; 2e-16 ***\nDESTIN_SZKLSZ06      -3.0201496  0.0389503   -77.539  &lt; 2e-16 ***\nDESTIN_SZKLSZ07      -1.1522413  0.0076607  -150.409  &lt; 2e-16 ***\nDESTIN_SZKLSZ08      -0.6977825  0.0057610  -121.122  &lt; 2e-16 ***\nDESTIN_SZLKSZ01      -0.6895952  0.0268661   -25.668  &lt; 2e-16 ***\nDESTIN_SZMDSZ01      -0.7155951  0.0228203   -31.358  &lt; 2e-16 ***\nDESTIN_SZMDSZ02      -0.8153643  0.0123003   -66.288  &lt; 2e-16 ***\nDESTIN_SZMDSZ03      -2.7745226  0.0301326   -92.077  &lt; 2e-16 ***\nDESTIN_SZMPSZ01      -0.5492095  0.0087198   -62.984  &lt; 2e-16 ***\nDESTIN_SZMPSZ02      -0.6104744  0.0069346   -88.033  &lt; 2e-16 ***\nDESTIN_SZMPSZ03       0.2775047  0.0054964    50.489  &lt; 2e-16 ***\nDESTIN_SZMUSZ02      -2.6322870  0.0214943  -122.464  &lt; 2e-16 ***\nDESTIN_SZNTSZ01      -4.0762008  0.0531046   -76.758  &lt; 2e-16 ***\nDESTIN_SZNTSZ02      -1.9765545  0.0125659  -157.296  &lt; 2e-16 ***\nDESTIN_SZNTSZ03      -1.4563069  0.0085433  -170.462  &lt; 2e-16 ***\nDESTIN_SZNTSZ05      -2.0125598  0.0270737   -74.336  &lt; 2e-16 ***\nDESTIN_SZNTSZ06      -3.0145357  0.0504986   -59.695  &lt; 2e-16 ***\nDESTIN_SZNVSZ01      -0.4693625  0.0053866   -87.135  &lt; 2e-16 ***\nDESTIN_SZNVSZ02      -0.4525631  0.0060428   -74.894  &lt; 2e-16 ***\nDESTIN_SZNVSZ03      -0.4821492  0.0064725   -74.492  &lt; 2e-16 ***\nDESTIN_SZNVSZ04      -1.8929756  0.0128397  -147.432  &lt; 2e-16 ***\nDESTIN_SZNVSZ05      -1.4501752  0.0099737  -145.400  &lt; 2e-16 ***\nDESTIN_SZPGSZ01      -1.2305867  0.0174321   -70.593  &lt; 2e-16 ***\nDESTIN_SZPGSZ02      -0.8232919  0.0080153  -102.715  &lt; 2e-16 ***\nDESTIN_SZPGSZ03       0.2138480  0.0050850    42.054  &lt; 2e-16 ***\nDESTIN_SZPGSZ04       0.1045757  0.0053579    19.518  &lt; 2e-16 ***\nDESTIN_SZPGSZ05      -0.7542450  0.0088883   -84.858  &lt; 2e-16 ***\nDESTIN_SZPLSZ01      -0.0098642  0.0080428    -1.226  0.22003    \nDESTIN_SZPLSZ02      -1.2630412  0.0152594   -82.771  &lt; 2e-16 ***\nDESTIN_SZPLSZ03      -0.1554479  0.0108611   -14.312  &lt; 2e-16 ***\nDESTIN_SZPLSZ04      -1.5505819  0.0114768  -135.105  &lt; 2e-16 ***\nDESTIN_SZPLSZ05      -0.2417805  0.0130391   -18.543  &lt; 2e-16 ***\nDESTIN_SZPNSZ01       0.7926715  0.0073628   107.659  &lt; 2e-16 ***\nDESTIN_SZPNSZ02       2.1914920  0.0073537   298.013  &lt; 2e-16 ***\nDESTIN_SZPNSZ03       1.0246845  0.0086874   117.951  &lt; 2e-16 ***\nDESTIN_SZPNSZ04       2.5522612  0.0091789   278.057  &lt; 2e-16 ***\nDESTIN_SZPNSZ05       1.7995301  0.0138562   129.872  &lt; 2e-16 ***\nDESTIN_SZPRSZ01      -0.6576686  0.0096037   -68.481  &lt; 2e-16 ***\nDESTIN_SZPRSZ02       0.3113532  0.0059851    52.021  &lt; 2e-16 ***\nDESTIN_SZPRSZ03       0.9255296  0.0044779   206.687  &lt; 2e-16 ***\nDESTIN_SZPRSZ04      -0.0028578  0.0093218    -0.307  0.75917    \nDESTIN_SZPRSZ05       0.2457863  0.0058261    42.187  &lt; 2e-16 ***\nDESTIN_SZPRSZ06       0.3692137  0.0064542    57.205  &lt; 2e-16 ***\nDESTIN_SZPRSZ07      -1.6733306  0.0138440  -120.871  &lt; 2e-16 ***\nDESTIN_SZPRSZ08      -0.2221048  0.0074846   -29.675  &lt; 2e-16 ***\nDESTIN_SZQTSZ01      -1.0185488  0.0093179  -109.311  &lt; 2e-16 ***\nDESTIN_SZQTSZ02      -1.2802688  0.0081670  -156.761  &lt; 2e-16 ***\nDESTIN_SZQTSZ03      -1.3322708  0.0079106  -168.415  &lt; 2e-16 ***\nDESTIN_SZQTSZ04      -1.1803631  0.0077366  -152.568  &lt; 2e-16 ***\nDESTIN_SZQTSZ05      -1.2215818  0.0072829  -167.734  &lt; 2e-16 ***\nDESTIN_SZQTSZ06      -1.3213145  0.0074858  -176.509  &lt; 2e-16 ***\nDESTIN_SZQTSZ07      -1.6426306  0.0123347  -133.171  &lt; 2e-16 ***\nDESTIN_SZQTSZ08      -0.2224169  0.0058405   -38.082  &lt; 2e-16 ***\nDESTIN_SZQTSZ09      -0.8142678  0.0069796  -116.665  &lt; 2e-16 ***\nDESTIN_SZQTSZ10      -0.1090496  0.0062573   -17.428  &lt; 2e-16 ***\nDESTIN_SZQTSZ11      -0.0108951  0.0061145    -1.782  0.07477 .  \nDESTIN_SZQTSZ12      -0.8582515  0.0090243   -95.105  &lt; 2e-16 ***\nDESTIN_SZQTSZ13       0.1834409  0.0065231    28.122  &lt; 2e-16 ***\nDESTIN_SZQTSZ14       0.1994454  0.0073615    27.093  &lt; 2e-16 ***\nDESTIN_SZQTSZ15       0.6740197  0.0088699    75.990  &lt; 2e-16 ***\nDESTIN_SZRCSZ01      -0.7746427  0.0079375   -97.593  &lt; 2e-16 ***\nDESTIN_SZRCSZ06      -1.4394098  0.0209931   -68.566  &lt; 2e-16 ***\nDESTIN_SZRVSZ01      -2.6060495  0.0175759  -148.274  &lt; 2e-16 ***\nDESTIN_SZRVSZ02      -2.5823769  0.0354706   -72.803  &lt; 2e-16 ***\nDESTIN_SZRVSZ03      -2.5890601  0.0152644  -169.614  &lt; 2e-16 ***\nDESTIN_SZRVSZ04      -2.2277482  0.0165661  -134.477  &lt; 2e-16 ***\nDESTIN_SZRVSZ05      -3.8610445  0.0298251  -129.456  &lt; 2e-16 ***\nDESTIN_SZSBSZ01      -1.2035529  0.0103954  -115.777  &lt; 2e-16 ***\nDESTIN_SZSBSZ02      -1.0267199  0.0085239  -120.452  &lt; 2e-16 ***\nDESTIN_SZSBSZ03       0.5977382  0.0050336   118.750  &lt; 2e-16 ***\nDESTIN_SZSBSZ04       0.5362769  0.0060573    88.534  &lt; 2e-16 ***\nDESTIN_SZSBSZ05      -1.0440525  0.0089622  -116.495  &lt; 2e-16 ***\nDESTIN_SZSBSZ06      -1.3939595  0.0246679   -56.509  &lt; 2e-16 ***\nDESTIN_SZSBSZ07       0.1029116  0.0235414     4.372 1.23e-05 ***\nDESTIN_SZSBSZ08       1.3564902  0.0060529   224.105  &lt; 2e-16 ***\nDESTIN_SZSBSZ09       0.4573712  0.0056585    80.829  &lt; 2e-16 ***\nDESTIN_SZSESZ02      -0.1553609  0.0056716   -27.393  &lt; 2e-16 ***\nDESTIN_SZSESZ03       0.5412776  0.0043801   123.576  &lt; 2e-16 ***\nDESTIN_SZSESZ04      -0.6382091  0.0065411   -97.568  &lt; 2e-16 ***\nDESTIN_SZSESZ05      -0.3332093  0.0055002   -60.581  &lt; 2e-16 ***\nDESTIN_SZSESZ06      -0.3085951  0.0072340   -42.659  &lt; 2e-16 ***\nDESTIN_SZSESZ07      -2.6237684  0.0245753  -106.764  &lt; 2e-16 ***\nDESTIN_SZSGSZ01      -0.1062372  0.0066634   -15.943  &lt; 2e-16 ***\nDESTIN_SZSGSZ02      -0.0475568  0.0058908    -8.073 6.85e-16 ***\nDESTIN_SZSGSZ03      -0.2118402  0.0055056   -38.477  &lt; 2e-16 ***\nDESTIN_SZSGSZ04      -0.1099618  0.0054841   -20.051  &lt; 2e-16 ***\nDESTIN_SZSGSZ05      -2.1556963  0.0113821  -189.394  &lt; 2e-16 ***\nDESTIN_SZSGSZ06       0.4416352  0.0043842   100.734  &lt; 2e-16 ***\nDESTIN_SZSGSZ07      -0.3949335  0.0059250   -66.655  &lt; 2e-16 ***\nDESTIN_SZSISZ01      -1.2847094  0.0288610   -44.514  &lt; 2e-16 ***\nDESTIN_SZSKSZ01       0.3089834  0.0082924    37.261  &lt; 2e-16 ***\nDESTIN_SZSKSZ02       1.4139309  0.0059981   235.729  &lt; 2e-16 ***\nDESTIN_SZSKSZ03       0.2427688  0.0067373    36.034  &lt; 2e-16 ***\nDESTIN_SZSKSZ04      -0.2527488  0.0161286   -15.671  &lt; 2e-16 ***\nDESTIN_SZSKSZ05       0.6046051  0.0122766    49.249  &lt; 2e-16 ***\nDESTIN_SZSLSZ01      -0.3927387  0.0099790   -39.356  &lt; 2e-16 ***\nDESTIN_SZSLSZ04      -0.5942110  0.0086225   -68.914  &lt; 2e-16 ***\nDESTIN_SZSRSZ01      -2.6855766  0.0138707  -193.615  &lt; 2e-16 ***\nDESTIN_SZTHSZ01      -3.2750084  0.0402668   -81.333  &lt; 2e-16 ***\nDESTIN_SZTHSZ03      -1.7964408  0.0261810   -68.616  &lt; 2e-16 ***\nDESTIN_SZTHSZ04      -2.6323994  0.0241831  -108.853  &lt; 2e-16 ***\nDESTIN_SZTHSZ06      -1.9444390  0.0166052  -117.098  &lt; 2e-16 ***\nDESTIN_SZTMSZ01       0.3856054  0.0063086    61.123  &lt; 2e-16 ***\nDESTIN_SZTMSZ02       1.8586526  0.0039229   473.790  &lt; 2e-16 ***\nDESTIN_SZTMSZ03       1.2601385  0.0044018   286.278  &lt; 2e-16 ***\nDESTIN_SZTMSZ04       1.5884327  0.0043362   366.316  &lt; 2e-16 ***\nDESTIN_SZTMSZ05       1.0377553  0.0063271   164.018  &lt; 2e-16 ***\nDESTIN_SZTNSZ01      -0.9954275  0.0080345  -123.895  &lt; 2e-16 ***\nDESTIN_SZTNSZ02      -2.1032696  0.0109228  -192.557  &lt; 2e-16 ***\nDESTIN_SZTNSZ03      -2.0044892  0.0129215  -155.128  &lt; 2e-16 ***\nDESTIN_SZTNSZ04      -0.9750326  0.0081677  -119.377  &lt; 2e-16 ***\nDESTIN_SZTPSZ01      -0.7788383  0.0068769  -113.254  &lt; 2e-16 ***\nDESTIN_SZTPSZ02       0.2866080  0.0042843    66.898  &lt; 2e-16 ***\nDESTIN_SZTPSZ03      -0.8749841  0.0065470  -133.646  &lt; 2e-16 ***\nDESTIN_SZTPSZ04      -1.6852792  0.0081488  -206.812  &lt; 2e-16 ***\nDESTIN_SZTPSZ05      -1.3721346  0.0068230  -201.104  &lt; 2e-16 ***\nDESTIN_SZTPSZ06      -0.7832133  0.0069164  -113.239  &lt; 2e-16 ***\nDESTIN_SZTPSZ07      -2.3109126  0.0130830  -176.635  &lt; 2e-16 ***\nDESTIN_SZTPSZ08      -1.6406531  0.0104897  -156.406  &lt; 2e-16 ***\nDESTIN_SZTPSZ09      -0.5636273  0.0076848   -73.343  &lt; 2e-16 ***\nDESTIN_SZTPSZ10      -1.5640843  0.0099984  -156.433  &lt; 2e-16 ***\nDESTIN_SZTPSZ11      -0.3700482  0.0059834   -61.846  &lt; 2e-16 ***\nDESTIN_SZTPSZ12      -0.8828228  0.0072302  -122.102  &lt; 2e-16 ***\nDESTIN_SZTSSZ01       0.3529526  0.0221887    15.907  &lt; 2e-16 ***\nDESTIN_SZTSSZ02       1.0265792  0.0153515    66.871  &lt; 2e-16 ***\nDESTIN_SZTSSZ03       1.9647347  0.0092388   212.662  &lt; 2e-16 ***\nDESTIN_SZTSSZ04       1.8649836  0.0089976   207.275  &lt; 2e-16 ***\nDESTIN_SZTSSZ05       2.8437058  0.0085738   331.673  &lt; 2e-16 ***\nDESTIN_SZTSSZ06       3.4238870  0.0161304   212.263  &lt; 2e-16 ***\nDESTIN_SZWCSZ01       2.9550693  0.0051690   571.689  &lt; 2e-16 ***\nDESTIN_SZWCSZ02      -0.8214103  0.0129213   -63.570  &lt; 2e-16 ***\nDESTIN_SZWCSZ03      -1.7393427  0.0347472   -50.057  &lt; 2e-16 ***\nDESTIN_SZWDSZ01       1.3424417  0.0039957   335.972  &lt; 2e-16 ***\nDESTIN_SZWDSZ02      -0.2103694  0.0068601   -30.666  &lt; 2e-16 ***\nDESTIN_SZWDSZ03       0.8268551  0.0051363   160.983  &lt; 2e-16 ***\nDESTIN_SZWDSZ04      -0.0643997  0.0079076    -8.144 3.82e-16 ***\nDESTIN_SZWDSZ05       0.0451985  0.0075732     5.968 2.40e-09 ***\nDESTIN_SZWDSZ06       0.6981330  0.0051936   134.423  &lt; 2e-16 ***\nDESTIN_SZWDSZ07      -0.0403233  0.0067749    -5.952 2.65e-09 ***\nDESTIN_SZWDSZ08       0.2850631  0.0069225    41.179  &lt; 2e-16 ***\nDESTIN_SZWDSZ09       1.3016106  0.0050365   258.433  &lt; 2e-16 ***\nDESTIN_SZYSSZ01       0.7598564  0.0044144   172.133  &lt; 2e-16 ***\nDESTIN_SZYSSZ02       0.2648061  0.0058239    45.469  &lt; 2e-16 ***\nDESTIN_SZYSSZ03      -0.0412163  0.0068337    -6.031 1.63e-09 ***\nDESTIN_SZYSSZ04      -0.0561054  0.0060829    -9.223  &lt; 2e-16 ***\nDESTIN_SZYSSZ05      -0.9970159  0.0121827   -81.839  &lt; 2e-16 ***\nDESTIN_SZYSSZ06      -1.3808376  0.0125738  -109.819  &lt; 2e-16 ***\nDESTIN_SZYSSZ07      -0.7128364  0.0165296   -43.125  &lt; 2e-16 ***\nDESTIN_SZYSSZ08       0.9409510  0.0045886   205.064  &lt; 2e-16 ***\nDESTIN_SZYSSZ09       0.3738436  0.0047971    77.930  &lt; 2e-16 ***\nlog(ORIGIN_AGE25_64)  0.1928847  0.0001667  1157.214  &lt; 2e-16 ***\nlog(dist)            -1.7828141  0.0004794 -3718.501  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance: 12319763  on 13992  degrees of freedom\nAIC: 12404881\n\nNumber of Fisher Scoring iterations: 7\n\n\nSimilarly, we can calculate the R-squared.\n\nCalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)\n\n[1] 0.496166\n\n\n\n\nDoubly constrained\nNow, we will fit a doubly constrained SIM.\n\ndbcSIM &lt;- glm(formula = TRIPS ~\n                ORIGIN_SZ +\n                DESTIN_SZ +\n                log(dist),\n              family = poisson(link = 'log'),\n              data = SIM_data,\n              na.action = na.exclude)\n\nsummary(dbcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + DESTIN_SZ + log(dist), family = poisson(link = \"log\"), \n    data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                  Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)     21.9587595  0.0066831  3285.715  &lt; 2e-16 ***\nORIGIN_SZAMSZ02  0.4778050  0.0054127    88.275  &lt; 2e-16 ***\nORIGIN_SZAMSZ03  0.2895973  0.0055517    52.163  &lt; 2e-16 ***\nORIGIN_SZAMSZ04 -0.2628080  0.0060720   -43.282  &lt; 2e-16 ***\nORIGIN_SZAMSZ05 -0.2631404  0.0069008   -38.132  &lt; 2e-16 ***\nORIGIN_SZAMSZ06  0.1722337  0.0062028    27.767  &lt; 2e-16 ***\nORIGIN_SZAMSZ07 -0.9883200  0.0111224   -88.859  &lt; 2e-16 ***\nORIGIN_SZAMSZ08 -0.4052821  0.0104095   -38.934  &lt; 2e-16 ***\nORIGIN_SZAMSZ09  0.0356290  0.0064816     5.497 3.86e-08 ***\nORIGIN_SZAMSZ10  0.4815569  0.0055521    86.735  &lt; 2e-16 ***\nORIGIN_SZAMSZ11 -1.4440079  0.0146079   -98.851  &lt; 2e-16 ***\nORIGIN_SZAMSZ12 -1.7862677  0.0128071  -139.475  &lt; 2e-16 ***\nORIGIN_SZBDSZ01  0.8653749  0.0054381   159.132  &lt; 2e-16 ***\nORIGIN_SZBDSZ02  0.0841000  0.0062834    13.385  &lt; 2e-16 ***\nORIGIN_SZBDSZ03  0.3158343  0.0057510    54.918  &lt; 2e-16 ***\nORIGIN_SZBDSZ04  1.4556701  0.0049986   291.215  &lt; 2e-16 ***\nORIGIN_SZBDSZ05  0.6363125  0.0057193   111.257  &lt; 2e-16 ***\nORIGIN_SZBDSZ06  0.6749341  0.0058650   115.078  &lt; 2e-16 ***\nORIGIN_SZBDSZ07 -1.2176407  0.0113698  -107.095  &lt; 2e-16 ***\nORIGIN_SZBDSZ08 -0.9803580  0.0105604   -92.833  &lt; 2e-16 ***\nORIGIN_SZBKSZ01 -0.2919642  0.0080763   -36.151  &lt; 2e-16 ***\nORIGIN_SZBKSZ02  0.4609570  0.0067997    67.791  &lt; 2e-16 ***\nORIGIN_SZBKSZ03  0.6273448  0.0065989    95.068  &lt; 2e-16 ***\nORIGIN_SZBKSZ04 -0.2499063  0.0076555   -32.644  &lt; 2e-16 ***\nORIGIN_SZBKSZ05 -0.2628428  0.0078905   -33.311  &lt; 2e-16 ***\nORIGIN_SZBKSZ06 -0.2174034  0.0075134   -28.936  &lt; 2e-16 ***\nORIGIN_SZBKSZ07  0.7094093  0.0058574   121.114  &lt; 2e-16 ***\nORIGIN_SZBKSZ08 -0.1614362  0.0067626   -23.872  &lt; 2e-16 ***\nORIGIN_SZBKSZ09 -0.2739085  0.0072969   -37.537  &lt; 2e-16 ***\nORIGIN_SZBLSZ01 -2.4281074  0.0181172  -134.022  &lt; 2e-16 ***\nORIGIN_SZBLSZ02 -2.7305447  0.0219341  -124.489  &lt; 2e-16 ***\nORIGIN_SZBLSZ03 -3.3071431  0.0540398   -61.198  &lt; 2e-16 ***\nORIGIN_SZBLSZ04 -2.4550671  0.0263946   -93.014  &lt; 2e-16 ***\nORIGIN_SZBMSZ01  0.1198976  0.0065964    18.176  &lt; 2e-16 ***\nORIGIN_SZBMSZ02 -1.3908667  0.0083230  -167.112  &lt; 2e-16 ***\nORIGIN_SZBMSZ03 -0.6999122  0.0069754  -100.339  &lt; 2e-16 ***\nORIGIN_SZBMSZ04 -0.2691159  0.0066184   -40.662  &lt; 2e-16 ***\nORIGIN_SZBMSZ05 -2.6163780  0.0190989  -136.991  &lt; 2e-16 ***\nORIGIN_SZBMSZ06 -2.9729956  0.0197182  -150.774  &lt; 2e-16 ***\nORIGIN_SZBMSZ07 -0.7309916  0.0072407  -100.956  &lt; 2e-16 ***\nORIGIN_SZBMSZ08 -1.0019514  0.0073169  -136.936  &lt; 2e-16 ***\nORIGIN_SZBMSZ09 -1.3667460  0.0105325  -129.764  &lt; 2e-16 ***\nORIGIN_SZBMSZ10 -1.6907268  0.0106687  -158.476  &lt; 2e-16 ***\nORIGIN_SZBMSZ11 -1.2288802  0.0082919  -148.202  &lt; 2e-16 ***\nORIGIN_SZBMSZ12 -1.6517767  0.0115101  -143.507  &lt; 2e-16 ***\nORIGIN_SZBMSZ13 -0.7251351  0.0075289   -96.314  &lt; 2e-16 ***\nORIGIN_SZBMSZ14 -1.1534912  0.0082629  -139.599  &lt; 2e-16 ***\nORIGIN_SZBMSZ15 -0.5476774  0.0075710   -72.339  &lt; 2e-16 ***\nORIGIN_SZBMSZ16 -1.5195034  0.0111459  -136.329  &lt; 2e-16 ***\nORIGIN_SZBMSZ17 -1.6026767  0.0184419   -86.904  &lt; 2e-16 ***\nORIGIN_SZBPSZ01  0.5571291  0.0071866    77.523  &lt; 2e-16 ***\nORIGIN_SZBPSZ02  0.0523197  0.0082259     6.360 2.01e-10 ***\nORIGIN_SZBPSZ03  0.2942047  0.0080482    36.555  &lt; 2e-16 ***\nORIGIN_SZBPSZ04  0.6246296  0.0065878    94.816  &lt; 2e-16 ***\nORIGIN_SZBPSZ05  0.8663708  0.0060852   142.372  &lt; 2e-16 ***\nORIGIN_SZBPSZ06 -0.9896182  0.0109551   -90.334  &lt; 2e-16 ***\nORIGIN_SZBPSZ07 -0.5219250  0.0101830   -51.255  &lt; 2e-16 ***\nORIGIN_SZBSSZ01  0.3299588  0.0066440    49.663  &lt; 2e-16 ***\nORIGIN_SZBSSZ02  0.2851357  0.0057077    49.956  &lt; 2e-16 ***\nORIGIN_SZBSSZ03 -0.2084740  0.0063364   -32.901  &lt; 2e-16 ***\nORIGIN_SZBTSZ01  0.1425664  0.0071103    20.051  &lt; 2e-16 ***\nORIGIN_SZBTSZ02 -0.5591999  0.0093616   -59.733  &lt; 2e-16 ***\nORIGIN_SZBTSZ03 -0.3648190  0.0081677   -44.666  &lt; 2e-16 ***\nORIGIN_SZBTSZ04 -1.4555078  0.0120138  -121.152  &lt; 2e-16 ***\nORIGIN_SZBTSZ05 -0.8635510  0.0133848   -64.517  &lt; 2e-16 ***\nORIGIN_SZBTSZ06 -1.1383111  0.0106421  -106.963  &lt; 2e-16 ***\nORIGIN_SZBTSZ07 -2.3477669  0.0160858  -145.953  &lt; 2e-16 ***\nORIGIN_SZBTSZ08 -1.2918779  0.0124862  -103.464  &lt; 2e-16 ***\nORIGIN_SZCBSZ01 -3.3713588  0.0578683   -58.259  &lt; 2e-16 ***\nORIGIN_SZCCSZ01 -0.6029242  0.0153385   -39.308  &lt; 2e-16 ***\nORIGIN_SZCHSZ01 -0.7641380  0.0135100   -56.561  &lt; 2e-16 ***\nORIGIN_SZCHSZ02 -0.8400736  0.0101951   -82.400  &lt; 2e-16 ***\nORIGIN_SZCHSZ03  1.2753127  0.0072576   175.720  &lt; 2e-16 ***\nORIGIN_SZCKSZ01  0.2470943  0.0067135    36.806  &lt; 2e-16 ***\nORIGIN_SZCKSZ02  0.5793581  0.0070498    82.181  &lt; 2e-16 ***\nORIGIN_SZCKSZ03  1.0795767  0.0060642   178.025  &lt; 2e-16 ***\nORIGIN_SZCKSZ04  1.4947920  0.0063122   236.808  &lt; 2e-16 ***\nORIGIN_SZCKSZ05  0.7457580  0.0074071   100.681  &lt; 2e-16 ***\nORIGIN_SZCKSZ06  0.5760952  0.0094861    60.730  &lt; 2e-16 ***\nORIGIN_SZCLSZ01 -0.9061335  0.0098617   -91.884  &lt; 2e-16 ***\nORIGIN_SZCLSZ02 -1.7609479  0.0156124  -112.791  &lt; 2e-16 ***\nORIGIN_SZCLSZ03 -1.0081325  0.0095171  -105.929  &lt; 2e-16 ***\nORIGIN_SZCLSZ04  0.6181200  0.0057953   106.659  &lt; 2e-16 ***\nORIGIN_SZCLSZ05 -2.0462335  0.0168934  -121.127  &lt; 2e-16 ***\nORIGIN_SZCLSZ06  0.7902389  0.0055680   141.924  &lt; 2e-16 ***\nORIGIN_SZCLSZ07 -0.5472929  0.0071001   -77.082  &lt; 2e-16 ***\nORIGIN_SZCLSZ08 -0.2197650  0.0077460   -28.372  &lt; 2e-16 ***\nORIGIN_SZCLSZ09 -1.8175782  0.0195989   -92.739  &lt; 2e-16 ***\nORIGIN_SZDTSZ02 -3.7618796  0.0872098   -43.136  &lt; 2e-16 ***\nORIGIN_SZDTSZ03 -3.4514766  0.0840812   -41.049  &lt; 2e-16 ***\nORIGIN_SZDTSZ13 -3.0627578  0.0352485   -86.891  &lt; 2e-16 ***\nORIGIN_SZGLSZ01 -1.8055929  0.0111938  -161.303  &lt; 2e-16 ***\nORIGIN_SZGLSZ02 -0.1588829  0.0061413   -25.871  &lt; 2e-16 ***\nORIGIN_SZGLSZ03 -0.2508524  0.0064276   -39.027  &lt; 2e-16 ***\nORIGIN_SZGLSZ04  0.8819358  0.0051993   169.627  &lt; 2e-16 ***\nORIGIN_SZGLSZ05  0.6062778  0.0053735   112.828  &lt; 2e-16 ***\nORIGIN_SZHGSZ01  0.3841503  0.0056776    67.660  &lt; 2e-16 ***\nORIGIN_SZHGSZ02  0.3962330  0.0057579    68.815  &lt; 2e-16 ***\nORIGIN_SZHGSZ03  0.2159531  0.0061671    35.017  &lt; 2e-16 ***\nORIGIN_SZHGSZ04  0.7831941  0.0052216   149.992  &lt; 2e-16 ***\nORIGIN_SZHGSZ05  1.1741558  0.0051799   226.677  &lt; 2e-16 ***\nORIGIN_SZHGSZ06 -0.1891403  0.0065556   -28.852  &lt; 2e-16 ***\nORIGIN_SZHGSZ07  0.3105421  0.0057186    54.304  &lt; 2e-16 ***\nORIGIN_SZHGSZ08 -0.0766364  0.0063474   -12.074  &lt; 2e-16 ***\nORIGIN_SZHGSZ09 -1.2211107  0.0101434  -120.384  &lt; 2e-16 ***\nORIGIN_SZHGSZ10 -3.4844709  0.0504793   -69.028  &lt; 2e-16 ***\nORIGIN_SZJESZ01  0.4916496  0.0063444    77.493  &lt; 2e-16 ***\nORIGIN_SZJESZ02  0.1343893  0.0063762    21.077  &lt; 2e-16 ***\nORIGIN_SZJESZ03 -0.2761723  0.0068085   -40.563  &lt; 2e-16 ***\nORIGIN_SZJESZ04 -1.5932744  0.0121402  -131.240  &lt; 2e-16 ***\nORIGIN_SZJESZ05 -2.3041311  0.0160245  -143.788  &lt; 2e-16 ***\nORIGIN_SZJESZ06  0.2811076  0.0062495    44.981  &lt; 2e-16 ***\nORIGIN_SZJESZ07 -1.9413956  0.0136276  -142.461  &lt; 2e-16 ***\nORIGIN_SZJESZ08 -1.3315645  0.0143168   -93.007  &lt; 2e-16 ***\nORIGIN_SZJESZ09  0.4418314  0.0069208    63.841  &lt; 2e-16 ***\nORIGIN_SZJESZ10 -1.5551555  0.0236523   -65.751  &lt; 2e-16 ***\nORIGIN_SZJESZ11 -1.8888230  0.0224630   -84.086  &lt; 2e-16 ***\nORIGIN_SZJWSZ01  0.2564586  0.0084699    30.279  &lt; 2e-16 ***\nORIGIN_SZJWSZ02  0.6899398  0.0061751   111.729  &lt; 2e-16 ***\nORIGIN_SZJWSZ03  1.4761229  0.0057392   257.198  &lt; 2e-16 ***\nORIGIN_SZJWSZ04  0.5701272  0.0065749    86.713  &lt; 2e-16 ***\nORIGIN_SZJWSZ05 -2.1253657  0.0150769  -140.968  &lt; 2e-16 ***\nORIGIN_SZJWSZ06 -1.5307265  0.0131906  -116.047  &lt; 2e-16 ***\nORIGIN_SZJWSZ07 -2.8801618  0.0360772   -79.833  &lt; 2e-16 ***\nORIGIN_SZJWSZ08  1.4428820  0.0059638   241.938  &lt; 2e-16 ***\nORIGIN_SZJWSZ09  1.8968475  0.0055649   340.860  &lt; 2e-16 ***\nORIGIN_SZKLSZ01  0.1116580  0.0059844    18.658  &lt; 2e-16 ***\nORIGIN_SZKLSZ02 -0.9618787  0.0077344  -124.364  &lt; 2e-16 ***\nORIGIN_SZKLSZ03 -0.7070626  0.0070275  -100.613  &lt; 2e-16 ***\nORIGIN_SZKLSZ04 -2.2742765  0.0139991  -162.459  &lt; 2e-16 ***\nORIGIN_SZKLSZ05 -1.1907262  0.0123719   -96.244  &lt; 2e-16 ***\nORIGIN_SZKLSZ06 -5.9774897  0.1857994   -32.172  &lt; 2e-16 ***\nORIGIN_SZKLSZ07 -1.4258369  0.0103083  -138.320  &lt; 2e-16 ***\nORIGIN_SZKLSZ08 -1.7625888  0.0116107  -151.808  &lt; 2e-16 ***\nORIGIN_SZLKSZ01 -2.0541388  0.0448216   -45.829  &lt; 2e-16 ***\nORIGIN_SZMDSZ01 -0.8571117  0.0321054   -26.697  &lt; 2e-16 ***\nORIGIN_SZMDSZ02 -0.6034597  0.0120724   -49.987  &lt; 2e-16 ***\nORIGIN_SZMDSZ03 -2.1681163  0.0201078  -107.825  &lt; 2e-16 ***\nORIGIN_SZMPSZ01 -0.9331562  0.0096218   -96.984  &lt; 2e-16 ***\nORIGIN_SZMPSZ02 -1.0268229  0.0081379  -126.178  &lt; 2e-16 ***\nORIGIN_SZMPSZ03  0.0054001  0.0066875     0.807 0.419385    \nORIGIN_SZMUSZ02 -3.6269863  0.1105492   -32.809  &lt; 2e-16 ***\nORIGIN_SZNTSZ01 -3.0593717  0.0399843   -76.514  &lt; 2e-16 ***\nORIGIN_SZNTSZ02 -3.3331415  0.0251754  -132.397  &lt; 2e-16 ***\nORIGIN_SZNTSZ03 -0.8351522  0.0090372   -92.413  &lt; 2e-16 ***\nORIGIN_SZNTSZ05 -4.2082472  0.0583343   -72.140  &lt; 2e-16 ***\nORIGIN_SZNTSZ06 -3.8549296  0.0593793   -64.920  &lt; 2e-16 ***\nORIGIN_SZNVSZ01  0.2789069  0.0056024    49.784  &lt; 2e-16 ***\nORIGIN_SZNVSZ02 -0.6036857  0.0077126   -78.273  &lt; 2e-16 ***\nORIGIN_SZNVSZ03 -1.0072683  0.0092678  -108.685  &lt; 2e-16 ***\nORIGIN_SZNVSZ04 -0.8723996  0.0101399   -86.037  &lt; 2e-16 ***\nORIGIN_SZNVSZ05 -2.1552928  0.0183064  -117.734  &lt; 2e-16 ***\nORIGIN_SZPGSZ01  0.0520607  0.0157846     3.298 0.000973 ***\nORIGIN_SZPGSZ02 -0.3481687  0.0089328   -38.976  &lt; 2e-16 ***\nORIGIN_SZPGSZ03  0.9095292  0.0058835   154.590  &lt; 2e-16 ***\nORIGIN_SZPGSZ04  1.3653717  0.0054727   249.489  &lt; 2e-16 ***\nORIGIN_SZPGSZ05  0.3762720  0.0073841    50.957  &lt; 2e-16 ***\nORIGIN_SZPLSZ01 -0.9142754  0.0136552   -66.954  &lt; 2e-16 ***\nORIGIN_SZPLSZ02 -1.0987582  0.0175891   -62.468  &lt; 2e-16 ***\nORIGIN_SZPLSZ03 -2.3427113  0.0474176   -49.406  &lt; 2e-16 ***\nORIGIN_SZPLSZ04 -2.9140779  0.0374458   -77.821  &lt; 2e-16 ***\nORIGIN_SZPLSZ05 -2.2381965  0.0261572   -85.567  &lt; 2e-16 ***\nORIGIN_SZPNSZ01  0.9659006  0.0075177   128.484  &lt; 2e-16 ***\nORIGIN_SZPNSZ02 -0.0158348  0.0143869    -1.101 0.271053    \nORIGIN_SZPNSZ03 -2.1837321  0.0224396   -97.316  &lt; 2e-16 ***\nORIGIN_SZPNSZ04 -3.2481509  0.0370762   -87.608  &lt; 2e-16 ***\nORIGIN_SZPNSZ05 -2.0450679  0.0328165   -62.318  &lt; 2e-16 ***\nORIGIN_SZPRSZ01 -0.6701245  0.0141567   -47.336  &lt; 2e-16 ***\nORIGIN_SZPRSZ02  0.7931907  0.0058079   136.570  &lt; 2e-16 ***\nORIGIN_SZPRSZ03  0.4249094  0.0058610    72.498  &lt; 2e-16 ***\nORIGIN_SZPRSZ04 -0.8529967  0.0090997   -93.739  &lt; 2e-16 ***\nORIGIN_SZPRSZ05  0.7865479  0.0055282   142.278  &lt; 2e-16 ***\nORIGIN_SZPRSZ06 -1.3303664  0.0134512   -98.903  &lt; 2e-16 ***\nORIGIN_SZPRSZ07 -3.0458370  0.0181514  -167.802  &lt; 2e-16 ***\nORIGIN_SZPRSZ08 -0.5342399  0.0075966   -70.327  &lt; 2e-16 ***\nORIGIN_SZQTSZ01 -0.2548930  0.0086485   -29.473  &lt; 2e-16 ***\nORIGIN_SZQTSZ02 -0.8662439  0.0076549  -113.162  &lt; 2e-16 ***\nORIGIN_SZQTSZ03 -0.0890168  0.0072455   -12.286  &lt; 2e-16 ***\nORIGIN_SZQTSZ04 -1.4634370  0.0089384  -163.724  &lt; 2e-16 ***\nORIGIN_SZQTSZ05 -0.6535669  0.0077612   -84.210  &lt; 2e-16 ***\nORIGIN_SZQTSZ06 -0.8275765  0.0081835  -101.128  &lt; 2e-16 ***\nORIGIN_SZQTSZ07 -1.5369800  0.0112808  -136.248  &lt; 2e-16 ***\nORIGIN_SZQTSZ08 -0.4437979  0.0075302   -58.936  &lt; 2e-16 ***\nORIGIN_SZQTSZ09 -0.8184934  0.0083589   -97.918  &lt; 2e-16 ***\nORIGIN_SZQTSZ10 -0.6906597  0.0080980   -85.288  &lt; 2e-16 ***\nORIGIN_SZQTSZ11 -2.3251162  0.0154191  -150.795  &lt; 2e-16 ***\nORIGIN_SZQTSZ12 -3.0442790  0.0208985  -145.670  &lt; 2e-16 ***\nORIGIN_SZQTSZ13 -0.7241013  0.0093441   -77.493  &lt; 2e-16 ***\nORIGIN_SZQTSZ14 -1.8225351  0.0138207  -131.870  &lt; 2e-16 ***\nORIGIN_SZQTSZ15 -0.8720806  0.0138589   -62.926  &lt; 2e-16 ***\nORIGIN_SZRCSZ01 -1.8063415  0.0144295  -125.184  &lt; 2e-16 ***\nORIGIN_SZRCSZ06 -0.5370905  0.0101573   -52.877  &lt; 2e-16 ***\nORIGIN_SZRVSZ01 -2.7426167  0.0341386   -80.338  &lt; 2e-16 ***\nORIGIN_SZRVSZ02 -3.0827269  0.0302299  -101.976  &lt; 2e-16 ***\nORIGIN_SZRVSZ03 -2.9133853  0.0262543  -110.968  &lt; 2e-16 ***\nORIGIN_SZRVSZ04 -3.4220022  0.0582209   -58.776  &lt; 2e-16 ***\nORIGIN_SZRVSZ05 -2.6206257  0.0197470  -132.710  &lt; 2e-16 ***\nORIGIN_SZSBSZ01  0.1010337  0.0085117    11.870  &lt; 2e-16 ***\nORIGIN_SZSBSZ02 -0.8810456  0.0098244   -89.680  &lt; 2e-16 ***\nORIGIN_SZSBSZ03  0.8303668  0.0063009   131.785  &lt; 2e-16 ***\nORIGIN_SZSBSZ04  0.3489128  0.0071456    48.829  &lt; 2e-16 ***\nORIGIN_SZSBSZ05 -0.3182914  0.0085560   -37.201  &lt; 2e-16 ***\nORIGIN_SZSBSZ06 -0.9074308  0.0200035   -45.364  &lt; 2e-16 ***\nORIGIN_SZSBSZ07 -0.2217124  0.0167188   -13.261  &lt; 2e-16 ***\nORIGIN_SZSBSZ08 -1.3007367  0.0178771   -72.760  &lt; 2e-16 ***\nORIGIN_SZSBSZ09 -0.9813703  0.0107885   -90.965  &lt; 2e-16 ***\nORIGIN_SZSESZ02  1.1283424  0.0054209   208.146  &lt; 2e-16 ***\nORIGIN_SZSESZ03  1.2389996  0.0051926   238.610  &lt; 2e-16 ***\nORIGIN_SZSESZ04  0.7535119  0.0060371   124.814  &lt; 2e-16 ***\nORIGIN_SZSESZ05 -0.2347978  0.0071482   -32.847  &lt; 2e-16 ***\nORIGIN_SZSESZ06  0.9520620  0.0057572   165.368  &lt; 2e-16 ***\nORIGIN_SZSESZ07 -2.4296685  0.0231677  -104.873  &lt; 2e-16 ***\nORIGIN_SZSGSZ01 -0.6995899  0.0099969   -69.980  &lt; 2e-16 ***\nORIGIN_SZSGSZ02 -1.2602157  0.0111471  -113.053  &lt; 2e-16 ***\nORIGIN_SZSGSZ03  0.0725860  0.0061970    11.713  &lt; 2e-16 ***\nORIGIN_SZSGSZ04  0.2738315  0.0057524    47.603  &lt; 2e-16 ***\nORIGIN_SZSGSZ05 -2.0207710  0.0119838  -168.625  &lt; 2e-16 ***\nORIGIN_SZSGSZ06  0.4885608  0.0054646    89.404  &lt; 2e-16 ***\nORIGIN_SZSGSZ07 -0.8892155  0.0075074  -118.445  &lt; 2e-16 ***\nORIGIN_SZSKSZ01 -0.3682754  0.0108025   -34.092  &lt; 2e-16 ***\nORIGIN_SZSKSZ02  1.1826086  0.0071388   165.659  &lt; 2e-16 ***\nORIGIN_SZSKSZ03 -0.3230177  0.0101683   -31.767  &lt; 2e-16 ***\nORIGIN_SZSKSZ04 -1.8504236  0.0362400   -51.060  &lt; 2e-16 ***\nORIGIN_SZSKSZ05 -0.2759035  0.0185157   -14.901  &lt; 2e-16 ***\nORIGIN_SZSLSZ01 -2.2757902  0.0348766   -65.253  &lt; 2e-16 ***\nORIGIN_SZSLSZ04 -0.0899820  0.0090356    -9.959  &lt; 2e-16 ***\nORIGIN_SZSRSZ01 -2.1460151  0.0187871  -114.228  &lt; 2e-16 ***\nORIGIN_SZTHSZ01 -2.6851549  0.0571841   -46.956  &lt; 2e-16 ***\nORIGIN_SZTHSZ03 -1.0121495  0.0275551   -36.732  &lt; 2e-16 ***\nORIGIN_SZTHSZ04 -2.6129645  0.0345167   -75.701  &lt; 2e-16 ***\nORIGIN_SZTHSZ06 -1.7229100  0.0208134   -82.779  &lt; 2e-16 ***\nORIGIN_SZTMSZ01 -0.2254986  0.0070312   -32.071  &lt; 2e-16 ***\nORIGIN_SZTMSZ02  1.7271575  0.0049219   350.914  &lt; 2e-16 ***\nORIGIN_SZTMSZ03  0.9891319  0.0052266   189.250  &lt; 2e-16 ***\nORIGIN_SZTMSZ04  0.2018090  0.0062114    32.490  &lt; 2e-16 ***\nORIGIN_SZTMSZ05 -1.1882870  0.0125842   -94.427  &lt; 2e-16 ***\nORIGIN_SZTNSZ01 -1.6122620  0.0141911  -113.611  &lt; 2e-16 ***\nORIGIN_SZTNSZ02 -1.5630967  0.0112227  -139.280  &lt; 2e-16 ***\nORIGIN_SZTNSZ03 -2.0739538  0.0149298  -138.914  &lt; 2e-16 ***\nORIGIN_SZTNSZ04 -0.2816960  0.0085295   -33.026  &lt; 2e-16 ***\nORIGIN_SZTPSZ01 -0.7822239  0.0077901  -100.412  &lt; 2e-16 ***\nORIGIN_SZTPSZ02  0.5735478  0.0053042   108.131  &lt; 2e-16 ***\nORIGIN_SZTPSZ03 -0.8748650  0.0074202  -117.903  &lt; 2e-16 ***\nORIGIN_SZTPSZ04 -0.8537831  0.0069792  -122.332  &lt; 2e-16 ***\nORIGIN_SZTPSZ05 -0.5581114  0.0077012   -72.471  &lt; 2e-16 ***\nORIGIN_SZTPSZ06  0.0262001  0.0075241     3.482 0.000497 ***\nORIGIN_SZTPSZ07 -0.5969952  0.0074272   -80.380  &lt; 2e-16 ***\nORIGIN_SZTPSZ08 -1.0537959  0.0111297   -94.683  &lt; 2e-16 ***\nORIGIN_SZTPSZ09 -0.9588508  0.0081314  -117.920  &lt; 2e-16 ***\nORIGIN_SZTPSZ10 -1.1177249  0.0089403  -125.021  &lt; 2e-16 ***\nORIGIN_SZTPSZ11 -0.2799677  0.0067135   -41.702  &lt; 2e-16 ***\nORIGIN_SZTPSZ12 -0.8898871  0.0080215  -110.938  &lt; 2e-16 ***\nORIGIN_SZTSSZ01 -2.6146463  0.0521606   -50.127  &lt; 2e-16 ***\nORIGIN_SZTSSZ02  0.1682588  0.0119965    14.026  &lt; 2e-16 ***\nORIGIN_SZTSSZ03  0.2587653  0.0123809    20.900  &lt; 2e-16 ***\nORIGIN_SZTSSZ04 -0.5473825  0.0135215   -40.482  &lt; 2e-16 ***\nORIGIN_SZTSSZ05 -0.9967379  0.0206068   -48.369  &lt; 2e-16 ***\nORIGIN_SZTSSZ06  0.4933147  0.0229597    21.486  &lt; 2e-16 ***\nORIGIN_SZWCSZ01  1.2524706  0.0111133   112.700  &lt; 2e-16 ***\nORIGIN_SZWCSZ02 -2.8544820  0.0347805   -82.071  &lt; 2e-16 ***\nORIGIN_SZWCSZ03 -5.1277334  0.1475585   -34.751  &lt; 2e-16 ***\nORIGIN_SZWDSZ01  1.4725308  0.0056496   260.645  &lt; 2e-16 ***\nORIGIN_SZWDSZ02  0.1571680  0.0064909    24.214  &lt; 2e-16 ***\nORIGIN_SZWDSZ03  1.2584097  0.0061471   204.717  &lt; 2e-16 ***\nORIGIN_SZWDSZ04  0.8578765  0.0069277   123.833  &lt; 2e-16 ***\nORIGIN_SZWDSZ05  0.1702728  0.0069687    24.434  &lt; 2e-16 ***\nORIGIN_SZWDSZ06  0.1736910  0.0069507    24.989  &lt; 2e-16 ***\nORIGIN_SZWDSZ07 -1.5610176  0.0100803  -154.859  &lt; 2e-16 ***\nORIGIN_SZWDSZ08 -0.9490906  0.0102047   -93.005  &lt; 2e-16 ***\nORIGIN_SZWDSZ09  1.2107011  0.0062294   194.354  &lt; 2e-16 ***\nORIGIN_SZYSSZ01 -0.3324158  0.0074537   -44.598  &lt; 2e-16 ***\nORIGIN_SZYSSZ02  0.8177113  0.0066108   123.693  &lt; 2e-16 ***\nORIGIN_SZYSSZ03  1.6751777  0.0058470   286.503  &lt; 2e-16 ***\nORIGIN_SZYSSZ04  0.8130044  0.0059025   137.738  &lt; 2e-16 ***\nORIGIN_SZYSSZ05  0.3678420  0.0072431    50.785  &lt; 2e-16 ***\nORIGIN_SZYSSZ06 -0.6024384  0.0126722   -47.540  &lt; 2e-16 ***\nORIGIN_SZYSSZ07 -0.7631918  0.0158478   -48.157  &lt; 2e-16 ***\nORIGIN_SZYSSZ08  0.2141930  0.0076154    28.126  &lt; 2e-16 ***\nORIGIN_SZYSSZ09  1.0809368  0.0057973   186.457  &lt; 2e-16 ***\nDESTIN_SZAMSZ02  0.0761304  0.0051207    14.867  &lt; 2e-16 ***\nDESTIN_SZAMSZ03  0.0143394  0.0050755     2.825 0.004724 ** \nDESTIN_SZAMSZ04 -1.2516780  0.0074947  -167.008  &lt; 2e-16 ***\nDESTIN_SZAMSZ05 -1.2312375  0.0076598  -160.741  &lt; 2e-16 ***\nDESTIN_SZAMSZ06 -1.0333412  0.0075283  -137.261  &lt; 2e-16 ***\nDESTIN_SZAMSZ07 -1.5338249  0.0110036  -139.392  &lt; 2e-16 ***\nDESTIN_SZAMSZ08 -0.3751665  0.0075358   -49.784  &lt; 2e-16 ***\nDESTIN_SZAMSZ09 -1.1633493  0.0077556  -150.001  &lt; 2e-16 ***\nDESTIN_SZAMSZ10  0.1017717  0.0053151    19.148  &lt; 2e-16 ***\nDESTIN_SZAMSZ11 -0.8840362  0.0097007   -91.131  &lt; 2e-16 ***\nDESTIN_SZAMSZ12  0.1628123  0.0055220    29.484  &lt; 2e-16 ***\nDESTIN_SZBDSZ01  1.0040794  0.0047922   209.523  &lt; 2e-16 ***\nDESTIN_SZBDSZ02 -0.2478149  0.0063085   -39.283  &lt; 2e-16 ***\nDESTIN_SZBDSZ03  0.1016088  0.0057420    17.696  &lt; 2e-16 ***\nDESTIN_SZBDSZ04  1.1082928  0.0047747   232.116  &lt; 2e-16 ***\nDESTIN_SZBDSZ05  0.8737933  0.0050593   172.712  &lt; 2e-16 ***\nDESTIN_SZBDSZ06  0.2897032  0.0058244    49.740  &lt; 2e-16 ***\nDESTIN_SZBDSZ07 -0.9026193  0.0113656   -79.416  &lt; 2e-16 ***\nDESTIN_SZBDSZ08 -1.7063577  0.0131234  -130.024  &lt; 2e-16 ***\nDESTIN_SZBKSZ01 -1.3892839  0.0083307  -166.767  &lt; 2e-16 ***\nDESTIN_SZBKSZ02 -0.6661120  0.0073464   -90.672  &lt; 2e-16 ***\nDESTIN_SZBKSZ03 -0.9536826  0.0073196  -130.292  &lt; 2e-16 ***\nDESTIN_SZBKSZ04 -0.6655610  0.0065868  -101.044  &lt; 2e-16 ***\nDESTIN_SZBKSZ05 -0.9053119  0.0079264  -114.215  &lt; 2e-16 ***\nDESTIN_SZBKSZ06 -1.2622159  0.0075079  -168.119  &lt; 2e-16 ***\nDESTIN_SZBKSZ07 -0.0423370  0.0056686    -7.469 8.10e-14 ***\nDESTIN_SZBKSZ08 -1.3811240  0.0084985  -162.515  &lt; 2e-16 ***\nDESTIN_SZBKSZ09 -0.0797012  0.0061428   -12.975  &lt; 2e-16 ***\nDESTIN_SZBLSZ01 -0.8859670  0.0088108  -100.555  &lt; 2e-16 ***\nDESTIN_SZBLSZ02  0.1362723  0.0082167    16.585  &lt; 2e-16 ***\nDESTIN_SZBLSZ03  1.2037396  0.0093508   128.732  &lt; 2e-16 ***\nDESTIN_SZBLSZ04 -0.9316219  0.0178080   -52.315  &lt; 2e-16 ***\nDESTIN_SZBMSZ01  0.7188470  0.0061160   117.536  &lt; 2e-16 ***\nDESTIN_SZBMSZ02 -0.0597895  0.0061206    -9.769  &lt; 2e-16 ***\nDESTIN_SZBMSZ03 -0.2427075  0.0069937   -34.704  &lt; 2e-16 ***\nDESTIN_SZBMSZ04 -0.0622494  0.0065569    -9.494  &lt; 2e-16 ***\nDESTIN_SZBMSZ05 -0.2857019  0.0086450   -33.048  &lt; 2e-16 ***\nDESTIN_SZBMSZ06 -1.3486558  0.0158904   -84.872  &lt; 2e-16 ***\nDESTIN_SZBMSZ07  0.4549687  0.0058315    78.020  &lt; 2e-16 ***\nDESTIN_SZBMSZ08 -0.8730268  0.0077814  -112.195  &lt; 2e-16 ***\nDESTIN_SZBMSZ09 -2.0319890  0.0163038  -124.633  &lt; 2e-16 ***\nDESTIN_SZBMSZ10 -1.4319101  0.0102616  -139.541  &lt; 2e-16 ***\nDESTIN_SZBMSZ11 -1.2429176  0.0092250  -134.733  &lt; 2e-16 ***\nDESTIN_SZBMSZ12 -0.8526549  0.0096009   -88.810  &lt; 2e-16 ***\nDESTIN_SZBMSZ13  0.1399907  0.0066885    20.930  &lt; 2e-16 ***\nDESTIN_SZBMSZ14 -1.0103155  0.0091377  -110.566  &lt; 2e-16 ***\nDESTIN_SZBMSZ15 -0.6819769  0.0086179   -79.135  &lt; 2e-16 ***\nDESTIN_SZBMSZ16 -1.4468308  0.0134051  -107.931  &lt; 2e-16 ***\nDESTIN_SZBMSZ17 -1.5312175  0.0186843   -81.952  &lt; 2e-16 ***\nDESTIN_SZBPSZ01 -1.1726725  0.0073257  -160.077  &lt; 2e-16 ***\nDESTIN_SZBPSZ02 -2.1072012  0.0103320  -203.949  &lt; 2e-16 ***\nDESTIN_SZBPSZ03 -1.6944911  0.0098520  -171.995  &lt; 2e-16 ***\nDESTIN_SZBPSZ04 -0.7664610  0.0074458  -102.939  &lt; 2e-16 ***\nDESTIN_SZBPSZ05  0.1358370  0.0056258    24.145  &lt; 2e-16 ***\nDESTIN_SZBPSZ06 -1.2425471  0.0096942  -128.175  &lt; 2e-16 ***\nDESTIN_SZBPSZ07 -0.1666192  0.0094969   -17.545  &lt; 2e-16 ***\nDESTIN_SZBSSZ01  0.3857894  0.0057261    67.374  &lt; 2e-16 ***\nDESTIN_SZBSSZ02 -0.5293265  0.0064886   -81.578  &lt; 2e-16 ***\nDESTIN_SZBSSZ03  0.3909966  0.0048540    80.551  &lt; 2e-16 ***\nDESTIN_SZBTSZ01  0.7114965  0.0054528   130.482  &lt; 2e-16 ***\nDESTIN_SZBTSZ02 -0.0487084  0.0082474    -5.906 3.51e-09 ***\nDESTIN_SZBTSZ03  0.5539032  0.0064423    85.979  &lt; 2e-16 ***\nDESTIN_SZBTSZ04 -0.7120734  0.0128676   -55.339  &lt; 2e-16 ***\nDESTIN_SZBTSZ05  0.2176097  0.0086791    25.073  &lt; 2e-16 ***\nDESTIN_SZBTSZ06 -0.2167084  0.0084925   -25.518  &lt; 2e-16 ***\nDESTIN_SZBTSZ07 -1.4045618  0.0124363  -112.940  &lt; 2e-16 ***\nDESTIN_SZBTSZ08 -0.8213918  0.0120793   -68.000  &lt; 2e-16 ***\nDESTIN_SZCBSZ01 -5.7340877  0.3333916   -17.199  &lt; 2e-16 ***\nDESTIN_SZCCSZ01 -0.0304192  0.0095920    -3.171 0.001518 ** \nDESTIN_SZCHSZ01 -0.2598507  0.0115311   -22.535  &lt; 2e-16 ***\nDESTIN_SZCHSZ02  0.3497750  0.0068334    51.186  &lt; 2e-16 ***\nDESTIN_SZCHSZ03  2.4550172  0.0050883   482.481  &lt; 2e-16 ***\nDESTIN_SZCKSZ01 -0.4691744  0.0063130   -74.319  &lt; 2e-16 ***\nDESTIN_SZCKSZ02 -0.9557084  0.0069331  -137.847  &lt; 2e-16 ***\nDESTIN_SZCKSZ03  0.0442112  0.0057117     7.740 9.91e-15 ***\nDESTIN_SZCKSZ04 -0.8592063  0.0081238  -105.764  &lt; 2e-16 ***\nDESTIN_SZCKSZ05 -1.1745333  0.0087305  -134.532  &lt; 2e-16 ***\nDESTIN_SZCKSZ06 -0.4982877  0.0085514   -58.269  &lt; 2e-16 ***\nDESTIN_SZCLSZ01  0.2665065  0.0059712    44.632  &lt; 2e-16 ***\nDESTIN_SZCLSZ02 -1.9758876  0.0150823  -131.007  &lt; 2e-16 ***\nDESTIN_SZCLSZ03 -0.9051310  0.0091479   -98.944  &lt; 2e-16 ***\nDESTIN_SZCLSZ04 -0.0828732  0.0061559   -13.462  &lt; 2e-16 ***\nDESTIN_SZCLSZ05 -1.1414780  0.0100760  -113.287  &lt; 2e-16 ***\nDESTIN_SZCLSZ06  0.3229402  0.0056269    57.392  &lt; 2e-16 ***\nDESTIN_SZCLSZ07 -0.4833612  0.0069777   -69.272  &lt; 2e-16 ***\nDESTIN_SZCLSZ08 -0.3219670  0.0075615   -42.580  &lt; 2e-16 ***\nDESTIN_SZCLSZ09  0.0564166  0.0080703     6.991 2.74e-12 ***\nDESTIN_SZDTSZ02 -1.6384236  0.0374725   -43.723  &lt; 2e-16 ***\nDESTIN_SZDTSZ03 -0.4021571  0.0152716   -26.334  &lt; 2e-16 ***\nDESTIN_SZDTSZ13 -1.2799441  0.0177095   -72.274  &lt; 2e-16 ***\nDESTIN_SZGLSZ01 -0.0190303  0.0060665    -3.137 0.001707 ** \nDESTIN_SZGLSZ02 -0.0308469  0.0058724    -5.253 1.50e-07 ***\nDESTIN_SZGLSZ03  0.6927638  0.0048456   142.969  &lt; 2e-16 ***\nDESTIN_SZGLSZ04  0.9325848  0.0049183   189.616  &lt; 2e-16 ***\nDESTIN_SZGLSZ05  0.8480056  0.0048801   173.768  &lt; 2e-16 ***\nDESTIN_SZHGSZ01  0.0652969  0.0047795    13.662  &lt; 2e-16 ***\nDESTIN_SZHGSZ02 -0.9498251  0.0066577  -142.667  &lt; 2e-16 ***\nDESTIN_SZHGSZ03 -1.4372499  0.0076387  -188.154  &lt; 2e-16 ***\nDESTIN_SZHGSZ04 -0.5236292  0.0055353   -94.599  &lt; 2e-16 ***\nDESTIN_SZHGSZ05 -0.5420295  0.0058099   -93.295  &lt; 2e-16 ***\nDESTIN_SZHGSZ06 -0.9054730  0.0067581  -133.983  &lt; 2e-16 ***\nDESTIN_SZHGSZ07  0.0215109  0.0054019     3.982 6.83e-05 ***\nDESTIN_SZHGSZ08 -0.0490979  0.0059206    -8.293  &lt; 2e-16 ***\nDESTIN_SZHGSZ09 -0.0711560  0.0062875   -11.317  &lt; 2e-16 ***\nDESTIN_SZHGSZ10 -3.5807154  0.0290642  -123.200  &lt; 2e-16 ***\nDESTIN_SZJESZ01 -0.4023638  0.0065057   -61.848  &lt; 2e-16 ***\nDESTIN_SZJESZ02 -0.7654353  0.0067096  -114.081  &lt; 2e-16 ***\nDESTIN_SZJESZ03 -0.8778812  0.0071238  -123.232  &lt; 2e-16 ***\nDESTIN_SZJESZ04 -1.1998075  0.0088733  -135.215  &lt; 2e-16 ***\nDESTIN_SZJESZ05 -1.5623652  0.0116898  -133.652  &lt; 2e-16 ***\nDESTIN_SZJESZ06  0.2311474  0.0055595    41.577  &lt; 2e-16 ***\nDESTIN_SZJESZ07 -1.2753348  0.0094838  -134.475  &lt; 2e-16 ***\nDESTIN_SZJESZ08 -0.7654533  0.0099306   -77.081  &lt; 2e-16 ***\nDESTIN_SZJESZ09  0.1637628  0.0074164    22.081  &lt; 2e-16 ***\nDESTIN_SZJESZ10  0.7394958  0.0091249    81.041  &lt; 2e-16 ***\nDESTIN_SZJESZ11  0.5157364  0.0086546    59.591  &lt; 2e-16 ***\nDESTIN_SZJWSZ01 -1.0165204  0.0083025  -122.435  &lt; 2e-16 ***\nDESTIN_SZJWSZ02 -0.8530646  0.0067851  -125.727  &lt; 2e-16 ***\nDESTIN_SZJWSZ03  0.5176135  0.0056449    91.695  &lt; 2e-16 ***\nDESTIN_SZJWSZ04  0.3427105  0.0058499    58.584  &lt; 2e-16 ***\nDESTIN_SZJWSZ05 -1.1695940  0.0080069  -146.073  &lt; 2e-16 ***\nDESTIN_SZJWSZ06 -0.7466462  0.0070240  -106.299  &lt; 2e-16 ***\nDESTIN_SZJWSZ07 -3.0124535  0.0333481   -90.334  &lt; 2e-16 ***\nDESTIN_SZJWSZ08 -0.4253502  0.0066584   -63.881  &lt; 2e-16 ***\nDESTIN_SZJWSZ09  0.9428005  0.0053190   177.251  &lt; 2e-16 ***\nDESTIN_SZKLSZ01 -0.2965013  0.0066422   -44.639  &lt; 2e-16 ***\nDESTIN_SZKLSZ02 -0.4921137  0.0067689   -72.702  &lt; 2e-16 ***\nDESTIN_SZKLSZ03 -0.8489213  0.0078294  -108.427  &lt; 2e-16 ***\nDESTIN_SZKLSZ04 -1.2656342  0.0099918  -126.667  &lt; 2e-16 ***\nDESTIN_SZKLSZ05 -0.3570126  0.0096300   -37.073  &lt; 2e-16 ***\nDESTIN_SZKLSZ06 -2.4764906  0.0390868   -63.359  &lt; 2e-16 ***\nDESTIN_SZKLSZ07 -0.7316189  0.0080994   -90.330  &lt; 2e-16 ***\nDESTIN_SZKLSZ08 -0.1115398  0.0061168   -18.235  &lt; 2e-16 ***\nDESTIN_SZLKSZ01 -1.4940710  0.0271518   -55.027  &lt; 2e-16 ***\nDESTIN_SZMDSZ01 -1.6101440  0.0231238   -69.631  &lt; 2e-16 ***\nDESTIN_SZMDSZ02 -0.9339318  0.0126277   -73.959  &lt; 2e-16 ***\nDESTIN_SZMDSZ03 -3.4868547  0.0303657  -114.829  &lt; 2e-16 ***\nDESTIN_SZMPSZ01 -0.4518483  0.0089869   -50.279  &lt; 2e-16 ***\nDESTIN_SZMPSZ02 -0.5868264  0.0073193   -80.176  &lt; 2e-16 ***\nDESTIN_SZMPSZ03  0.4805365  0.0059041    81.391  &lt; 2e-16 ***\nDESTIN_SZMUSZ02 -1.3837581  0.0218713   -63.268  &lt; 2e-16 ***\nDESTIN_SZNTSZ01 -3.0694691  0.0533346   -57.551  &lt; 2e-16 ***\nDESTIN_SZNTSZ02 -1.4992973  0.0130358  -115.014  &lt; 2e-16 ***\nDESTIN_SZNTSZ03 -0.5221236  0.0089923   -58.064  &lt; 2e-16 ***\nDESTIN_SZNTSZ05 -1.9751162  0.0282369   -69.948  &lt; 2e-16 ***\nDESTIN_SZNTSZ06 -3.9959411  0.0511214   -78.166  &lt; 2e-16 ***\nDESTIN_SZNVSZ01 -0.1126966  0.0057077   -19.745  &lt; 2e-16 ***\nDESTIN_SZNVSZ02 -0.0259250  0.0064427    -4.024 5.72e-05 ***\nDESTIN_SZNVSZ03 -0.0123214  0.0067692    -1.820 0.068725 .  \nDESTIN_SZNVSZ04 -1.3371298  0.0130261  -102.650  &lt; 2e-16 ***\nDESTIN_SZNVSZ05 -0.9686333  0.0101539   -95.395  &lt; 2e-16 ***\nDESTIN_SZPGSZ01 -1.1798309  0.0180543   -65.349  &lt; 2e-16 ***\nDESTIN_SZPGSZ02 -1.3289737  0.0085335  -155.736  &lt; 2e-16 ***\nDESTIN_SZPGSZ03 -0.1661373  0.0055166   -30.116  &lt; 2e-16 ***\nDESTIN_SZPGSZ04 -0.3046408  0.0058469   -52.103  &lt; 2e-16 ***\nDESTIN_SZPGSZ05 -1.5412612  0.0093261  -165.264  &lt; 2e-16 ***\nDESTIN_SZPLSZ01 -0.3439667  0.0083504   -41.192  &lt; 2e-16 ***\nDESTIN_SZPLSZ02 -1.7574919  0.0154244  -113.942  &lt; 2e-16 ***\nDESTIN_SZPLSZ03 -0.3455776  0.0112089   -30.831  &lt; 2e-16 ***\nDESTIN_SZPLSZ04 -2.0749385  0.0141153  -146.999  &lt; 2e-16 ***\nDESTIN_SZPLSZ05 -0.4855216  0.0134069   -36.214  &lt; 2e-16 ***\nDESTIN_SZPNSZ01  0.0117816  0.0083558     1.410 0.158543    \nDESTIN_SZPNSZ02  0.7389858  0.0089823    82.272  &lt; 2e-16 ***\nDESTIN_SZPNSZ03 -0.4708719  0.0098588   -47.761  &lt; 2e-16 ***\nDESTIN_SZPNSZ04  1.3156771  0.0111200   118.316  &lt; 2e-16 ***\nDESTIN_SZPNSZ05  0.9881886  0.0153169    64.516  &lt; 2e-16 ***\nDESTIN_SZPRSZ01 -1.0678999  0.0098295  -108.642  &lt; 2e-16 ***\nDESTIN_SZPRSZ02  0.0650279  0.0063927    10.172  &lt; 2e-16 ***\nDESTIN_SZPRSZ03  0.6348138  0.0050147   126.592  &lt; 2e-16 ***\nDESTIN_SZPRSZ04 -0.3640286  0.0097572   -37.309  &lt; 2e-16 ***\nDESTIN_SZPRSZ05  0.0380410  0.0062577     6.079 1.21e-09 ***\nDESTIN_SZPRSZ06  0.3153712  0.0068742    45.877  &lt; 2e-16 ***\nDESTIN_SZPRSZ07 -1.6669973  0.0145573  -114.513  &lt; 2e-16 ***\nDESTIN_SZPRSZ08 -0.6170648  0.0078424   -78.683  &lt; 2e-16 ***\nDESTIN_SZQTSZ01 -0.5496582  0.0098285   -55.925  &lt; 2e-16 ***\nDESTIN_SZQTSZ02 -0.7318114  0.0086807   -84.303  &lt; 2e-16 ***\nDESTIN_SZQTSZ03 -0.5893064  0.0084789   -69.503  &lt; 2e-16 ***\nDESTIN_SZQTSZ04 -0.7103906  0.0085341   -83.242  &lt; 2e-16 ***\nDESTIN_SZQTSZ05 -0.4721472  0.0078164   -60.405  &lt; 2e-16 ***\nDESTIN_SZQTSZ06 -0.6591466  0.0080069   -82.322  &lt; 2e-16 ***\nDESTIN_SZQTSZ07 -0.9540454  0.0126807   -75.236  &lt; 2e-16 ***\nDESTIN_SZQTSZ08  0.4508867  0.0064870    69.507  &lt; 2e-16 ***\nDESTIN_SZQTSZ09 -0.4061810  0.0075485   -53.810  &lt; 2e-16 ***\nDESTIN_SZQTSZ10  0.1351889  0.0068202    19.822  &lt; 2e-16 ***\nDESTIN_SZQTSZ11  0.3181553  0.0067958    46.816  &lt; 2e-16 ***\nDESTIN_SZQTSZ12 -0.1055766  0.0095576   -11.046  &lt; 2e-16 ***\nDESTIN_SZQTSZ13  0.5199663  0.0071928    72.290  &lt; 2e-16 ***\nDESTIN_SZQTSZ14  0.6086332  0.0078537    77.496  &lt; 2e-16 ***\nDESTIN_SZQTSZ15  1.3906866  0.0092250   150.753  &lt; 2e-16 ***\nDESTIN_SZRCSZ01 -0.0862091  0.0085363   -10.099  &lt; 2e-16 ***\nDESTIN_SZRCSZ06 -1.0186282  0.0211113   -48.250  &lt; 2e-16 ***\nDESTIN_SZRVSZ01 -1.5294454  0.0179337   -85.283  &lt; 2e-16 ***\nDESTIN_SZRVSZ02 -2.3607754  0.0355628   -66.383  &lt; 2e-16 ***\nDESTIN_SZRVSZ03 -1.5266254  0.0156276   -97.688  &lt; 2e-16 ***\nDESTIN_SZRVSZ04 -1.0986565  0.0168695   -65.127  &lt; 2e-16 ***\nDESTIN_SZRVSZ05 -2.4004418  0.0320917   -74.799  &lt; 2e-16 ***\nDESTIN_SZSBSZ01 -1.4023966  0.0109496  -128.078  &lt; 2e-16 ***\nDESTIN_SZSBSZ02 -1.3899893  0.0090891  -152.929  &lt; 2e-16 ***\nDESTIN_SZSBSZ03  0.4509008  0.0059864    75.321  &lt; 2e-16 ***\nDESTIN_SZSBSZ04  0.1796309  0.0070142    25.610  &lt; 2e-16 ***\nDESTIN_SZSBSZ05 -1.3159699  0.0096485  -136.391  &lt; 2e-16 ***\nDESTIN_SZSBSZ06 -1.7705263  0.0253064   -69.964  &lt; 2e-16 ***\nDESTIN_SZSBSZ07 -0.7471529  0.0238628   -31.310  &lt; 2e-16 ***\nDESTIN_SZSBSZ08  0.7884520  0.0069638   113.221  &lt; 2e-16 ***\nDESTIN_SZSBSZ09  0.0131702  0.0066350     1.985 0.047150 *  \nDESTIN_SZSESZ02 -0.7247347  0.0060626  -119.541  &lt; 2e-16 ***\nDESTIN_SZSESZ03  0.1032728  0.0048330    21.368  &lt; 2e-16 ***\nDESTIN_SZSESZ04 -1.0992420  0.0068328  -160.878  &lt; 2e-16 ***\nDESTIN_SZSESZ05 -0.8374712  0.0058155  -144.006  &lt; 2e-16 ***\nDESTIN_SZSESZ06 -0.5531619  0.0074766   -73.985  &lt; 2e-16 ***\nDESTIN_SZSESZ07 -3.0328672  0.0246371  -123.101  &lt; 2e-16 ***\nDESTIN_SZSGSZ01 -0.1933777  0.0068235   -28.340  &lt; 2e-16 ***\nDESTIN_SZSGSZ02 -0.3000845  0.0060284   -49.779  &lt; 2e-16 ***\nDESTIN_SZSGSZ03 -0.4322879  0.0057308   -75.433  &lt; 2e-16 ***\nDESTIN_SZSGSZ04 -0.1214792  0.0056548   -21.482  &lt; 2e-16 ***\nDESTIN_SZSGSZ05 -2.0309074  0.0114993  -176.611  &lt; 2e-16 ***\nDESTIN_SZSGSZ06  0.6592095  0.0046364   142.182  &lt; 2e-16 ***\nDESTIN_SZSGSZ07 -0.4618538  0.0062027   -74.460  &lt; 2e-16 ***\nDESTIN_SZSISZ01 -0.5227257  0.0293399   -17.816  &lt; 2e-16 ***\nDESTIN_SZSKSZ01 -0.4797341  0.0091087   -52.668  &lt; 2e-16 ***\nDESTIN_SZSKSZ02  0.8477357  0.0067821   124.996  &lt; 2e-16 ***\nDESTIN_SZSKSZ03 -0.2477566  0.0074817   -33.115  &lt; 2e-16 ***\nDESTIN_SZSKSZ04 -1.3315992  0.0167055   -79.710  &lt; 2e-16 ***\nDESTIN_SZSKSZ05 -0.3519096  0.0131326   -26.797  &lt; 2e-16 ***\nDESTIN_SZSLSZ01 -0.8570431  0.0102100   -83.941  &lt; 2e-16 ***\nDESTIN_SZSLSZ04 -0.9949105  0.0088280  -112.699  &lt; 2e-16 ***\nDESTIN_SZSRSZ01 -1.0260696  0.0154393   -66.458  &lt; 2e-16 ***\nDESTIN_SZTHSZ01 -4.2040410  0.0404795  -103.856  &lt; 2e-16 ***\nDESTIN_SZTHSZ03 -2.4907000  0.0264056   -94.325  &lt; 2e-16 ***\nDESTIN_SZTHSZ04 -3.0701470  0.0244975  -125.325  &lt; 2e-16 ***\nDESTIN_SZTHSZ06 -2.5308161  0.0169699  -149.135  &lt; 2e-16 ***\nDESTIN_SZTMSZ01 -0.2354889  0.0067201   -35.042  &lt; 2e-16 ***\nDESTIN_SZTMSZ02  1.7379292  0.0044573   389.906  &lt; 2e-16 ***\nDESTIN_SZTMSZ03  0.9112458  0.0048718   187.043  &lt; 2e-16 ***\nDESTIN_SZTMSZ04  1.0731075  0.0048626   220.685  &lt; 2e-16 ***\nDESTIN_SZTMSZ05  0.6398583  0.0067321    95.046  &lt; 2e-16 ***\nDESTIN_SZTNSZ01 -0.3500456  0.0083835   -41.754  &lt; 2e-16 ***\nDESTIN_SZTNSZ02 -1.0573515  0.0112412   -94.060  &lt; 2e-16 ***\nDESTIN_SZTNSZ03 -1.4069979  0.0132733  -106.002  &lt; 2e-16 ***\nDESTIN_SZTNSZ04 -0.3616604  0.0085207   -42.445  &lt; 2e-16 ***\nDESTIN_SZTPSZ01 -0.5919243  0.0071153   -83.190  &lt; 2e-16 ***\nDESTIN_SZTPSZ02  0.7083350  0.0046540   152.198  &lt; 2e-16 ***\nDESTIN_SZTPSZ03 -0.5746433  0.0069625   -82.534  &lt; 2e-16 ***\nDESTIN_SZTPSZ04 -1.5821259  0.0084517  -187.196  &lt; 2e-16 ***\nDESTIN_SZTPSZ05 -1.1796256  0.0073039  -161.505  &lt; 2e-16 ***\nDESTIN_SZTPSZ06 -0.3968272  0.0077295   -51.339  &lt; 2e-16 ***\nDESTIN_SZTPSZ07 -2.1796617  0.0135199  -161.219  &lt; 2e-16 ***\nDESTIN_SZTPSZ08 -1.2568483  0.0107267  -117.170  &lt; 2e-16 ***\nDESTIN_SZTPSZ09 -0.2446623  0.0080840   -30.265  &lt; 2e-16 ***\nDESTIN_SZTPSZ10 -1.2542191  0.0102049  -122.904  &lt; 2e-16 ***\nDESTIN_SZTPSZ11 -0.0886883  0.0062888   -14.102  &lt; 2e-16 ***\nDESTIN_SZTPSZ12 -0.7211823  0.0075086   -96.048  &lt; 2e-16 ***\nDESTIN_SZTSSZ01 -1.6271921  0.0238498   -68.227  &lt; 2e-16 ***\nDESTIN_SZTSSZ02 -0.3340439  0.0169137   -19.750  &lt; 2e-16 ***\nDESTIN_SZTSSZ03  0.3924580  0.0111060    35.338  &lt; 2e-16 ***\nDESTIN_SZTSSZ04  0.4169932  0.0114926    36.283  &lt; 2e-16 ***\nDESTIN_SZTSSZ05  1.3206287  0.0120381   109.704  &lt; 2e-16 ***\nDESTIN_SZTSSZ06  2.4023725  0.0192840   124.579  &lt; 2e-16 ***\nDESTIN_SZWCSZ01  2.0697378  0.0061379   337.206  &lt; 2e-16 ***\nDESTIN_SZWCSZ02 -2.0934025  0.0134782  -155.318  &lt; 2e-16 ***\nDESTIN_SZWCSZ03 -3.0670149  0.0349748   -87.692  &lt; 2e-16 ***\nDESTIN_SZWDSZ01  1.0113215  0.0051461   196.522  &lt; 2e-16 ***\nDESTIN_SZWDSZ02 -1.3383793  0.0076482  -174.993  &lt; 2e-16 ***\nDESTIN_SZWDSZ03  0.3394361  0.0060396    56.202  &lt; 2e-16 ***\nDESTIN_SZWDSZ04 -0.8324928  0.0086019   -96.780  &lt; 2e-16 ***\nDESTIN_SZWDSZ05 -0.8279090  0.0083251   -99.447  &lt; 2e-16 ***\nDESTIN_SZWDSZ06 -0.2252899  0.0061074   -36.888  &lt; 2e-16 ***\nDESTIN_SZWDSZ07 -1.3638599  0.0077990  -174.877  &lt; 2e-16 ***\nDESTIN_SZWDSZ08 -0.4350176  0.0077566   -56.083  &lt; 2e-16 ***\nDESTIN_SZWDSZ09  0.5461048  0.0060745    89.901  &lt; 2e-16 ***\nDESTIN_SZYSSZ01  0.0243093  0.0053476     4.546 5.47e-06 ***\nDESTIN_SZYSSZ02 -0.3398962  0.0065947   -51.540  &lt; 2e-16 ***\nDESTIN_SZYSSZ03 -0.3694187  0.0074032   -49.900  &lt; 2e-16 ***\nDESTIN_SZYSSZ04 -0.5222848  0.0067396   -77.495  &lt; 2e-16 ***\nDESTIN_SZYSSZ05 -1.5460539  0.0124899  -123.784  &lt; 2e-16 ***\nDESTIN_SZYSSZ06 -1.5556892  0.0127640  -121.881  &lt; 2e-16 ***\nDESTIN_SZYSSZ07 -0.8673403  0.0167723   -51.713  &lt; 2e-16 ***\nDESTIN_SZYSSZ08  0.5389364  0.0052540   102.577  &lt; 2e-16 ***\nDESTIN_SZYSSZ09  0.1199483  0.0055235    21.716  &lt; 2e-16 ***\nlog(dist)       -1.8906989  0.0005319 -3554.786  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 36117615  on 14273  degrees of freedom\nResidual deviance:  8091747  on 13715  degrees of freedom\nAIC: 8177420\n\nNumber of Fisher Scoring iterations: 7\n\n\nLet’s calculate the R-squared for the doubly constrained model.\n\nCalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)\n\n[1] 0.6883675\n\n\n\n\nModel Comparison\nAnother useful model performance measure for continuous dependent variable is Root Mean Squared Error.\nModel comparison can be done with the compare_performance() function of the performance package.\n\nmodel_list &lt;- list(unconstrained = uncSIM,\n                   originConstrained = orcSIM,\n                   destinationConstrained = decSIM,\n                   doublyConstrained = dbcSIM)\n\nNow let’s use the model_list to compare model performance.\n\ncompare_performance(model_list,\n                    metrics = 'RMSE')\n\n# Comparison of Model Performance Indices\n\nName                   | Model |     RMSE\n-----------------------------------------\nunconstrained          |   glm | 2429.978\noriginConstrained      |   glm | 2057.579\ndestinationConstrained |   glm | 1891.724\ndoublyConstrained      |   glm | 1487.111\n\n\nThe print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 1487.111.\n\n\nVisualizing Fitted\nBefore we visualize the observed and fitted values, we need to extract the fitted values from each model.\n\ndf &lt;- as.data.frame(uncSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nNext, we will join the values to SIM_data frame.\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(uncTRIPS = \"uncSIM$fitted.values\")\n\nRepeat these steps for other models.\n\ndf &lt;- as.data.frame(orcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(orcTRIPS = 'orcSIM$fitted.values')\n\n\ndf &lt;- as.data.frame(decSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(decTRIPS = 'decSIM$fitted.values')\n\n\ndf &lt;- as.data.frame(dbcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(dbcTRIPS = 'dbcSIM$fitted.values')\n\nNow we can create our visualizations.\n\nunc_p &lt;- ggplot(SIM_data,\n                aes(x = uncTRIPS,\n                    y = TRIPS))+\n  geom_point()+\n  geom_smooth(method = lm)\n\norc_p &lt;- ggplot(data = SIM_data,\n                aes(x = orcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndec_p &lt;- ggplot(data = SIM_data,\n                aes(x = decTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndbc_p &lt;- ggplot(data = SIM_data,\n                aes(x = dbcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\nggarrange(unc_p, orc_p, dec_p, dbc_p,\n          ncol = 2,\n          nrow = 2)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/data/geospatial/entertn.html",
    "href": "In-Class_Ex/In-Class_Ex4/data/geospatial/entertn.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/data/geospatial/FinServ.html",
    "href": "In-Class_Ex/In-Class_Ex4/data/geospatial/FinServ.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/data/geospatial/MPSZ-2019.html",
    "href": "In-Class_Ex/In-Class_Ex4/data/geospatial/MPSZ-2019.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html",
    "href": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html",
    "title": "In-Class_Ex4",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, httr, tmap, performance)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html#getting-started",
    "href": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html#getting-started",
    "title": "In-Class_Ex4",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, httr, tmap, performance)"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html#geocoding-using-sla-api",
    "href": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html#geocoding-using-sla-api",
    "title": "In-Class_Ex4",
    "section": "Geocoding using SLA API",
    "text": "Geocoding using SLA API\n\nurl &lt;- 'https://www.onemap.gov.sg/api/common/elastic/search'\n\ncsv &lt;- read_csv('data/aspatial/Generalinformationofschools.csv')\npostcodes &lt;- csv$`postal_code`\n\nfound &lt;- data.frame()\nnot_found &lt;- data.frame()\n\nfor(postcode in postcodes) {\n  query &lt;- list('searchVal' = postcode,\n                'returnGeom' = 'Y',\n                'getAddrDetails' = 'Y',\n                'pageNum' = '1')\n  res &lt;- GET(url,query = query)\n  if((content(res)$found)!= 0 ){\n    found &lt;- rbind(found, data.frame(content(res))[4:13])\n  }\n  else{\n    not_found = data.frame(postcode)\n  }\n}\n\nNext, the code chunk below will be used to combine both found and not_found data frames into a single tibble df called merged. At the same time, we will write merged and not_found tibble dfs into csv format for future use.\n\nmerged &lt;- merge(csv, found, by.x = 'postal_code', by.y = 'results.POSTAL', all = TRUE)\n\nwrite.csv(merged, file = 'data/aspatial/schools.csv')\n\nwrite.csv(not_found, file = 'data/aspatial/not_found.csv')"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html#converting-an-aspatial-data-frame-into-a-simple-feature-tibble-data-frame",
    "href": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html#converting-an-aspatial-data-frame-into-a-simple-feature-tibble-data-frame",
    "title": "In-Class_Ex4",
    "section": "Converting an aspatial data frame into a simple feature tibble data frame",
    "text": "Converting an aspatial data frame into a simple feature tibble data frame\n\nImporting and tidying schools.csv data frame\n\nschools &lt;- read_csv('data/aspatial/schools.csv')\n\nschools &lt;- schools %&gt;%\n  rename(latitude = results.LATITUDE,\n         longitude = results.LONGITUDE) %&gt;%\n  select(postal_code, school_name, latitude, longitude)\n\n\n\nConverting an aspatial data frame into sf tibble data frame\n\nschools &lt;- st_as_sf(schools, \n                    coords = c('longitude','latitude'),\n                    crs = 4326)%&gt;%\n  st_transform(crs = 3414)\n\n\n\nPlotting a point simple feature layer\nTo ensure that schools sf df has been projected and converted correctly, you can plot the school points data for visual inspection.\n\ntmap_mode('view')\n\ntm_shape(schools)+\n  tm_dots()+\n  tm_view(set.zoom.limits = c(11,14))"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html#preparing",
    "href": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html#preparing",
    "title": "In-Class_Ex4",
    "section": "Preparing",
    "text": "Preparing\n\nPoint-in-Polygon Count\nImporting Master Planning Sub-zone 2019\n\nmpsz &lt;- st_read(dsn = 'data/geospatial',\n                layer = 'MPSZ-2019') %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex4\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nCount number of school that falls within a planning subzone.\n\nmpsz$`SCHOOL_COUNT` &lt;- lengths(st_intersects(mpsz, schools))\n\n\n\nImporting Business shapefile\n\nbusiness &lt;- st_read(dsn = 'data/geospatial',\n                    layer = 'Business')\n\nReading layer `Business' from data source \n  `D:\\phlong2023\\ISSS624\\In-Class_Ex\\In-Class_Ex4\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 6550 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3669.148 ymin: 25408.41 xmax: 47034.83 ymax: 50148.54\nProjected CRS: SVY21 / Singapore TM\n\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode('plot')\n\ntm_shape(mpsz)+\n  tm_polygons()+\n  tm_shape(business)+\n  tm_dots()\n\n\n\n\nCreate a new column to count the number of Businesses in each mpsz.\n\nmpsz$`business_count` &lt;- lengths(st_intersects(mpsz, business))\n\n\nsummary(mpsz$business_count)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    2.00   19.73   13.00  307.00"
  },
  {
    "objectID": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html#the-data",
    "href": "In-Class_Ex/In-Class_Ex4/In-Class_Ex4.html#the-data",
    "title": "In-Class_Ex4",
    "section": "The Data",
    "text": "The Data\n\nflow_data &lt;- read_rds('data/rds/flow_data_tidy.rds')\nglimpse(flow_data)\n\nRows: 14,734\nColumns: 13\n$ ORIGIN_SZ       &lt;chr&gt; \"AMSZ01\", \"AMSZ01\", \"AMSZ01\", \"AMSZ01\", \"AMSZ01\", \"AMS…\n$ DESTIN_SZ       &lt;chr&gt; \"AMSZ01\", \"AMSZ02\", \"AMSZ03\", \"AMSZ04\", \"AMSZ05\", \"AMS…\n$ MORNING_PEAK    &lt;dbl&gt; 1998, 8289, 8971, 2252, 6136, 2148, 1620, 1925, 1773, …\n$ dist            &lt;dbl&gt; 50.0000, 810.4491, 1360.9294, 840.4432, 1076.7916, 805…\n$ ORIGIN_AGE7_12  &lt;dbl&gt; 310, 310, 310, 310, 310, 310, 310, 310, 310, 310, 310,…\n$ ORIGIN_AGE13_24 &lt;dbl&gt; 710, 710, 710, 710, 710, 710, 710, 710, 710, 710, 710,…\n$ ORIGIN_AGE25_64 &lt;dbl&gt; 2780, 2780, 2780, 2780, 2780, 2780, 2780, 2780, 2780, …\n$ DESTIN_AGE7_12  &lt;dbl&gt; 310.00, 1140.00, 1010.00, 980.00, 810.00, 1050.00, 420…\n$ DESTIN_AGE13_24 &lt;dbl&gt; 710.00, 2770.00, 2650.00, 2000.00, 1920.00, 2390.00, 1…\n$ DESTIN_AGE25_64 &lt;dbl&gt; 2780.00, 15700.00, 14240.00, 11320.00, 9650.00, 12460.…\n$ SCHOOL_COUNT    &lt;dbl&gt; 0.99, 2.00, 2.00, 1.00, 3.00, 2.00, 0.99, 0.99, 3.00, …\n$ RETAIL_COUNT    &lt;dbl&gt; 1.00, 0.99, 6.00, 0.99, 0.99, 0.99, 1.00, 117.00, 0.99…\n$ geometry        &lt;LINESTRING [m]&gt; LINESTRING (29501.77 39419...., LINESTRING …\n\n\nLet’s check for 0 values.\n\nsummary(flow_data)\n\n  ORIGIN_SZ          DESTIN_SZ          MORNING_PEAK         dist      \n Length:14734       Length:14734       Min.   :     1   Min.   :   50  \n Class :character   Class :character   1st Qu.:    14   1st Qu.: 3346  \n Mode  :character   Mode  :character   Median :    76   Median : 6067  \n                                       Mean   :  1021   Mean   : 6880  \n                                       3rd Qu.:   426   3rd Qu.: 9729  \n                                       Max.   :232187   Max.   :26136  \n ORIGIN_AGE7_12    ORIGIN_AGE13_24    ORIGIN_AGE25_64    DESTIN_AGE7_12   \n Min.   :   0.99   Min.   :    0.99   Min.   :    0.99   Min.   :   0.99  \n 1st Qu.: 240.00   1st Qu.:  440.00   1st Qu.: 2200.00   1st Qu.: 240.00  \n Median : 700.00   Median : 1350.00   Median : 6810.00   Median : 720.00  \n Mean   :1031.86   Mean   : 2268.84   Mean   :10487.62   Mean   :1033.40  \n 3rd Qu.:1480.00   3rd Qu.: 3260.00   3rd Qu.:15770.00   3rd Qu.:1500.00  \n Max.   :6340.00   Max.   :16380.00   Max.   :74610.00   Max.   :6340.00  \n DESTIN_AGE13_24    DESTIN_AGE25_64     SCHOOL_COUNT     RETAIL_COUNT   \n Min.   :    0.99   Min.   :    0.99   Min.   : 0.990   Min.   :  0.99  \n 1st Qu.:  460.00   1st Qu.: 2200.00   1st Qu.: 0.990   1st Qu.:  0.99  \n Median : 1420.00   Median : 7030.00   Median : 1.000   Median :  3.00  \n Mean   : 2290.35   Mean   :10574.46   Mean   : 1.987   Mean   : 16.47  \n 3rd Qu.: 3260.00   3rd Qu.:15830.00   3rd Qu.: 2.000   3rd Qu.: 12.00  \n Max.   :16380.00   Max.   :74610.00   Max.   :12.000   Max.   :307.00  \n          geometry    \n LINESTRING   :14734  \n epsg:3414    :    0  \n +proj=tmer...:    0  \n                      \n                      \n                      \n\n\n\nflow_data$FlowNoIntra &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ,\n  0, flow_data$MORNING_PEAK)\nflow_data$offset &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ,\n  0.000001, 1)\n\ninter_zonal_flow &lt;- flow_data %&gt;% \n  filter(FlowNoIntra &gt;0)\n\ninter_zonal_flow &lt;- inter_zonal_flow %&gt;% \n  rename(TRIPS = MORNING_PEAK,\n         DIST = dist)\n\n\nOrigin (Production) Constrained SIM\n\norcSIM_Poisson &lt;- glm(formula = TRIPS ~\n                        ORIGIN_SZ +\n                        log(SCHOOL_COUNT)+\n                        log(RETAIL_COUNT)+\n                        log(DIST) - 1, #the -1 is to remove the intercept which is not necessary in a constrained model\n                      family = poisson(link = 'log'),\n                      data = inter_zonal_flow,\n                      na.action = na.exclude)\n\nsummary(orcSIM_Poisson)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(SCHOOL_COUNT) + log(RETAIL_COUNT) + \n    log(DIST) - 1, family = poisson(link = \"log\"), data = inter_zonal_flow, \n    na.action = na.exclude)\n\nCoefficients:\n                    Estimate Std. Error  z value Pr(&gt;|z|)    \nORIGIN_SZAMSZ01   19.8739840  0.0047627  4172.84   &lt;2e-16 ***\nORIGIN_SZAMSZ02   20.5902203  0.0042786  4812.33   &lt;2e-16 ***\nORIGIN_SZAMSZ03   20.2327026  0.0045531  4443.70   &lt;2e-16 ***\nORIGIN_SZAMSZ04   19.7744438  0.0049837  3967.79   &lt;2e-16 ***\nORIGIN_SZAMSZ05   19.6574529  0.0056396  3485.61   &lt;2e-16 ***\nORIGIN_SZAMSZ06   19.9659115  0.0048946  4079.16   &lt;2e-16 ***\nORIGIN_SZAMSZ07   18.6746164  0.0096316  1938.90   &lt;2e-16 ***\nORIGIN_SZAMSZ08   19.2701601  0.0090776  2122.82   &lt;2e-16 ***\nORIGIN_SZAMSZ09   19.9889467  0.0052858  3781.64   &lt;2e-16 ***\nORIGIN_SZAMSZ10   20.3422035  0.0045778  4443.62   &lt;2e-16 ***\nORIGIN_SZAMSZ11   18.3944113  0.0129212  1423.58   &lt;2e-16 ***\nORIGIN_SZAMSZ12   18.3484209  0.0109652  1673.33   &lt;2e-16 ***\nORIGIN_SZBDSZ01   20.9668587  0.0043388  4832.36   &lt;2e-16 ***\nORIGIN_SZBDSZ02   20.4059518  0.0050601  4032.75   &lt;2e-16 ***\nORIGIN_SZBDSZ03   20.6725514  0.0045276  4565.93   &lt;2e-16 ***\nORIGIN_SZBDSZ04   21.6703853  0.0038930  5566.44   &lt;2e-16 ***\nORIGIN_SZBDSZ05   20.7497445  0.0046085  4502.46   &lt;2e-16 ***\nORIGIN_SZBDSZ06   20.9119361  0.0046432  4503.77   &lt;2e-16 ***\nORIGIN_SZBDSZ07   18.9749815  0.0097896  1938.28   &lt;2e-16 ***\nORIGIN_SZBDSZ08   19.1933901  0.0091312  2101.95   &lt;2e-16 ***\nORIGIN_SZBKSZ01   19.5422606  0.0064732  3018.96   &lt;2e-16 ***\nORIGIN_SZBKSZ02   20.1748913  0.0050076  4028.89   &lt;2e-16 ***\nORIGIN_SZBKSZ03   20.3984624  0.0047226  4319.35   &lt;2e-16 ***\nORIGIN_SZBKSZ04   19.6182212  0.0059652  3288.76   &lt;2e-16 ***\nORIGIN_SZBKSZ05   19.6033818  0.0063181  3102.74   &lt;2e-16 ***\nORIGIN_SZBKSZ06   19.7145224  0.0056372  3497.20   &lt;2e-16 ***\nORIGIN_SZBKSZ07   20.4237448  0.0041912  4873.03   &lt;2e-16 ***\nORIGIN_SZBKSZ08   19.7992538  0.0050405  3928.02   &lt;2e-16 ***\nORIGIN_SZBKSZ09   19.7821586  0.0055558  3560.66   &lt;2e-16 ***\nORIGIN_SZBLSZ01   17.7977276  0.0149058  1194.01   &lt;2e-16 ***\nORIGIN_SZBLSZ02   17.4287491  0.0192364   906.03   &lt;2e-16 ***\nORIGIN_SZBLSZ03   16.5884288  0.0459848   360.74   &lt;2e-16 ***\nORIGIN_SZBLSZ04   17.7851626  0.0232823   763.89   &lt;2e-16 ***\nORIGIN_SZBMSZ01   20.0751840  0.0052887  3795.89   &lt;2e-16 ***\nORIGIN_SZBMSZ02   18.6956140  0.0066656  2804.80   &lt;2e-16 ***\nORIGIN_SZBMSZ03   19.3204425  0.0054755  3528.56   &lt;2e-16 ***\nORIGIN_SZBMSZ04   19.4724220  0.0049390  3942.59   &lt;2e-16 ***\nORIGIN_SZBMSZ05   16.9581801  0.0168804  1004.61   &lt;2e-16 ***\nORIGIN_SZBMSZ06   16.9898638  0.0181852   934.27   &lt;2e-16 ***\nORIGIN_SZBMSZ07   19.2868403  0.0056231  3429.91   &lt;2e-16 ***\nORIGIN_SZBMSZ08   19.1477543  0.0055918  3424.28   &lt;2e-16 ***\nORIGIN_SZBMSZ09   18.7564539  0.0086298  2173.46   &lt;2e-16 ***\nORIGIN_SZBMSZ10   18.3617854  0.0089250  2057.35   &lt;2e-16 ***\nORIGIN_SZBMSZ11   18.9167941  0.0063340  2986.54   &lt;2e-16 ***\nORIGIN_SZBMSZ12   18.7874661  0.0093024  2019.63   &lt;2e-16 ***\nORIGIN_SZBMSZ13   19.5654046  0.0057517  3401.70   &lt;2e-16 ***\nORIGIN_SZBMSZ14   19.0685619  0.0063346  3010.24   &lt;2e-16 ***\nORIGIN_SZBMSZ15   19.4403124  0.0058147  3343.30   &lt;2e-16 ***\nORIGIN_SZBMSZ16   18.4469203  0.0092638  1991.28   &lt;2e-16 ***\nORIGIN_SZBMSZ17   18.3430175  0.0157692  1163.22   &lt;2e-16 ***\nORIGIN_SZBPSZ01   20.1806714  0.0053660  3760.81   &lt;2e-16 ***\nORIGIN_SZBPSZ02   19.8116707  0.0061485  3222.19   &lt;2e-16 ***\nORIGIN_SZBPSZ03   19.8467602  0.0059769  3320.57   &lt;2e-16 ***\nORIGIN_SZBPSZ04   20.4613200  0.0048398  4227.72   &lt;2e-16 ***\nORIGIN_SZBPSZ05   20.5379711  0.0043769  4692.39   &lt;2e-16 ***\nORIGIN_SZBPSZ06   18.8948034  0.0093668  2017.21   &lt;2e-16 ***\nORIGIN_SZBPSZ07   19.4104568  0.0087961  2206.70   &lt;2e-16 ***\nORIGIN_SZBSSZ01   20.0139503  0.0056561  3538.45   &lt;2e-16 ***\nORIGIN_SZBSSZ02   20.2543885  0.0047198  4291.38   &lt;2e-16 ***\nORIGIN_SZBSSZ03   19.5428803  0.0052713  3707.41   &lt;2e-16 ***\nORIGIN_SZBTSZ01   20.0198045  0.0058541  3419.77   &lt;2e-16 ***\nORIGIN_SZBTSZ02   19.3618525  0.0081472  2376.51   &lt;2e-16 ***\nORIGIN_SZBTSZ03   19.5883853  0.0068935  2841.59   &lt;2e-16 ***\nORIGIN_SZBTSZ04   18.7720238  0.0103909  1806.58   &lt;2e-16 ***\nORIGIN_SZBTSZ05   18.8069026  0.0120628  1559.08   &lt;2e-16 ***\nORIGIN_SZBTSZ06   18.7068633  0.0094575  1978.00   &lt;2e-16 ***\nORIGIN_SZBTSZ07   17.6292257  0.0141551  1245.43   &lt;2e-16 ***\nORIGIN_SZBTSZ08   18.6989374  0.0109610  1705.94   &lt;2e-16 ***\nORIGIN_SZCBSZ01   18.2189868  0.0548317   332.27   &lt;2e-16 ***\nORIGIN_SZCCSZ01   18.9734563  0.0139450  1360.59   &lt;2e-16 ***\nORIGIN_SZCHSZ01   19.5955119  0.0121035  1619.00   &lt;2e-16 ***\nORIGIN_SZCHSZ02   19.3320960  0.0081620  2368.55   &lt;2e-16 ***\nORIGIN_SZCHSZ03   21.2164518  0.0063552  3338.43   &lt;2e-16 ***\nORIGIN_SZCKSZ01   20.1046845  0.0049333  4075.29   &lt;2e-16 ***\nORIGIN_SZCKSZ02   20.5371946  0.0050256  4086.53   &lt;2e-16 ***\nORIGIN_SZCKSZ03   20.7210560  0.0042184  4912.07   &lt;2e-16 ***\nORIGIN_SZCKSZ04   21.4013886  0.0042524  5032.80   &lt;2e-16 ***\nORIGIN_SZCKSZ05   20.9413146  0.0049434  4236.18   &lt;2e-16 ***\nORIGIN_SZCKSZ06   20.2557727  0.0071832  2819.88   &lt;2e-16 ***\nORIGIN_SZCLSZ01   19.3383703  0.0076634  2523.46   &lt;2e-16 ***\nORIGIN_SZCLSZ02   18.5226956  0.0135522  1366.77   &lt;2e-16 ***\nORIGIN_SZCLSZ03   19.0225512  0.0080145  2373.51   &lt;2e-16 ***\nORIGIN_SZCLSZ04   20.7981505  0.0042400  4905.22   &lt;2e-16 ***\nORIGIN_SZCLSZ05   18.3015625  0.0146815  1246.58   &lt;2e-16 ***\nORIGIN_SZCLSZ06   20.8207386  0.0039567  5262.09   &lt;2e-16 ***\nORIGIN_SZCLSZ07   19.6728958  0.0054199  3629.76   &lt;2e-16 ***\nORIGIN_SZCLSZ08   20.0851929  0.0056956  3526.43   &lt;2e-16 ***\nORIGIN_SZCLSZ09   18.5749589  0.0165415  1122.93   &lt;2e-16 ***\nORIGIN_SZDTSZ02   15.8276209  0.0833992   189.78   &lt;2e-16 ***\nORIGIN_SZDTSZ03   16.2512838  0.0737972   220.22   &lt;2e-16 ***\nORIGIN_SZDTSZ13   16.7744385  0.0312450   536.87   &lt;2e-16 ***\nORIGIN_SZGLSZ01   18.2368248  0.0096104  1897.62   &lt;2e-16 ***\nORIGIN_SZGLSZ02   19.8705255  0.0049014  4054.06   &lt;2e-16 ***\nORIGIN_SZGLSZ03   19.8249435  0.0053109  3732.85   &lt;2e-16 ***\nORIGIN_SZGLSZ04   20.7800335  0.0041261  5036.20   &lt;2e-16 ***\nORIGIN_SZGLSZ05   20.6040494  0.0043049  4786.23   &lt;2e-16 ***\nORIGIN_SZHGSZ01   20.0273475  0.0044824  4468.04   &lt;2e-16 ***\nORIGIN_SZHGSZ02   20.2480656  0.0044575  4542.47   &lt;2e-16 ***\nORIGIN_SZHGSZ03   20.0756442  0.0049003  4096.81   &lt;2e-16 ***\nORIGIN_SZHGSZ04   20.7577748  0.0040465  5129.84   &lt;2e-16 ***\nORIGIN_SZHGSZ05   20.9779992  0.0040123  5228.42   &lt;2e-16 ***\nORIGIN_SZHGSZ06   19.7403058  0.0054229  3640.20   &lt;2e-16 ***\nORIGIN_SZHGSZ07   20.1896268  0.0046051  4384.22   &lt;2e-16 ***\nORIGIN_SZHGSZ08   19.8646492  0.0052403  3790.72   &lt;2e-16 ***\nORIGIN_SZHGSZ09   18.3647736  0.0069196  2654.04   &lt;2e-16 ***\nORIGIN_SZHGSZ10   16.8720475  0.0421046   400.72   &lt;2e-16 ***\nORIGIN_SZJESZ01   20.2673794  0.0046723  4337.79   &lt;2e-16 ***\nORIGIN_SZJESZ02   20.0595982  0.0046503  4313.61   &lt;2e-16 ***\nORIGIN_SZJESZ03   19.9128778  0.0049848  3994.75   &lt;2e-16 ***\nORIGIN_SZJESZ04   18.5053667  0.0099227  1864.94   &lt;2e-16 ***\nORIGIN_SZJESZ05   17.8172930  0.0138840  1283.29   &lt;2e-16 ***\nORIGIN_SZJESZ06   20.0124157  0.0045009  4446.36   &lt;2e-16 ***\nORIGIN_SZJESZ07   18.1821423  0.0117267  1550.49   &lt;2e-16 ***\nORIGIN_SZJESZ08   18.8713046  0.0116456  1620.46   &lt;2e-16 ***\nORIGIN_SZJESZ09   20.5535527  0.0048456  4241.72   &lt;2e-16 ***\nORIGIN_SZJESZ10   18.4922322  0.0191243   966.95   &lt;2e-16 ***\nORIGIN_SZJESZ11   18.2891211  0.0197114   927.85   &lt;2e-16 ***\nORIGIN_SZJWSZ01   20.4912737  0.0063102  3247.35   &lt;2e-16 ***\nORIGIN_SZJWSZ02   20.8236694  0.0042249  4928.82   &lt;2e-16 ***\nORIGIN_SZJWSZ03   21.2587613  0.0039733  5350.40   &lt;2e-16 ***\nORIGIN_SZJWSZ04   20.3816464  0.0046199  4411.67   &lt;2e-16 ***\nORIGIN_SZJWSZ05   18.0607448  0.0128857  1401.61   &lt;2e-16 ***\nORIGIN_SZJWSZ06   18.7015202  0.0107614  1737.83   &lt;2e-16 ***\nORIGIN_SZJWSZ07   17.3991822  0.0277096   627.91   &lt;2e-16 ***\nORIGIN_SZJWSZ08   21.8044465  0.0037356  5836.95   &lt;2e-16 ***\nORIGIN_SZJWSZ09   21.5414930  0.0036033  5978.19   &lt;2e-16 ***\nORIGIN_SZKLSZ01   20.0307712  0.0047868  4184.59   &lt;2e-16 ***\nORIGIN_SZKLSZ02   19.0634769  0.0062318  3059.05   &lt;2e-16 ***\nORIGIN_SZKLSZ03   19.2685700  0.0057172  3370.25   &lt;2e-16 ***\nORIGIN_SZKLSZ04   17.7085067  0.0119809  1478.06   &lt;2e-16 ***\nORIGIN_SZKLSZ05   18.6384471  0.0107596  1732.26   &lt;2e-16 ***\nORIGIN_SZKLSZ06   13.7280296  0.1857160    73.92   &lt;2e-16 ***\nORIGIN_SZKLSZ07   18.6425146  0.0084952  2194.47   &lt;2e-16 ***\nORIGIN_SZKLSZ08   18.0928506  0.0101567  1781.37   &lt;2e-16 ***\nORIGIN_SZLKSZ01   17.8907138  0.0397083   450.55   &lt;2e-16 ***\nORIGIN_SZMDSZ01   18.7605188  0.0285455   657.22   &lt;2e-16 ***\nORIGIN_SZMDSZ02   19.1533927  0.0102815  1862.90   &lt;2e-16 ***\nORIGIN_SZMDSZ03   17.8404982  0.0169690  1051.36   &lt;2e-16 ***\nORIGIN_SZMPSZ01   19.0765941  0.0083937  2272.74   &lt;2e-16 ***\nORIGIN_SZMPSZ02   19.2162527  0.0068331  2812.24   &lt;2e-16 ***\nORIGIN_SZMPSZ03   19.9965344  0.0054569  3664.44   &lt;2e-16 ***\nORIGIN_SZMUSZ02   15.9130765  0.1037472   153.38   &lt;2e-16 ***\nORIGIN_SZNTSZ01   17.0840999  0.0352513   484.64   &lt;2e-16 ***\nORIGIN_SZNTSZ02   16.5792122  0.0233186   710.99   &lt;2e-16 ***\nORIGIN_SZNTSZ03   18.9506415  0.0075957  2494.93   &lt;2e-16 ***\nORIGIN_SZNTSZ05   15.8770261  0.0495825   320.21   &lt;2e-16 ***\nORIGIN_SZNTSZ06   15.3997415  0.0557029   276.46   &lt;2e-16 ***\nORIGIN_SZNVSZ01   20.2241694  0.0043487  4650.65   &lt;2e-16 ***\nORIGIN_SZNVSZ02   19.1897826  0.0065383  2934.97   &lt;2e-16 ***\nORIGIN_SZNVSZ03   18.8854268  0.0080459  2347.22   &lt;2e-16 ***\nORIGIN_SZNVSZ04   18.8940191  0.0090985  2076.61   &lt;2e-16 ***\nORIGIN_SZNVSZ05   17.6278585  0.0168107  1048.61   &lt;2e-16 ***\nORIGIN_SZPGSZ01   19.4825220  0.0122960  1584.46   &lt;2e-16 ***\nORIGIN_SZPGSZ02   19.4726761  0.0073116  2663.25   &lt;2e-16 ***\nORIGIN_SZPGSZ03   20.5515713  0.0045631  4503.86   &lt;2e-16 ***\nORIGIN_SZPGSZ04   21.0527131  0.0041500  5072.89   &lt;2e-16 ***\nORIGIN_SZPGSZ05   20.1436604  0.0057267  3517.48   &lt;2e-16 ***\nORIGIN_SZPLSZ01   19.1832002  0.0120006  1598.53   &lt;2e-16 ***\nORIGIN_SZPLSZ02   18.8752206  0.0149740  1260.53   &lt;2e-16 ***\nORIGIN_SZPLSZ03   18.1000818  0.0371769   486.86   &lt;2e-16 ***\nORIGIN_SZPLSZ04   17.1730559  0.0370280   463.79   &lt;2e-16 ***\nORIGIN_SZPLSZ05   17.9084439  0.0225031   795.82   &lt;2e-16 ***\nORIGIN_SZPNSZ01   21.0804425  0.0044829  4702.41   &lt;2e-16 ***\nORIGIN_SZPNSZ02   19.8822123  0.0111507  1783.05   &lt;2e-16 ***\nORIGIN_SZPNSZ03   17.9293289  0.0193571   926.24   &lt;2e-16 ***\nORIGIN_SZPNSZ04   17.1039594  0.0334954   510.64   &lt;2e-16 ***\nORIGIN_SZPNSZ05   18.2543864  0.0275554   662.46   &lt;2e-16 ***\nORIGIN_SZPRSZ01   19.8777935  0.0117586  1690.49   &lt;2e-16 ***\nORIGIN_SZPRSZ02   21.0751780  0.0044832  4700.88   &lt;2e-16 ***\nORIGIN_SZPRSZ03   20.6717019  0.0045577  4535.55   &lt;2e-16 ***\nORIGIN_SZPRSZ04   19.6365125  0.0074923  2620.90   &lt;2e-16 ***\nORIGIN_SZPRSZ05   21.3132151  0.0042119  5060.24   &lt;2e-16 ***\nORIGIN_SZPRSZ06   18.9314574  0.0117278  1614.24   &lt;2e-16 ***\nORIGIN_SZPRSZ07   17.2822918  0.0162430  1063.98   &lt;2e-16 ***\nORIGIN_SZPRSZ08   19.9267642  0.0062298  3198.62   &lt;2e-16 ***\nORIGIN_SZQTSZ01   19.7357175  0.0066359  2974.08   &lt;2e-16 ***\nORIGIN_SZQTSZ02   19.2082141  0.0061402  3128.26   &lt;2e-16 ***\nORIGIN_SZQTSZ03   19.7771883  0.0056220  3517.83   &lt;2e-16 ***\nORIGIN_SZQTSZ04   18.7114421  0.0072842  2568.76   &lt;2e-16 ***\nORIGIN_SZQTSZ05   19.3049324  0.0062401  3093.69   &lt;2e-16 ***\nORIGIN_SZQTSZ06   19.2643228  0.0065590  2937.09   &lt;2e-16 ***\nORIGIN_SZQTSZ07   18.5697347  0.0095373  1947.06   &lt;2e-16 ***\nORIGIN_SZQTSZ08   19.6147001  0.0061330  3198.21   &lt;2e-16 ***\nORIGIN_SZQTSZ09   19.2550793  0.0069947  2752.82   &lt;2e-16 ***\nORIGIN_SZQTSZ10   19.5801866  0.0064513  3035.07   &lt;2e-16 ***\nORIGIN_SZQTSZ11   17.7398366  0.0143648  1234.95   &lt;2e-16 ***\nORIGIN_SZQTSZ12   17.2420354  0.0186736   923.34   &lt;2e-16 ***\nORIGIN_SZQTSZ13   19.3857418  0.0078878  2457.69   &lt;2e-16 ***\nORIGIN_SZQTSZ14   18.1300753  0.0122096  1484.90   &lt;2e-16 ***\nORIGIN_SZQTSZ15   19.4222283  0.0120871  1606.86   &lt;2e-16 ***\nORIGIN_SZRCSZ01   18.1549045  0.0125108  1451.13   &lt;2e-16 ***\nORIGIN_SZRCSZ06   18.8836400  0.0082161  2298.38   &lt;2e-16 ***\nORIGIN_SZRVSZ01   16.7864438  0.0323796   518.43   &lt;2e-16 ***\nORIGIN_SZRVSZ02   16.4203244  0.0276836   593.14   &lt;2e-16 ***\nORIGIN_SZRVSZ03   16.6453738  0.0244992   679.42   &lt;2e-16 ***\nORIGIN_SZRVSZ04   15.9559213  0.0556344   286.80   &lt;2e-16 ***\nORIGIN_SZRVSZ05   17.0476331  0.0164122  1038.71   &lt;2e-16 ***\nORIGIN_SZSBSZ01   20.0417968  0.0062488  3207.29   &lt;2e-16 ***\nORIGIN_SZSBSZ02   19.1869565  0.0081051  2367.26   &lt;2e-16 ***\nORIGIN_SZSBSZ03   20.5769861  0.0045108  4561.70   &lt;2e-16 ***\nORIGIN_SZSBSZ04   20.5154199  0.0050548  4058.57   &lt;2e-16 ***\nORIGIN_SZSBSZ05   19.6250669  0.0065562  2993.35   &lt;2e-16 ***\nORIGIN_SZSBSZ06   18.8419757  0.0171135  1101.00   &lt;2e-16 ***\nORIGIN_SZSBSZ07   19.4897259  0.0124528  1565.09   &lt;2e-16 ***\nORIGIN_SZSBSZ08   18.7027917  0.0140545  1330.73   &lt;2e-16 ***\nORIGIN_SZSBSZ09   18.8893480  0.0088571  2132.67   &lt;2e-16 ***\nORIGIN_SZSESZ02   20.8962192  0.0041665  5015.34   &lt;2e-16 ***\nORIGIN_SZSESZ03   20.9452771  0.0039737  5270.94   &lt;2e-16 ***\nORIGIN_SZSESZ04   20.6576142  0.0046364  4455.55   &lt;2e-16 ***\nORIGIN_SZSESZ05   19.5170732  0.0058912  3312.92   &lt;2e-16 ***\nORIGIN_SZSESZ06   20.7595824  0.0045747  4537.89   &lt;2e-16 ***\nORIGIN_SZSESZ07   17.6888256  0.0195787   903.47   &lt;2e-16 ***\nORIGIN_SZSGSZ01   19.1359250  0.0085781  2230.79   &lt;2e-16 ***\nORIGIN_SZSGSZ02   18.5614369  0.0102037  1819.10   &lt;2e-16 ***\nORIGIN_SZSGSZ03   19.9933176  0.0050434  3964.23   &lt;2e-16 ***\nORIGIN_SZSGSZ04   20.2426871  0.0047211  4287.71   &lt;2e-16 ***\nORIGIN_SZSGSZ05   18.0114965  0.0107743  1671.70   &lt;2e-16 ***\nORIGIN_SZSGSZ06   20.2593194  0.0044538  4548.76   &lt;2e-16 ***\nORIGIN_SZSGSZ07   19.0763664  0.0062968  3029.54   &lt;2e-16 ***\nORIGIN_SZSKSZ01   19.9222451  0.0085136  2340.04   &lt;2e-16 ***\nORIGIN_SZSKSZ02   20.8633383  0.0055248  3776.33   &lt;2e-16 ***\nORIGIN_SZSKSZ03   19.6528148  0.0080534  2440.33   &lt;2e-16 ***\nORIGIN_SZSKSZ04   18.0754470  0.0275771   655.45   &lt;2e-16 ***\nORIGIN_SZSKSZ05   19.1192521  0.0155579  1228.91   &lt;2e-16 ***\nORIGIN_SZSLSZ01   17.1501034  0.0329384   520.67   &lt;2e-16 ***\nORIGIN_SZSLSZ04   19.5949774  0.0076753  2552.98   &lt;2e-16 ***\nORIGIN_SZSRSZ01   16.9761403  0.0162020  1047.78   &lt;2e-16 ***\nORIGIN_SZTHSZ01   17.9695687  0.0488559   367.81   &lt;2e-16 ***\nORIGIN_SZTHSZ03   18.5427522  0.0223617   829.22   &lt;2e-16 ***\nORIGIN_SZTHSZ04   17.4760374  0.0286247   610.52   &lt;2e-16 ***\nORIGIN_SZTHSZ06   17.8401186  0.0183322   973.16   &lt;2e-16 ***\nORIGIN_SZTMSZ01   20.3406361  0.0056607  3593.33   &lt;2e-16 ***\nORIGIN_SZTMSZ02   22.0307026  0.0037386  5892.85   &lt;2e-16 ***\nORIGIN_SZTMSZ03   21.3451920  0.0040606  5256.65   &lt;2e-16 ***\nORIGIN_SZTMSZ04   20.6611593  0.0049896  4140.87   &lt;2e-16 ***\nORIGIN_SZTMSZ05   19.3323133  0.0112868  1712.82   &lt;2e-16 ***\nORIGIN_SZTNSZ01   17.9513571  0.0128266  1399.54   &lt;2e-16 ***\nORIGIN_SZTNSZ02   18.0267387  0.0098372  1832.51   &lt;2e-16 ***\nORIGIN_SZTNSZ03   17.7253700  0.0134668  1316.23   &lt;2e-16 ***\nORIGIN_SZTNSZ04   19.4474075  0.0073760  2636.59   &lt;2e-16 ***\nORIGIN_SZTPSZ01   19.1078631  0.0065635  2911.25   &lt;2e-16 ***\nORIGIN_SZTPSZ02   20.2837634  0.0041411  4898.18   &lt;2e-16 ***\nORIGIN_SZTPSZ03   19.1838238  0.0059552  3221.37   &lt;2e-16 ***\nORIGIN_SZTPSZ04   19.1805388  0.0054778  3501.53   &lt;2e-16 ***\nORIGIN_SZTPSZ05   19.3718076  0.0058610  3305.18   &lt;2e-16 ***\nORIGIN_SZTPSZ06   19.6605723  0.0054968  3576.70   &lt;2e-16 ***\nORIGIN_SZTPSZ07   19.4499807  0.0060491  3215.36   &lt;2e-16 ***\nORIGIN_SZTPSZ08   18.7996538  0.0095757  1963.28   &lt;2e-16 ***\nORIGIN_SZTPSZ09   19.0025110  0.0067068  2833.31   &lt;2e-16 ***\nORIGIN_SZTPSZ10   18.8899657  0.0076094  2482.46   &lt;2e-16 ***\nORIGIN_SZTPSZ11   19.6277780  0.0053983  3635.93   &lt;2e-16 ***\nORIGIN_SZTPSZ12   19.1471104  0.0065742  2912.45   &lt;2e-16 ***\nORIGIN_SZTSSZ01   17.4901113  0.0478954   365.17   &lt;2e-16 ***\nORIGIN_SZTSSZ02   20.4997466  0.0081850  2504.55   &lt;2e-16 ***\nORIGIN_SZTSSZ03   20.1076553  0.0084728  2373.19   &lt;2e-16 ***\nORIGIN_SZTSSZ04   20.0646610  0.0089008  2254.26   &lt;2e-16 ***\nORIGIN_SZTSSZ05   19.3962067  0.0151392  1281.19   &lt;2e-16 ***\nORIGIN_SZTSSZ06   20.9235857  0.0178278  1173.65   &lt;2e-16 ***\nORIGIN_SZWCSZ01   20.8411600  0.0086519  2408.86   &lt;2e-16 ***\nORIGIN_SZWCSZ02   17.7355404  0.0328889   539.26   &lt;2e-16 ***\nORIGIN_SZWCSZ03   14.9380886  0.1240699   120.40   &lt;2e-16 ***\nORIGIN_SZWDSZ01   21.1969012  0.0037830  5603.23   &lt;2e-16 ***\nORIGIN_SZWDSZ02   20.5930001  0.0044572  4620.13   &lt;2e-16 ***\nORIGIN_SZWDSZ03   21.2521867  0.0041672  5099.85   &lt;2e-16 ***\nORIGIN_SZWDSZ04   21.0702687  0.0048648  4331.13   &lt;2e-16 ***\nORIGIN_SZWDSZ05   20.4008998  0.0051801  3938.35   &lt;2e-16 ***\nORIGIN_SZWDSZ06   20.6669176  0.0049280  4193.78   &lt;2e-16 ***\nORIGIN_SZWDSZ07   19.0500370  0.0082729  2302.71   &lt;2e-16 ***\nORIGIN_SZWDSZ08   19.0816252  0.0080667  2365.49   &lt;2e-16 ***\nORIGIN_SZWDSZ09   21.4182096  0.0040391  5302.73   &lt;2e-16 ***\nORIGIN_SZYSSZ01   19.5355157  0.0057540  3395.14   &lt;2e-16 ***\nORIGIN_SZYSSZ02   20.8737972  0.0048278  4323.64   &lt;2e-16 ***\nORIGIN_SZYSSZ03   21.6614437  0.0040011  5413.81   &lt;2e-16 ***\nORIGIN_SZYSSZ04   20.9305289  0.0043595  4801.10   &lt;2e-16 ***\nORIGIN_SZYSSZ05   20.1727678  0.0058466  3450.34   &lt;2e-16 ***\nORIGIN_SZYSSZ06   19.1481507  0.0116724  1640.47   &lt;2e-16 ***\nORIGIN_SZYSSZ07   18.7919074  0.0141636  1326.78   &lt;2e-16 ***\nORIGIN_SZYSSZ08   19.9733515  0.0061229  3262.07   &lt;2e-16 ***\nORIGIN_SZYSSZ09   20.9366181  0.0040347  5189.15   &lt;2e-16 ***\nlog(SCHOOL_COUNT)  0.4755516  0.0004701  1011.55   &lt;2e-16 ***\nlog(RETAIL_COUNT)  0.1796905  0.0001856   968.12   &lt;2e-16 ***\nlog(DIST)         -1.6929522  0.0004093 -4136.01   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 189463537  on 14471  degrees of freedom\nResidual deviance:  15526121  on 14189  degrees of freedom\nAIC: 15615824\n\nNumber of Fisher Scoring iterations: 6\n\n\n\nGoodness-of-Fit\n\nCalcRSquared &lt;- function(observed,estimated){\n  r &lt;- cor(observed, estimated)\n  R2 &lt;- r^2\n  R2\n}\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(orcSIM_Poisson$data$TRIPS, orcSIM_Poisson$fitted.values)\n\n[1] 0.4362208\n\n\n\nperformance_rmse(orcSIM_Poisson,\n                 normalized = FALSE)\n\n[1] 2613.236\n\n\n\n\n\nDoubly Constrained\n\ndbcSIM_Poisson &lt;- glm(formula = TRIPS ~\n                        ORIGIN_SZ +\n                        DESTIN_SZ +\n                        log(DIST), # No - 1 after log(DIST)\n                      family = poisson(link = 'log'),\n                      data = inter_zonal_flow,\n                      na.action = na.exclude)\n\n\nCalcRSquared(dbcSIM_Poisson$data$TRIPS, dbcSIM_Poisson$fitted.values)\n\n[1] 0.7001882\n\n\n\nperformance_rmse(dbcSIM_Poisson,\n                 normalized = FALSE)\n\n[1] 1906.694"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex1/data/geospatial/hexagon.html",
    "href": "Take-Home_Ex/Take-Home_Ex1/data/geospatial/hexagon.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                 +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs 0 0     false"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Business.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Business.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/F&B.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/F&B.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Liesure&Recreation.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Liesure&Recreation.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Retails.html",
    "href": "Take-Home_Ex/Take-Home_Ex2/data/geospatial/Retails.html",
    "title": "ISSS624",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  }
]