---
title: "In-class_Ex3"
date: '2 December 2023'
date-modified: 'last-modified'
format: html
execute: 
  eval: true # run the code live
  echo: true # all code will appear
  warning: false # hide all warnings
editor: visual
---

## Getting Started

```{r}
pacman::p_load(tmap, sf, sp, DT, performance, reshape2, ggpubr, units, tidyverse)
```

## The Data

The following data will be used, as a continuation of Hands-on_Ex3:

1.  *od_data.rds:* weekday morning peak passenger flows at planning subzone level.
2.  *mpsz.rds:* URA Master Plan 2019 Planning Subzone boundary in simple feature tibble data frame format.

Beside these two data sets, an additional attribute data file called pop.csv will be provided.

### Importing Geospatial Data

```{r}
mpsz <- read_rds('data/rds/mpsz.rds')
```

### Converting from sf data.table to SpatialPolygonsDataFrame

This is a way to convert a sf data.table to SpatialPolygonsDataFrame. However, the sf data.table is still the preferred format for analysis.

```{r}
# Untidy way
mpsz_sp <- as(mpsz, 'Spatial')
```

## Distance matrix between centroids of each zone.

*spDists()* of **sp** can be used to calculate the cent

```{r}
dist <- spDists(mpsz_sp, longlat = FALSE)
```

### Labelling columns and row headers of distance matrix

```{r}
sz_names <- mpsz$SUBZONE_C
```

Next we will attach SUBZONE_C names to the rows and columns of the distance matrix.

```{r}
colnames(dist) <- paste0(sz_names)
rownames(dist) <- paste0(sz_names)
```

### Pivoting distance value by SUBZONE_C

Next, we will pivot the distance matrix into a long table by using melt.

```{r}
distPair <- melt(dist) %>%
  rename(dist = value)
```

### Updating intra-zonal distances

```{r}
distPair %>%
  filter(dist > 0) %>%
  summary()
```

Since Min inter-zonal distances is 173, we can roughly estimate the intra-zonal distance (distance between the centroid and the polygon's boundary).

```{r}
distPair$dist <- ifelse(distPair$dist == 0,
                        50, distPair$dist)
```

We can also rename the column names in the table for easier manipulation further on.

```{r}
distPair <- distPair %>%
  rename(orig = Var1,
         dest = Var2)
```

We can save distPair as an rds file for future use.

```{r}
write_rds(distPair, 'data/rds/distPair.rds')
```

## Preparing flow data

We can import *od_data.rds* created previously into R using *read_rds().*

```{r}
od_data <- read_rds('data/rds/od_data.rds')
```

Next, the total passenger trip between and within planning subzones will be calculated.

```{r}
flow_data <- od_data %>%
  group_by(ORIGIN_SZ, DESTIN_SZ) %>%
  summarize(TRIPS = sum(MORNING_PEAK))
```

We can see the top 5 rows of flow_data using *head()*

```{r}
head(flow_data)
```

### Separating intra-flow from passenger volume df

We can add three new fields into flow_data:

1.  FlowNoIntra: Number of trips, excluding intra-zonal trips.
2.  offset: A neglible value used for later analysis to offset intra-zonal trips.

```{r}
flow_data$FlowNoIntra <- ifelse(flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 0, flow_data$TRIPS)

flow_data$offset <- ifelse(flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, 0.000001, 1)
```

### Combining passenger volume data with distance value

Now that we have the distance between the subzones (distPair) and the number of trips between them (flow_data), we can try to combine them into one data frame.

Before we can join *flow_data* and *distPair,* we need to convert data value type of ORIGIN_SZ and DESTIN_SZ of flow_data into factor type.

```{r}
flow_data$ORIGIN_SZ <- as.factor(flow_data$ORIGIN_SZ)
flow_data$DESTIN_SZ <- as.factor(flow_data$DESTIN_SZ)
```

*left_join()* can be used to combine *flow_data* and *distPair*

```{r}
flow_data1 <- flow_data %>%
  left_join(distPair,
            by = c('ORIGIN_SZ' = 'orig',
                   'DESTIN_SZ' = 'dest'))
```

## Preparing Origin and Destination Attributes

### Importing Population Data

```{r}
pop <- read_csv('data/aspatial/pop.csv')
```

### Geospatial Data Wrangling

```{r}
pop <- pop %>%
  left_join(mpsz,
            by = c('PA' = 'PLN_AREA_N',
                   'SZ' = 'SUBZONE_N')) %>%
  select(1:6) %>%
  rename(SZ_NAME = SZ,
         SZ = SUBZONE_C)
```

### Preparing Origin Attribute

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(ORIGIN_SZ = 'SZ')) %>%
  rename(ORIGIN_AGE7_12 = AGE7_12,
         ORIGIN_AGE13_24 = AGE13_24,
         ORIGIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

### Preparing Destination Attribute

```{r}
flow_data1 <- flow_data1 %>%
  left_join(pop,
            by = c(DESTIN_SZ = 'SZ')) %>%
  rename(DESTIN_AGE7_12 = AGE7_12,
         DESTIN_AGE13_24 = AGE13_24,
         DESTIN_AGE25_64 = AGE25_64) %>%
  select(-c(PA, SZ_NAME))
```

## Calibrating Spatial Interaction Models

We will use the Poisson Regression Method to calibrate Spatial Interaction Models

### Importing the Modelling Data

```{r}
SIM_data <- read_rds('data/rds/SIM_data.rds')
```

### Visualizing the Dependent Variable

Let's plot the distribution of the dependent variable (i.e. TRIPS) by making a histogram with **ggplot2**.

```{r}
ggplot(SIM_data,
       aes(x=TRIPS))+
  geom_histogram()
```

The distribution is highly skewed and does not resemble a bell shape, also known as the normal distribution.

Now, we can visualize the relation between the dependent variable and one of the key independent variable (distance between zones) in the Spatial Interaction Mode.

```{r}
ggplot(SIM_data,
       aes(x = dist,
           y = TRIPS))+
  geom_point()+
  geom_smooth(method=lm)
```

The relationship does not resemble a linear relationship.

However, if we create a scatter plot using the log transformed version of these variables, the relationship will better resemble a linear relationship.

```{r}
ggplot(SIM_data,
       aes(x = log(dist),
           y = log(TRIPS)))+
  geom_point()+
  geom_smooth(method = lm)
```

### Checking for Variables with Zero Values

Since Poisson Regression is based of log and log 0 is undefined, it is important for us to ensure that there is no 0 in the explanatory variables.

*summary()* can be used to compute the summary statistics of all variables in the data frame.

```{r}
summary(SIM_data)
```

The print report above reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.

We can use *ifelse()* functions to replace 0 values to 0.99 so that the log function would not result in minus infinity (for 0) or 0 (for 1).

```{r}
SIM_data$ORIGIN_AGE7_12 <- ifelse(SIM_data$ORIGIN_AGE7_12 == 0, 0.99, SIM_data$ORIGIN_AGE7_12)

SIM_data$ORIGIN_AGE13_24 <- ifelse(SIM_data$ORIGIN_AGE13_24 == 0, 0.99, SIM_data$ORIGIN_AGE13_24)

SIM_data$ORIGIN_AGE25_64 <- ifelse(SIM_data$ORIGIN_AGE25_64 == 0, 0.99, SIM_data$ORIGIN_AGE25_64)

SIM_data$DESTIN_AGE7_12 <- ifelse(SIM_data$DESTIN_AGE7_12 == 0, 0.99, SIM_data$DESTIN_AGE7_12)

SIM_data$DESTIN_AGE13_24 <- ifelse(SIM_data$DESTIN_AGE13_24 == 0, 0.99, SIM_data$DESTIN_AGE13_24)

SIM_data$DESTIN_AGE25_64 <- ifelse(SIM_data$DESTIN_AGE25_64 == 0, 0.99, SIM_data$DESTIN_AGE25_64)

```

Let's check the *summary()* again.

```{r}
summary(SIM_data)
```

All 0 values have been replaced by 0.99

### Unconstrained Spatial Interaction Model

*glm()* can be used to calibrate an unconstrained spatial interaction model. Our explanatory variables are origin population by different age cohort, destination population by age cohort and distance between origin and destination in km (i.e. *dist).*

```{r}
uncSIM <- glm(formula = TRIPS ~ 
                log(ORIGIN_AGE25_64)+
                log(DESTIN_AGE25_64)+
                log(dist),
              family = poisson(link = 'log'),
              data = SIM_data,
              na.action = na.exclude)

uncSIM
```

### R-squared Function

In order to measure how much variation of the trips can be accounted by the model, we will calculate the R-squared value.

```{r}
CalcRSquared <- function(observed,estimated){
  r <- cor(observed, estimated)
  R2 <- r^2
  R2
}
```

Now that we have the function, we can plug in our observed and fitted values to compute R-squared.

```{r}
CalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)
```

We can also calculate the McFadden Pseudo-R-squared.

```{r}
r2_mcfadden(uncSIM)
```

### Origin (Production) constrained SIM

We will fit an origin constrained SIM by using the code below.

```{r}
orcSIM <- glm(formula = TRIPS ~
                ORIGIN_SZ +
                log(DESTIN_AGE25_64)+
                log(dist),
              family = poisson(link = 'log'),
              data = SIM_data,
              na.action = na.exclude)

summary(orcSIM)
```

We can use our function to calculate the R-squared.

```{r}
CalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)
```

### Destination Constrained

Similarly, we can fit a destination constrained SIM

```{r}
decSIM <- glm(formula = TRIPS ~
                DESTIN_SZ +
                log(ORIGIN_AGE25_64)+
                log(dist),
              family = poisson(link = 'log'),
              data = SIM_data,
              na.action = na.exclude)

summary(decSIM)
```

Similarly, we can calculate the R-squared.

```{r}
CalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)
```

### Doubly constrained

Now, we will fit a doubly constrained SIM.

```{r}
dbcSIM <- glm(formula = TRIPS ~
                ORIGIN_SZ +
                DESTIN_SZ +
                log(dist),
              family = poisson(link = 'log'),
              data = SIM_data,
              na.action = na.exclude)

summary(dbcSIM)
```

Let's calculate the R-squared for the doubly constrained model.

```{r}
CalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)
```

### Model Comparison

Another useful model performance measure for continuous dependent variable is Root Mean Squared Error.

Model comparison can be done with the *compare_performance()* function of the **performance** package.

```{r}
model_list <- list(unconstrained = uncSIM,
                   originConstrained = orcSIM,
                   destinationConstrained = decSIM,
                   doublyConstrained = dbcSIM)
```

Now let's use the model_list to compare model performance.

```{r}
compare_performance(model_list,
                    metrics = 'RMSE')
```

The print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 1487.111.

### Visualizing Fitted

Before we visualize the observed and fitted values, we need to extract the fitted values from each model.

```{r}
df <- as.data.frame(uncSIM$fitted.values) %>%
  round(digits = 0)
```

Next, we will join the values to SIM_data frame.

```{r}
SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(uncTRIPS = "uncSIM$fitted.values")
```

Repeat these steps for other models.

```{r}
df <- as.data.frame(orcSIM$fitted.values) %>%
  round(digits = 0)

SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(orcTRIPS = 'orcSIM$fitted.values')
```

```{r}
df <- as.data.frame(decSIM$fitted.values) %>%
  round(digits = 0)

SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(decTRIPS = 'decSIM$fitted.values')
```

```{r}
df <- as.data.frame(dbcSIM$fitted.values) %>%
  round(digits = 0)

SIM_data <- SIM_data %>%
  cbind(df) %>%
  rename(dbcTRIPS = 'dbcSIM$fitted.values')
```

Now we can create our visualizations.

```{r}
unc_p <- ggplot(SIM_data,
                aes(x = uncTRIPS,
                    y = TRIPS))+
  geom_point()+
  geom_smooth(method = lm)

orc_p <- ggplot(data = SIM_data,
                aes(x = orcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dec_p <- ggplot(data = SIM_data,
                aes(x = decTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

dbc_p <- ggplot(data = SIM_data,
                aes(x = dbcTRIPS,
                    y = TRIPS)) +
  geom_point() +
  geom_smooth(method = lm)

ggarrange(unc_p, orc_p, dec_p, dbc_p,
          ncol = 2,
          nrow = 2)
```
